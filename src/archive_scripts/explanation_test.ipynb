{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests on how to launch the explanation module for our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch_geometric\n",
    "from torch_geometric.loader import DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from models import GATv2Lightning\n",
    "from utils.dataloader_utils import HDFDataset_Writer, HDFDatasetLoader, GraphDataset\n",
    "from torch_geometric.nn import Sequential\n",
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEIZURE_LOOKBACK = 600\n",
    "BUFFER_TIME = 15\n",
    "TIMESTEP = 6\n",
    "INTER_OVERLAP = 0\n",
    "PREICTAL_OVERLAP = 0\n",
    "ICTAL_OVERLAP = 0\n",
    "DOWNSAMPLING_F = 60\n",
    "SFREQ = 256\n",
    "SMOTE_FLAG = False\n",
    "CONNECTIVITY_METRIC = \"spectral_corr\"\n",
    "TRAIN_VAL_SPLIT = 0.1\n",
    "SEED = 42\n",
    "FFT = False\n",
    "loso_patient = \"chb20\"\n",
    "MNE_FEATURES = True\n",
    "KFOLD_CVAL_MODE = False\n",
    "NORMALIZING_PERIOD = 'interictal'\n",
    "USED_CLASSES_DICT = {\n",
    "            \"interictal\": False,\n",
    "            \"preictal\": True,\n",
    "            \"ictal\": True,\n",
    "        }\n",
    "BATCH_SIZE = 32\n",
    "data_pth = \"../../data\"\n",
    "writer = HDFDataset_Writer(\n",
    "            seizure_lookback=SEIZURE_LOOKBACK,\n",
    "            buffer_time=BUFFER_TIME,\n",
    "            sample_timestep=TIMESTEP,\n",
    "            inter_overlap=INTER_OVERLAP,\n",
    "            preictal_overlap=PREICTAL_OVERLAP,\n",
    "            ictal_overlap=ICTAL_OVERLAP,\n",
    "            downsample=DOWNSAMPLING_F,\n",
    "            sampling_f=SFREQ,\n",
    "            smote=SMOTE_FLAG,\n",
    "            connectivity_metric=CONNECTIVITY_METRIC,\n",
    "            npy_dataset_path=f\"{data_pth}/npy_data_full\",\n",
    "            event_tables_path=f\"{data_pth}/event_tables\",\n",
    "            cache_folder=f\"{data_pth}/cache\",\n",
    "        )\n",
    "cache_file_path = writer.get_dataset()\n",
    "\n",
    "loader = HDFDatasetLoader(\n",
    "    root=cache_file_path,\n",
    "    train_val_split_ratio=TRAIN_VAL_SPLIT,\n",
    "    loso_subject=loso_patient,\n",
    "    sampling_f=SFREQ,\n",
    "    extract_features=MNE_FEATURES,\n",
    "    fft=FFT,\n",
    "    seed=SEED,\n",
    "    used_classes_dict=USED_CLASSES_DICT,\n",
    "    normalize_with=NORMALIZING_PERIOD,\n",
    "    kfold_cval_mode=KFOLD_CVAL_MODE,\n",
    ")\n",
    "\n",
    "train_ds_path, valid_ds_path, loso_ds_path = loader.get_datasets()\n",
    "\n",
    "train_dataset = GraphDataset(train_ds_path)\n",
    "valid_dataset = GraphDataset(valid_ds_path)\n",
    "loso_dataset = GraphDataset(loso_ds_path)\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0\n",
    ")\n",
    "valid_dataloader = DataLoader(\n",
    "    valid_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0\n",
    ")\n",
    "loso_dataloader = DataLoader(\n",
    "    loso_dataset, batch_size=len(loso_dataset), shuffle=False, num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_shape = train_dataset[0].x.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GATv2Lightning(\n",
    "    in_features=features_shape,\n",
    "    n_gat_layers=4,\n",
    "    hidden_dim=32,\n",
    "    n_heads=4,\n",
    "    activation=\"leaky_relu\",\n",
    "    norm_method=\"batch\",\n",
    "    pooling_method=\"mean\",\n",
    "    class_weights=torch.tensor([1.])\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example for attention explanation and connectivty measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_unpacked = next(iter(loso_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_unpacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.explain import AttentionExplainer, Explainer, ModelConfig\n",
    "\n",
    "att_explainer = AttentionExplainer()\n",
    "torch_geometric.seed_everything(42)\n",
    "config = ModelConfig(\n",
    "    \"binary_classification\", task_level=\"graph\", return_type=\"raw\"\n",
    ")\n",
    "explainer = Explainer(\n",
    "    model,\n",
    "    algorithm=att_explainer,\n",
    "    explanation_type=\"model\",\n",
    "    model_config=config,\n",
    "    edge_mask_type=\"object\",\n",
    ")\n",
    "idx = 0\n",
    "pyg_batch = torch.zeros((18,), dtype=torch.long)\n",
    "explanation = explainer(\n",
    "    x=batch_unpacked.x,\n",
    "    edge_index=batch_unpacked.edge_index,\n",
    "    target=batch_unpacked.y,\n",
    "    pyg_batch=batch_unpacked.batch,\n",
    ")\n",
    "#explanation.visualize_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample connection_strengths dictionary\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "connection_strengths = {\n",
    "    ('node1', 'node2'): 0.8, ('node1', 'node3'): 0.6, ('node1', 'node4'): 0.9, ('node1', 'node5'): 0.7,\n",
    "    ('node2', 'node3'): 0.7, ('node2', 'node4'): 0.5, ('node2', 'node5'): 0.6, ('node2', 'node6'): 0.4,\n",
    "    ('node3', 'node4'): 0.4, ('node3', 'node5'): 0.3, ('node3', 'node6'): 0.2, ('node3', 'node7'): 0.1,\n",
    "    ('node4', 'node5'): 0.3, ('node4', 'node6'): 0.2, ('node4', 'node7'): 0.1, ('node4', 'node8'): 0.6,\n",
    "    ('node5', 'node6'): 0.1, ('node5', 'node7'): 0.2, ('node5', 'node8'): 0.3, ('node5', 'node9'): 0.9\n",
    "}\n",
    "# Create a NetworkX graph\n",
    "G = nx.Graph()\n",
    "\n",
    "# Add edges and connection strengths to the graph\n",
    "for edge, strength in connection_strengths.items():\n",
    "    G.add_edge(*edge, strength=strength)\n",
    "\n",
    "# Get positions for circular layout\n",
    "pos = nx.circular_layout(G)\n",
    "\n",
    "# Get connection strengths as edge labels\n",
    "edge_labels = {(edge[0], edge[1]): f\"{strength:.2f}\" for edge, strength in nx.get_edge_attributes(G, 'strength').items()}\n",
    "\n",
    "# Get connection strengths as edge opacities (scaled between 0.2 to 1.0 for visualization)\n",
    "edge_opacities = [0.2 + strength * 0.8 for strength in nx.get_edge_attributes(G, 'strength').values()]\n",
    "\n",
    "# Draw the graph\n",
    "nx.draw(G, pos, with_labels=True, node_size=1000, font_size=10, node_color='skyblue', font_color='black', width=2.0, edge_color=edge_opacities, edge_cmap=plt.cm.Blues)\n",
    "plt.colorbar(plt.cm.ScalarMappable(cmap=plt.cm.Blues), label=\"Connection Strength\")\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example for feature importance explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.explain import GNNExplainer, Explainer, ModelConfig\n",
    "\n",
    "gnn_explainer = GNNExplainer(epochs=100, lr=0.001)\n",
    "torch_geometric.seed_everything(42)\n",
    "config = ModelConfig(\n",
    "    \"binary_classification\", task_level=\"graph\", return_type=\"raw\"\n",
    ")\n",
    "explainer = Explainer(\n",
    "    model,\n",
    "    algorithm=gnn_explainer,\n",
    "    explanation_type=\"model\",\n",
    "    model_config=config,\n",
    "    node_mask_type=\"attributes\",\n",
    "    edge_mask_type='object'\n",
    ")\n",
    "idx = 0\n",
    "pyg_batch = torch.zeros((18,), dtype=torch.long)\n",
    "explanation = explainer(\n",
    "    x=batch_unpacked.x,\n",
    "    edge_index=batch_unpacked.edge_index,\n",
    "    target=batch_unpacked.y,\n",
    "    pyg_batch=batch_unpacked.batch,\n",
    ")\n",
    "feature_labels = ['variance', 'hjorth_mobility','hjorth_complexity',\n",
    "                  \"line_length\", \"katz_fd\", \"higuchi_fd\", \"delta_energy\",\n",
    "                  \"theta_energy\", \"alpha_energy\", \"beta_energy\"\n",
    "                  ]\n",
    "explanation.visualize_feature_importance(feat_labels=feature_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation.visualize_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Captum feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.explain import CaptumExplainer, Explainer, ModelConfig\n",
    "\n",
    "captum_explainer = CaptumExplainer(\"ShapleyValueSampling\")\n",
    "torch_geometric.seed_everything(42)\n",
    "config = ModelConfig(\n",
    "    \"binary_classification\", task_level=\"graph\", return_type=\"raw\"\n",
    ")\n",
    "explainer = Explainer(\n",
    "    model,\n",
    "    algorithm=captum_explainer,\n",
    "    explanation_type=\"model\",\n",
    "    model_config=config,\n",
    "    node_mask_type=\"attributes\",\n",
    ")\n",
    "idx = 0\n",
    "pyg_batch = torch.zeros((18,), dtype=torch.long)\n",
    "explanation = explainer(\n",
    "    x=train_dataset[idx].x,\n",
    "    edge_index=train_dataset[idx].edge_index,\n",
    "    target=train_dataset[idx].y.squeeze(),\n",
    "    pyg_batch=pyg_batch,\n",
    ")\n",
    "feature_labels = ['variance', 'hjorth_mobility','hjorth_complexity',\n",
    "                  \"line_length\", \"katz_fd\", \"higuchi_fd\", \"delta_energy\",\n",
    "                  \"theta_energy\", \"alpha_energy\", \"beta_energy\"\n",
    "                  ]\n",
    "explanation.visualize_feature_importance(feat_labels=feature_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
