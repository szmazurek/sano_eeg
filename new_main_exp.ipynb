{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import os\n",
    "from dataclasses import dataclass\n",
    "import utils\n",
    "from torch_geometric_temporal import  DynamicGraphTemporalSignal,StaticGraphTemporalSignal, temporal_signal_split, DynamicGraphTemporalSignalBatch\n",
    "import networkx as nx\n",
    "from torch_geometric.utils import from_networkx\n",
    "import scipy\n",
    "import sklearn\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DynamicBatchSampler,DataLoader\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torchvision.ops import sigmoid_focal_loss\n",
    "from torch_geometric_temporal.nn.recurrent import DCRNN,  GConvGRU, A3TGCN, TGCN2, TGCN, A3TGCN2\n",
    "from torch_geometric_temporal.nn.attention import STConv\n",
    "from torchmetrics.classification import BinaryRecall,BinarySpecificity, AUROC, ROC\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "import pytorch_lightning as pl\n",
    "from torch_geometric.nn import GCNConv,BatchNorm,GATv2Conv\n",
    "from sklearn.model_selection import KFold,StratifiedKFold, StratifiedShuffleSplit\n",
    "from mne_features.univariate import compute_kurtosis, compute_hjorth_complexity, compute_hjorth_mobility\n",
    "import torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO think about using kwargs argument here to specify args for dataloader\n",
    "@dataclass\n",
    "class SeizureDataLoader:\n",
    "    npy_dataset_path: Path\n",
    "    event_tables_path: Path\n",
    "    plv_values_path: Path\n",
    "    loso_patient: str = None\n",
    "    sampling_f: int = 256\n",
    "    seizure_lookback: int = 600\n",
    "    sample_timestep: int = 5\n",
    "    inter_overlap: int = 0\n",
    "    ictal_overlap: int = 0\n",
    "    self_loops: bool = True\n",
    "    balance: bool = True\n",
    "    train_test_split: float = None\n",
    "    fft: bool = False\n",
    "    hjorth: bool = False\n",
    "    downsample: int = None\n",
    "    buffer_time: int = 15\n",
    "    batch_size : int = 32\n",
    "    \"\"\"Class to prepare dataloaders for eeg seizure perdiction from stored files.\n",
    "\n",
    "    Attributes:\n",
    "        npy_dataset_path {Path} -- Path to folder with dataset preprocessed into .npy files.\n",
    "        event_tables_path {Path} -- Path to folder with .csv files containing seizure events information for every patient.\n",
    "        loso_patient {str} -- Name of patient to be selected for LOSO valdiation, specified in format \"chb{patient_number}\"\",\n",
    "        eg. \"chb16\". (default: {None}).\n",
    "        samplin_f {int} -- Sampling frequency of the loaded eeg data. (default: {256}).\n",
    "        seizure_lookback {int} -- Time horizon to sample pre-seizure data (length of period before seizure) in seconds. \n",
    "        (default: {600}).\n",
    "        sample_timestep {int} -- Amounts of seconds analyzed in a single sample. (default: {5}).\n",
    "        overlap {int} -- Amount of seconds overlap between samples. (default: {0}).\n",
    "        self_loops {bool} -- Wheather to add self loops to nodes of the graph. (default: {True}).\n",
    "        shuffle {bool} --  Wheather to shuffle training samples.\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    assert (fft and hjorth) == False, \"When fft is True, hjorth should be False\"\n",
    "\n",
    "    def _get_event_tables(self, patient_name: str) -> tuple[dict, dict]:\n",
    "        \"\"\"Read events for given patient into start and stop times lists from .csv extracted files.\"\"\"\n",
    "\n",
    "        event_table_list = os.listdir(self.event_tables_path)\n",
    "        patient_event_tables = [\n",
    "            os.path.join(self.event_tables_path, ev_table)\n",
    "            for ev_table in event_table_list\n",
    "            if patient_name in ev_table\n",
    "        ]\n",
    "        patient_event_tables = sorted(patient_event_tables)\n",
    "        patient_start_table = patient_event_tables[\n",
    "            0\n",
    "        ]  ## done terribly, but it has to be so for win/linux compat\n",
    "        patient_stop_table = patient_event_tables[1]\n",
    "        start_events_dict = pd.read_csv(patient_start_table).to_dict(\"index\")\n",
    "        stop_events_dict = pd.read_csv(patient_stop_table).to_dict(\"index\")\n",
    "        return start_events_dict, stop_events_dict\n",
    "\n",
    "    def _get_recording_events(self, events_dict, recording) -> list[int]:\n",
    "        \"\"\"Read seizure times into list from event_dict\"\"\"\n",
    "        recording_list = list(events_dict[recording + \".edf\"].values())\n",
    "        recording_events = [int(x) for x in recording_list if not np.isnan(x)]\n",
    "        return recording_events\n",
    "\n",
    "    def _get_graph(self, n_nodes: int) -> nx.Graph:\n",
    "        \"\"\"Creates Networx fully connected graph with self loops\"\"\"\n",
    "        graph = nx.complete_graph(n_nodes)\n",
    "        self_loops = [[node, node] for node in graph.nodes()]\n",
    "        graph.add_edges_from(self_loops)\n",
    "        return graph\n",
    "\n",
    "    def _get_edge_weights_recording(self, plv_values: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Method that takes plv values for given recording and assigns them\n",
    "        as edge attributes to a fc graph.\"\"\"\n",
    "        graph = self._get_graph(plv_values.shape[0])\n",
    "        garph_dict = {}\n",
    "        for edge in graph.edges():\n",
    "            e_start, e_end = edge\n",
    "            garph_dict[edge] = {\"plv\": plv_values[e_start, e_end]}\n",
    "        nx.set_edge_attributes(graph, garph_dict)\n",
    "        edge_weights = from_networkx(graph).plv.numpy()\n",
    "        return edge_weights\n",
    "\n",
    "    def _get_edges(self):\n",
    "        \"\"\"Method to assign edge attributes. Has to be called AFTER get_dataset() method.\"\"\"\n",
    "        graph = self._get_graph(self._features.shape[1])\n",
    "        edges = np.expand_dims(from_networkx(graph).edge_index.numpy(), axis=0)\n",
    "        edges_per_sample_train = np.repeat(\n",
    "            edges, repeats=self._features.shape[0], axis=0\n",
    "        )\n",
    "        self._edges = torch.tensor(edges_per_sample_train)\n",
    "        if self.loso_patient is not None:\n",
    "            edges_per_sample_val = np.repeat(\n",
    "                edges, repeats=self._val_features.shape[0], axis=0\n",
    "            )\n",
    "            self._val_edges = torch.tensor(edges_per_sample_val)\n",
    "\n",
    "    def _array_to_tensor(self):\n",
    "        \"\"\"Method converting features, edges and weights to torch.tensors\"\"\"\n",
    "        self._features = torch.tensor(self._features, dtype=torch.float32)\n",
    "        self._labels = torch.tensor(self._labels)\n",
    "        self._time_labels = torch.tensor(self._time_labels)\n",
    "        self._edge_weights = torch.tensor(self._edge_weights)\n",
    "\n",
    "    def _val_array_to_tensor(self):\n",
    "        self._val_features = torch.tensor(self._val_features, dtype=torch.float32)\n",
    "        self._val_labels = torch.tensor(self._val_labels)\n",
    "        self._val_time_labels = torch.tensor(self._val_time_labels)\n",
    "        self._val_edge_weights = torch.tensor(self._val_edge_weights)\n",
    "\n",
    "    def _get_labels_count(self):\n",
    "        labels, counts = np.unique(self._labels, return_counts=True)\n",
    "        self._label_counts = {}\n",
    "        for n, label in enumerate(labels):\n",
    "            self._label_counts[int(label)] = counts[n]\n",
    "\n",
    "    def _get_val_labels_count(self):\n",
    "        labels, counts = np.unique(self._val_labels, return_counts=True)\n",
    "        self._val_label_counts = {}\n",
    "        for n, label in enumerate(labels):\n",
    "            self._val_label_counts[int(label)] = counts[n]\n",
    "\n",
    "    def _perform_features_train_fft(self):\n",
    "        self._features = torch.fft.fft(self._features)\n",
    "\n",
    "    def _perform_features_val_fft(self):\n",
    "        self._val_features = torch.fft.fft(self._val_features)\n",
    "\n",
    "    def _downsample_features_train(self):\n",
    "        resampler = torchaudio.transforms.Resample(self.sampling_f, self.downsample)\n",
    "        self._features = resampler(self._features)\n",
    "\n",
    "    def _downsample_features_val(self):\n",
    "        resampler = torchaudio.transforms.Resample(self.sampling_f, self.downsample)\n",
    "        self._val_features = resampler(self._val_features)\n",
    "\n",
    "    def _calculate_hjorth_features_train(self):\n",
    "\n",
    "        new_features = [\n",
    "            np.concatenate(\n",
    "                [\n",
    "                    compute_hjorth_mobility(feature),\n",
    "                    compute_hjorth_complexity(feature),\n",
    "                ],\n",
    "                axis=1,\n",
    "            )\n",
    "            for feature in self._features\n",
    "        ]\n",
    "        self._features = np.array(new_features)\n",
    "\n",
    "    def _calculate_hjorth_features_val(self):\n",
    "\n",
    "        new_features = [\n",
    "            np.concatenate(\n",
    "                [\n",
    "                    compute_hjorth_mobility(feature),\n",
    "                    compute_hjorth_complexity(feature),\n",
    "                ],\n",
    "                axis=1,\n",
    "            )\n",
    "            for feature in self._val_features\n",
    "        ]\n",
    "        self._val_features = np.array(new_features)\n",
    "    def _features_to_data_list(features,edges,edge_weights,labels, time_label):\n",
    "        data_list = [\n",
    "                    Data(\n",
    "                        x=features[i],\n",
    "                        edge_index=edges[i],\n",
    "                        edge_attr=edge_weights[i],\n",
    "                        y=labels[i],\n",
    "                        time=time_label[i],\n",
    "                    )\n",
    "                    for i in range(len(features))\n",
    "                ]\n",
    "        return data_list\n",
    "    def _split_data_list(data_list):\n",
    "        class_labels = [data.y.item() for data in data_list]\n",
    "        splitter = StratifiedShuffleSplit(n_splits=1, test_size=self.train_test_split, random_state=42)\n",
    "        train_indices, val_indices = next(splitter.split(data_list, class_labels))\n",
    "        data_list_train = [data_list[i] for i in train_indices]\n",
    "        dataset_list_val = [data_list[i] for i in val_indices]\n",
    "        return data_list_train, dataset_list_val\n",
    "    def _balance_classes(self):\n",
    "        negative_label = self._label_counts[0]\n",
    "        positive_label = self._label_counts[1]\n",
    "\n",
    "        imbalance = negative_label - positive_label\n",
    "        negative_indices = np.where(self._labels == 0)[0]\n",
    "        indices_to_discard = np.random.choice(\n",
    "            negative_indices, size=imbalance, replace=False\n",
    "        )\n",
    "\n",
    "        self._features = np.delete(self._features, obj=indices_to_discard, axis=0)\n",
    "        self._labels = np.delete(self._labels, obj=indices_to_discard, axis=0)\n",
    "        self._time_labels = np.delete(self._time_labels, obj=indices_to_discard, axis=0)\n",
    "        self._edge_weights = np.delete(\n",
    "            self._edge_weights, obj=indices_to_discard, axis=0\n",
    "        )\n",
    "\n",
    "    def _get_labels_features_edge_weights(self):\n",
    "        \"\"\"Prepare features, labels, time labels and edge wieghts for training and\n",
    "        optionally validation data.\"\"\"\n",
    "        patient_list = os.listdir(self.npy_dataset_path)\n",
    "        for patient in patient_list:  # iterate over patient names\n",
    "            event_tables = self._get_event_tables(\n",
    "                patient\n",
    "            )  # extract start and stop of seizure for patient\n",
    "            patient_path = os.path.join(self.npy_dataset_path, patient)\n",
    "            recording_list = os.listdir(patient_path)\n",
    "            for record in recording_list:  # iterate over recordings for a patient\n",
    "                recording_path = os.path.join(patient_path, record)\n",
    "                record_id = record.split(\".npy\")[0]  #  get record id\n",
    "                start_event_tables = self._get_recording_events(\n",
    "                    event_tables[0], record_id\n",
    "                )  # get start events\n",
    "                stop_event_tables = self._get_recording_events(\n",
    "                    event_tables[1], record_id\n",
    "                )  # get stop events\n",
    "                data_array = np.load(recording_path)  # load the recording\n",
    "\n",
    "                plv_edge_weights = np.expand_dims(\n",
    "                    self._get_edge_weights_recording(\n",
    "                        np.load(os.path.join(self.plv_values_path, patient, record))\n",
    "                    ),\n",
    "                    axis=0,\n",
    "                )\n",
    "\n",
    "                ##TODO add a gateway to reject seizure periods shorter than lookback\n",
    "                # extract timeseries and labels from the array\n",
    "                features, labels, time_labels = utils.extract_training_data_and_labels(\n",
    "                    data_array,\n",
    "                    start_event_tables,\n",
    "                    stop_event_tables,\n",
    "                    fs=self.sampling_f,\n",
    "                    seizure_lookback=self.seizure_lookback,\n",
    "                    sample_timestep=self.sample_timestep,\n",
    "                    inter_overlap=self.inter_overlap,\n",
    "                    ictal_overlap=self.ictal_overlap,\n",
    "                    buffer_time=self.buffer_time,\n",
    "                )\n",
    "\n",
    "                if features is None:\n",
    "                    continue\n",
    "                time_labels = np.expand_dims(time_labels.astype(np.int32), 1)\n",
    "                labels = labels.reshape((labels.shape[0], 1)).astype(np.float32)\n",
    "                \"\"\"SCALING FEATURES INTO uV!!!\"\"\"\n",
    "                # features = features*(10**6)\n",
    "                \"\"\"SCALING FEATURES INTO uV!!!\"\"\"\n",
    "                if patient == self.loso_patient:\n",
    "                    try:\n",
    "                        self._val_features = np.concatenate(\n",
    "                            (self._val_features, features)\n",
    "                        )\n",
    "                        self._val_labels = np.concatenate((self._val_labels, labels))\n",
    "                        self._val_time_labels = np.concatenate(\n",
    "                            (self._val_time_labels, time_labels)\n",
    "                        )\n",
    "                        self._val_edge_weights = np.concatenate(\n",
    "                            (\n",
    "                                self._val_edge_weights,\n",
    "                                np.repeat(plv_edge_weights, features.shape[0], axis=0),\n",
    "                            )\n",
    "                        )\n",
    "                    except:\n",
    "                        self._val_features = features\n",
    "                        self._val_labels = labels\n",
    "                        self._val_time_labels = time_labels\n",
    "                        self._val_edge_weights = np.repeat(\n",
    "                            plv_edge_weights, features.shape[0], axis=0\n",
    "                        )\n",
    "                else:\n",
    "                    try:\n",
    "                        self._features = np.concatenate((self._features, features))\n",
    "                        self._labels = np.concatenate((self._labels, labels))\n",
    "                        self._time_labels = np.concatenate(\n",
    "                            (self._time_labels, time_labels)\n",
    "                        )\n",
    "                        self._edge_weights = np.concatenate(\n",
    "                            (\n",
    "                                self._edge_weights,\n",
    "                                np.repeat(plv_edge_weights, features.shape[0], axis=0),\n",
    "                            )\n",
    "                        )\n",
    "\n",
    "                    except:\n",
    "                        print(\"Creating initial attributes\")\n",
    "                        self._features = features\n",
    "                        self._labels = labels\n",
    "                        self._time_labels = time_labels\n",
    "                        self._edge_weights = np.repeat(\n",
    "                            plv_edge_weights, features.shape[0], axis=0\n",
    "                        )\n",
    "\n",
    "    # TODO define a method to create edges and calculate plv to get weights\n",
    "    def get_dataset(self) -> DynamicGraphTemporalSignal:\n",
    "\n",
    "        \"\"\"Creating graph data iterators. The iterator yelds dynamic, weighted and undirected graphs\n",
    "        containing self loops. Every node represents one electrode in EEG. The graph is fully connected,\n",
    "        edge weights are calculated for every EEG recording as PLV between channels (edge weight describes\n",
    "        the \"strength\" of connectivity between two channels in a recording). Node features are values of\n",
    "        channel voltages in time. Features are of shape [nodes,features,timesteps].\n",
    "\n",
    "        Returns:\n",
    "            train_dataset {DynamicGraphTemporalSignal} -- Training data iterator.\n",
    "            valid_dataset {DynamicGraphTemporalSignal} -- Validation data iterator (only if loso_patient is\n",
    "            specified in class constructor).\n",
    "        \"\"\"\n",
    "        ### TODO rozkminić o co chodzi z tym całym time labels - na razie wartość liczbowa która tam wchodzi\n",
    "        ### to shape atrybutu time_labels\n",
    "\n",
    "        self._get_labels_features_edge_weights()\n",
    "        self.train_features_min_max = [self._features.min(), self._features.max()]\n",
    "        if self.balance:\n",
    "            self._get_labels_count()\n",
    "            self._balance_classes()\n",
    "        self._get_edges()\n",
    "        self._get_labels_count()\n",
    "        if self.hjorth:\n",
    "            self._calculate_hjorth_features_train()\n",
    "        self._array_to_tensor()\n",
    "        if self.downsample:\n",
    "            self._downsample_features_train()\n",
    "        if self.fft:\n",
    "            self._perform_features_train_fft()\n",
    "        train_dataset = torch.utils.data.TensorDataset(\n",
    "            self._features,\n",
    "            self._edges,\n",
    "            self._edge_weights,\n",
    "            self._labels,\n",
    "            self._time_labels,\n",
    "        )\n",
    "        if self.train_test_split is not None:\n",
    "            if self.fft or self.hjorth:\n",
    "                data_list = self._features_to_data_list(\n",
    "                    self._features,self._edges,self._edge_weights, self._labels, self._time_labels\n",
    "                )\n",
    "                train_data_list, val_data_list = self._split_data_list(data_list)\n",
    "                loaders = [\n",
    "                    DataLoader(train_data_list, batch_size=self.batch_size, shuffle=True,drop_last=False),\n",
    "                    DataLoader(val_data_list, batch_size=self.batch_size, shuffle=False,drop_last=False)\n",
    "                           ]\n",
    "                \n",
    "            else:    \n",
    "                train_dataset, val_dataset = torch.utils.data.random_split(\n",
    "                    train_dataset,\n",
    "                    [1 - self.train_test_split, self.train_test_split],\n",
    "                    generator=torch.Generator().manual_seed(42),\n",
    "                )\n",
    "\n",
    "                train_dataloader = torch.utils.data.DataLoader(\n",
    "                    train_dataset,\n",
    "                    batch_size=self.batch_size,\n",
    "                    shuffle=True,\n",
    "                    num_workers=2,\n",
    "                    pin_memory=True,\n",
    "                    prefetch_factor=4,\n",
    "                    drop_last=False,\n",
    "                )\n",
    "\n",
    "                val_dataloader = torch.utils.data.DataLoader(\n",
    "                    val_dataset,\n",
    "                    batch_size=self.batch_size,\n",
    "                    shuffle=False,\n",
    "                    num_workers=2,\n",
    "                    pin_memory=True,\n",
    "                    prefetch_factor=4,\n",
    "                    drop_last=False,\n",
    "                )\n",
    "                loaders = [train_dataloader, val_dataloader]\n",
    "        else:\n",
    "            if self.fft or self.hjorth:\n",
    "                train_data_list = self._features_to_data_list(\n",
    "                    self._features,self._edges,self._edge_weights, self._labels, self._time_labels\n",
    "                )\n",
    "                loaders = [DataLoader(train_data_list, batch_size=self.batch_size, shuffle=True,drop_last=False)]\n",
    "            else:\n",
    "                train_dataloader = torch.utils.data.DataLoader(\n",
    "                    train_dataset,\n",
    "                    batch_size=self.batch_size,\n",
    "                    shuffle=True,\n",
    "                    num_workers=2,\n",
    "                    pin_memory=True,\n",
    "                    prefetch_factor=4,\n",
    "                    drop_last=False,\n",
    "                )\n",
    "                loaders = [train_dataloader]\n",
    "        if self.loso_patient:\n",
    "            self.val_features_min_max = [\n",
    "                self._val_features.min(),\n",
    "                self._val_features.max(),\n",
    "            ]\n",
    "            self._get_val_labels_count()\n",
    "            if self.hjorth:\n",
    "                self._calculate_hjorth_features_val()\n",
    "            self._val_array_to_tensor()\n",
    "            if self.downsample:\n",
    "                self._downsample_features_val()\n",
    "            if self.fft:\n",
    "                self._perform_features_val_fft()\n",
    "            if self.fft or self.hjorth:\n",
    "                loso_data_list = self._features_to_data_list(\n",
    "                    self._val_features,self._val_edges,self._val_edge_weights, self._val_labels, self._val_time_labels\n",
    "                )\n",
    "                return (*loaders, DataLoader(loso_data_list, batch_size=self.batch_size, shuffle=False,drop_last=False))\n",
    "            loso_dataset = torch.utils.data.TensorDataset(\n",
    "                self._val_features,\n",
    "                self._val_edges,\n",
    "                self._val_edge_weights,\n",
    "                self._val_labels,\n",
    "                self._val_time_labels,\n",
    "            )\n",
    "            loso_dataloader = torch.utils.data.DataLoader(\n",
    "                loso_dataset,\n",
    "                batch_size=self.batch_size,\n",
    "                shuffle=False,\n",
    "                pin_memory=True,\n",
    "                num_workers=2,\n",
    "                prefetch_factor=4,\n",
    "                drop_last=False,\n",
    "            )\n",
    "            return (*loaders, loso_dataloader)\n",
    "\n",
    "        return (*loaders,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecurrentGCN(torch.nn.Module):\n",
    "    def __init__(self, timestep,sfreq, n_nodes=18,batch_size=32):\n",
    "        super(RecurrentGCN, self).__init__()\n",
    "        self.n_nodes = n_nodes\n",
    "        self.out_features = 128\n",
    "        self.recurrent_1 = GCNConv(sfreq*timestep,32, add_self_loops=True,improved=False)\n",
    "        self.recurrent_2 = GCNConv(32,64,add_self_loops=True,improved=False)\n",
    "        self.recurrent_3 = GCNConv(64,128,add_self_loops=True,improved=False)\n",
    "        self.fc1 = torch.nn.Linear(n_nodes*128, 64)\n",
    "        self.fc2 = torch.nn.Linear(64, 32)\n",
    "        self.fc3 = torch.nn.Linear(32, 16)\n",
    "        self.fc4 = torch.nn.Linear(16, 1)\n",
    "        self.flatten = torch.nn.Flatten(start_dim=0)\n",
    "        self.dropout = torch.nn.Dropout()\n",
    "    def forward(self, x, edge_index,edge_weight):\n",
    "        x = torch.squeeze(x)\n",
    "        h = self.recurrent_1(x, edge_index=edge_index, edge_weight = edge_weight)\n",
    "        h = torch.nn.BatchNorm1d(32)(h)\n",
    "        h = F.leaky_relu(h)\n",
    "        h = self.recurrent_2(h, edge_index,edge_weight)\n",
    "        h = torch.nn.BatchNorm1d(64)(h)\n",
    "        h = F.leaky_relu(h)\n",
    "        h = self.recurrent_3(h, edge_index,edge_weight)\n",
    "        h = torch.nn.BatchNorm1d(128)(h)\n",
    "        h = F.leaky_relu(h)\n",
    "        h = self.flatten(h)\n",
    "        \n",
    "        h = self.dropout(h)\n",
    "        h = self.fc1(h)\n",
    "        h = F.leaky_relu(h)\n",
    "        h = self.dropout(h)\n",
    "        h = self.fc2(h)\n",
    "        h = F.leaky_relu(h)\n",
    "        h = self.dropout(h)\n",
    "        h = self.fc3(h)\n",
    "        h = F.leaky_relu(h)\n",
    "        h = self.dropout(h)\n",
    "        h = self.fc4(h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GATv2(torch.nn.Module):\n",
    "    def __init__(self, timestep,sfreq, n_nodes=18,batch_size=32):\n",
    "        super(GATv2, self).__init__()\n",
    "        self.n_nodes = n_nodes\n",
    "        self.out_features = 128\n",
    "        self.recurrent_1 = GATv2Conv(sfreq*timestep,32,heads=6, add_self_loops=True,improved=False,edge_dim=1)\n",
    "\n",
    "        self.fc1 = torch.nn.Linear(3456, 1024)\n",
    "        self.fc2 = torch.nn.Linear(1024, 512)\n",
    "        self.fc3 = torch.nn.Linear(512, 128)\n",
    "        self.fc4 = torch.nn.Linear(128, 1)\n",
    "        self.flatten = torch.nn.Flatten(start_dim=0)\n",
    "        self.dropout = torch.nn.Dropout()\n",
    "    def forward(self, x, edge_index,edge_weight):\n",
    "        x = torch.squeeze(x)\n",
    "        h = self.recurrent_1(x, edge_index=edge_index, edge_attr = edge_weight)\n",
    "        \n",
    "        h = torch.nn.BatchNorm1d(192)(h)\n",
    "        h = F.leaky_relu(h)\n",
    "        h = self.flatten(h)\n",
    "        h = self.dropout(h)\n",
    "        h = self.fc1(h)\n",
    "        h = F.leaky_relu(h)\n",
    "        h = self.dropout(h)\n",
    "        h = self.fc2(h)\n",
    "        h = F.leaky_relu(h)\n",
    "        h = self.dropout(h)\n",
    "        h = self.fc3(h)\n",
    "        h = F.leaky_relu(h)\n",
    "        h = self.dropout(h)\n",
    "        h = self.fc4(h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating initial attributes\n"
     ]
    }
   ],
   "source": [
    "TIMESTEP = 3\n",
    "INTER_OVERLAP = 0\n",
    "ICTAL_OVERLAP = 0\n",
    "SFREQ = 256\n",
    "\n",
    "dataloader = SeizureDataLoader(\n",
    "    npy_dataset_path=Path('data/npy_data'),\n",
    "    event_tables_path=Path('data/event_tables'),\n",
    "    plv_values_path=Path('data/plv_arrays'),\n",
    "    loso_patient='chb16',\n",
    "    sampling_f=SFREQ,\n",
    "    seizure_lookback=600,\n",
    "    sample_timestep= TIMESTEP,\n",
    "    inter_overlap=INTER_OVERLAP,\n",
    "    ictal_overlap=ICTAL_OVERLAP,\n",
    "    self_loops=False,\n",
    "    balance=False,\n",
    "    train_test_split=0.2,\n",
    "    fft=True,\n",
    "    hjorth=False,\n",
    "    downsample=60\n",
    "    \n",
    "    )\n",
    "train_loader,val_dataloader,loso_loader=dataloader.get_dataset()\n",
    "alpha = list(dataloader._label_counts.values())[0]/list(dataloader._label_counts.values())[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = len(dataloader._features)\n",
    "sample_edge_indexes = dataloader._edges[0:32]\n",
    "sample_edge_weights = dataloader._edge_weights[0:32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = [Data(x=dataloader._features[i],y=dataloader._labels[i],edge_index=dataloader._edges[i],edge_weight=dataloader._edge_weights[i]) for i in range(n_samples)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch.utils.data.dataset import Subset\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "# Assuming `data_list` is a list of PyTorch Geometric data objects, and `num_classes` is the total number of classes.\n",
    "\n",
    "# Create an array of class labels for each data object.\n",
    "class_labels = [data.y.item() for data in data_list]\n",
    "\n",
    "# Use StratifiedShuffleSplit to split the data into train and validation sets while maintaining class balance.\n",
    "splitter = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "train_indices, val_indices = next(splitter.split(data_list, class_labels))\n",
    "\n",
    "# Use SubsetRandomSampler to split the data into training and validation subsets.\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "val_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "# Create DataLoader objects for the training and validation sets.\n",
    "train_loader = DataLoader(data_list, batch_size=32, sampler=train_sampler)\n",
    "val_loader = DataLoader(data_list, batch_size=32, sampler=val_sampler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = [data.y.item() for data in data_list]\n",
    "splitter = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "train_indices, val_indices = next(splitter.split(data_list, class_labels))\n",
    "data_list_train = [data_list[i] for i in train_indices]\n",
    "dataset_list_val = [data_list[i] for i in val_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 1.]), array([24250,  2866]))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique([data.y.item() for data in data_list_train],return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 1.]), array([6062,  717]))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique([data.y.item() for data in dataset_list_val],return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.sampler.SubsetRandomSampler at 0x7f8e4b24ab90>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "geom_dloader = DataLoader(data_list,batch_size=8,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataBatch(x=[576, 1, 180], edge_index=[2, 10368], y=[32], edge_weight=[10368], batch=[576], ptr=[33])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LightningGATv2(pl.LightningModule):\n",
    "    def __init__(self, timestep,sfreq,alpha):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            GATv2Conv(sfreq*timestep,32,heads=6, add_self_loops=True,improved=False),\n",
    "            nn.BatchNorm1d(192),\n",
    "            nn.Flatten(start_dim=0),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(3456, 1024),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(128, 1)\n",
    "        )   \n",
    "        self.criterion = torch.nn.BCEWithLogitsLoss()\n",
    "        self.alpha = alpha\n",
    "        self.save_hyperparameters()\n",
    "        self.recall = BinaryRecall(threshold=0.5)\n",
    "        self.specificity = BinarySpecificity(threshold=0.6)\n",
    "        self.auroc = AUROC(task=\"binary\")\n",
    "    def forward(self, x, edge_index,edge_weight):\n",
    "        x = torch.squeeze(x)\n",
    "        return self.model(x, edge_index,edge_weight)\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, edge_index, edge_weight, y = batch[0:4]\n",
    "        y_hat = self(x, edge_index,edge_weight)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        self.log('train_loss', loss)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n",
      "torch.Size([3456])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/13 [00:03<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3456])"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 35\u001b[0m\n\u001b[1;32m     31\u001b[0m x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39msqueeze()\n\u001b[1;32m     32\u001b[0m x \u001b[39m=\u001b[39m (x\u001b[39m-\u001b[39mx\u001b[39m.\u001b[39mmean(dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m))\u001b[39m/\u001b[39mx\u001b[39m.\u001b[39mstd(dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m     34\u001b[0m y_hat \u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mstack(\n\u001b[0;32m---> 35\u001b[0m         [model(x\u001b[39m=\u001b[39mx[n], edge_index\u001b[39m=\u001b[39medge_index[n], edge_weight\u001b[39m=\u001b[39medge_attr[n]\u001b[39m.\u001b[39mfloat()) \n\u001b[1;32m     36\u001b[0m          \u001b[39mfor\u001b[39;00m n \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(x\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m])])\n\u001b[1;32m     37\u001b[0m \u001b[39m##loss\u001b[39;00m\n\u001b[1;32m     39\u001b[0m loss \u001b[39m=\u001b[39m loss_fn(y_hat,y)\n",
      "Cell \u001b[0;32mIn[16], line 35\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     31\u001b[0m x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39msqueeze()\n\u001b[1;32m     32\u001b[0m x \u001b[39m=\u001b[39m (x\u001b[39m-\u001b[39mx\u001b[39m.\u001b[39mmean(dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m))\u001b[39m/\u001b[39mx\u001b[39m.\u001b[39mstd(dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m     34\u001b[0m y_hat \u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mstack(\n\u001b[0;32m---> 35\u001b[0m         [model(x\u001b[39m=\u001b[39;49mx[n], edge_index\u001b[39m=\u001b[39;49medge_index[n], edge_weight\u001b[39m=\u001b[39;49medge_attr[n]\u001b[39m.\u001b[39;49mfloat()) \n\u001b[1;32m     36\u001b[0m          \u001b[39mfor\u001b[39;00m n \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(x\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m])])\n\u001b[1;32m     37\u001b[0m \u001b[39m##loss\u001b[39;00m\n\u001b[1;32m     39\u001b[0m loss \u001b[39m=\u001b[39m loss_fn(y_hat,y)\n",
      "File \u001b[0;32m~/code/sano/sano_eeg/sano_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[15], line 21\u001b[0m, in \u001b[0;36mGATv2.forward\u001b[0;34m(self, x, edge_index, edge_weight)\u001b[0m\n\u001b[1;32m     19\u001b[0m h \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mleaky_relu(h)\n\u001b[1;32m     20\u001b[0m h \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mflatten(h)\n\u001b[0;32m---> 21\u001b[0m \u001b[39mprint\u001b[39;49m(h\u001b[39m.\u001b[39;49mshape)\n\u001b[1;32m     22\u001b[0m h \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(h)\n\u001b[1;32m     23\u001b[0m h \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc1(h)\n",
      "File \u001b[0;32m~/code/sano/sano_eeg/sano_env/lib/python3.10/site-packages/ipykernel/iostream.py:574\u001b[0m, in \u001b[0;36mOutStream.write\u001b[0;34m(self, string)\u001b[0m\n\u001b[1;32m    572\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpub_thread\u001b[39m.\u001b[39mschedule(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flush)\n\u001b[1;32m    573\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 574\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_schedule_flush()\n\u001b[1;32m    576\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mlen\u001b[39m(string)\n",
      "File \u001b[0;32m~/code/sano/sano_eeg/sano_env/lib/python3.10/site-packages/ipykernel/iostream.py:478\u001b[0m, in \u001b[0;36mOutStream._schedule_flush\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    475\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_schedule_in_thread\u001b[39m():\n\u001b[1;32m    476\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_io_loop\u001b[39m.\u001b[39mcall_later(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mflush_interval, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flush)\n\u001b[0;32m--> 478\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpub_thread\u001b[39m.\u001b[39;49mschedule(_schedule_in_thread)\n",
      "File \u001b[0;32m~/code/sano/sano_eeg/sano_env/lib/python3.10/site-packages/ipykernel/iostream.py:211\u001b[0m, in \u001b[0;36mIOPubThread.schedule\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_events\u001b[39m.\u001b[39mappend(f)\n\u001b[1;32m    210\u001b[0m     \u001b[39m# wake event thread (message content is ignored)\u001b[39;00m\n\u001b[0;32m--> 211\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_event_pipe\u001b[39m.\u001b[39;49msend(\u001b[39mb\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m    212\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    213\u001b[0m     f()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/zmq/sugar/socket.py:620\u001b[0m, in \u001b[0;36mSocket.send\u001b[0;34m(self, data, flags, copy, track, routing_id, group)\u001b[0m\n\u001b[1;32m    613\u001b[0m         data \u001b[39m=\u001b[39m zmq\u001b[39m.\u001b[39mFrame(\n\u001b[1;32m    614\u001b[0m             data,\n\u001b[1;32m    615\u001b[0m             track\u001b[39m=\u001b[39mtrack,\n\u001b[1;32m    616\u001b[0m             copy\u001b[39m=\u001b[39mcopy \u001b[39mor\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    617\u001b[0m             copy_threshold\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcopy_threshold,\n\u001b[1;32m    618\u001b[0m         )\n\u001b[1;32m    619\u001b[0m     data\u001b[39m.\u001b[39mgroup \u001b[39m=\u001b[39m group\n\u001b[0;32m--> 620\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49msend(data, flags\u001b[39m=\u001b[39;49mflags, copy\u001b[39m=\u001b[39;49mcopy, track\u001b[39m=\u001b[39;49mtrack)\n",
      "File \u001b[0;32mzmq/backend/cython/socket.pyx:746\u001b[0m, in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mzmq/backend/cython/socket.pyx:793\u001b[0m, in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mzmq/backend/cython/socket.pyx:250\u001b[0m, in \u001b[0;36mzmq.backend.cython.socket._send_copy\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/zmq/backend/cython/checkrc.pxd:13\u001b[0m, in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## normal loop\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "model = GATv2(TIMESTEP,60,batch_size=16).to(device)\n",
    "loss_fn =  nn.BCEWithLogitsLoss(pos_weight=torch.full([1], alpha))\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.001)\n",
    "recall = BinaryRecall(threshold=0.5)\n",
    "specificity = BinarySpecificity(threshold=0.6)\n",
    "auroc = AUROC(task=\"binary\")\n",
    "roc = ROC('binary')\n",
    "model.train()\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min',patience=2)\n",
    "\n",
    "for epoch in tqdm(range(13)):\n",
    "\n",
    "    \n",
    "        epoch_loss = 0.0\n",
    "        epoch_loss_valid = 0.0\n",
    "        model.train()\n",
    "        sample_counter = 0\n",
    "        batch_counter = 0\n",
    "        print(get_lr(optimizer))\n",
    "        for time, batch in enumerate(train_loader): ## TODO - this thing is still operating with no edge weights!!!\n",
    "                ## find a way to compute plv per batch fast (is it even possible?)\n",
    "        \n",
    "                x, edge_index, edge_attr,y = batch[0:4]\n",
    "               \n",
    "                signal_samples = x.shape[3]\n",
    "                x = 2 / signal_samples * torch.abs(x)\n",
    "            \n",
    "                x = x.squeeze()\n",
    "                x = (x-x.mean(dim=0))/x.std(dim=0)\n",
    "           \n",
    "                y_hat =torch.stack(\n",
    "                        [model(x=x[n], edge_index=edge_index[n], edge_weight=edge_attr[n].float()) \n",
    "                         for n in range(x.shape[0])])\n",
    "                ##loss\n",
    "        \n",
    "                loss = loss_fn(y_hat,y)\n",
    "                #loss = torchvision.ops.sigmoid_focal_loss(y_hat,y,alpha=alpha*0.1,gamma=2,reduction='mean')\n",
    "                epoch_loss += loss\n",
    "                ## get preds & gorund truth\n",
    "                try:\n",
    "                 preds = torch.cat([preds,y_hat],dim=0)\n",
    "                 ground_truth = torch.cat([ground_truth,y],dim=0)\n",
    "            \n",
    "                except:\n",
    "                 preds= y_hat.detach()\n",
    "                 ground_truth = y\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        ## calculate acc\n",
    "\n",
    "        train_auroc = auroc(preds,ground_truth)\n",
    "        sensitivity = recall(preds,ground_truth)\n",
    "        train_specificity = specificity(preds,ground_truth)\n",
    "        del preds, ground_truth\n",
    "        print(f'Epoch: {epoch}',f'Epoch sensitivity: {sensitivity}', f'Epoch loss: {epoch_loss.detach().numpy()/time+1}')\n",
    "        print(f'Epoch specificity: {train_specificity}')\n",
    "        print(f'Epoch AUROC: {train_auroc} ')\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "                for time_valid, batch_valid in enumerate(val_dataloader):\n",
    "                        x, edge_index, edge_attr,y_val = batch_valid[0:4]\n",
    "                    \n",
    "                        signal_samples = x.shape[3]\n",
    "                        x = 2 / signal_samples * torch.abs(x)\n",
    "              \n",
    "                        x = x.squeeze()\n",
    "                      \n",
    "                        x = (x-x.mean(dim=0))/x.std(dim=0)\n",
    "                        \n",
    "                        y_hat_val = torch.stack(\n",
    "                                [model(x=x[n], edge_index=edge_index[n], edge_weight=edge_attr[n].float()) \n",
    "                                 for n in range(x.shape[0])])\n",
    "                        loss_valid = loss_fn(y_hat_val,y_val)\n",
    "                        #loss_valid = torchvision.ops.sigmoid_focal_loss(y_hat,y,alpha=alpha*0.1,gamma=2,reduction='mean')\n",
    "                        epoch_loss_valid += loss_valid\n",
    "                        try:\n",
    "                         preds_valid = torch.cat([preds_valid,y_hat_val],dim=0)\n",
    "                         ground_truth_valid = torch.cat([ground_truth_valid,y_val],dim=0)\n",
    "                        except:\n",
    "                         preds_valid= y_hat_val\n",
    "                         ground_truth_valid = y_val\n",
    "        scheduler.step(epoch_loss_valid)\n",
    "        val_auroc = auroc(preds_valid,ground_truth_valid)\n",
    "        val_sensitivity = recall(preds_valid,ground_truth_valid)\n",
    "        val_specificity = specificity(preds_valid,ground_truth_valid)\n",
    "        del preds_valid, ground_truth_valid\n",
    "        print(f'Epoch: {epoch}',f'Epoch val_sensitivity: {val_sensitivity}', f'Epoch val_loss: {epoch_loss_valid.detach().numpy()/time_valid+1}')\n",
    "        print(f'Epoch val specificity: {train_specificity}')\n",
    "        print(f'Epoch val AUROC: {val_specificity} ')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "88cc438b9c90976695678f0d6c20e4c06983b5710e6855b5b4390f60ecf93fe8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
