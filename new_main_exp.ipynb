{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import os\n",
    "from dataclasses import dataclass, field\n",
    "import utils\n",
    "\n",
    "# from torch_geometric_temporal import  DynamicGraphTemporalSignal,StaticGraphTemporalSignal, temporal_signal_split, DynamicGraphTemporalSignalBatch\n",
    "import networkx as nx\n",
    "from torch_geometric.utils import from_networkx\n",
    "import scipy\n",
    "import sklearn\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torchvision.ops import sigmoid_focal_loss\n",
    "\n",
    "# from torch_geometric_temporal.nn.recurrent import DCRNN,  GConvGRU, A3TGCN, TGCN2, TGCN, A3TGCN2\n",
    "# from torch_geometric_temporal.nn.attention import STConv\n",
    "from torchmetrics.classification import BinaryRecall, BinarySpecificity, AUROC, ROC\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "import pytorch_lightning as pl\n",
    "from torch_geometric.nn import GCNConv, BatchNorm, GATv2Conv\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from mne_features.univariate import (\n",
    "    compute_variance,\n",
    "    compute_hjorth_complexity,\n",
    "    compute_hjorth_mobility,\n",
    "    compute_line_length,\n",
    "    compute_higuchi_fd,\n",
    "    compute_katz_fd,\n",
    ")\n",
    "import mne_features\n",
    "import torch_geometric\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "from librosa import zero_crossings\n",
    "from scipy.signal import find_peaks, peak_prominences\n",
    "from statistics import mean\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_geometric.seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO think about using kwargs argument here to specify args for dataloader\n",
    "@dataclass\n",
    "class SeizureDataLoader:\n",
    "    npy_dataset_path: Path\n",
    "    event_tables_path: Path\n",
    "    plv_values_path: Path\n",
    "    loso_patient: str = None\n",
    "    sampling_f: int = 256\n",
    "    seizure_lookback: int = 600\n",
    "    sample_timestep: int = 5\n",
    "    inter_overlap: int = 0\n",
    "    preictal_overlap: int = 0\n",
    "    ictal_overlap: int = 0\n",
    "    self_loops: bool = True\n",
    "    balance: bool = True\n",
    "    train_test_split: float = None\n",
    "    fft: bool = False\n",
    "    hjorth: bool = False\n",
    "    downsample: int = None\n",
    "    buffer_time: int = 15\n",
    "    batch_size: int = 32\n",
    "    smote: bool = False\n",
    "    used_classes_dict: dict[str] = field(default_factory=lambda: {\"interictal\": True, \"preictal\": True, \"ictal\": True})\n",
    "    \"\"\"Class to prepare dataloaders for eeg seizure perdiction from stored files.\n",
    "\n",
    "    Attributes:\n",
    "        npy_dataset_path: (Path) Path to directory with .npy files\n",
    "        event_tables_path: (Path) Path to directory with .csv files\n",
    "        plv_values_path: (Path) Path to directory with .npy files\n",
    "        loso_patient: (str) Patient name to be left out of training set.\n",
    "    If None, no patient is left out for testing. (default: None)\n",
    "        sampling_f: (int) Sampling frequency of the recordings. (default: 256)\n",
    "        seizure_lookback: (int) Time in seconds to look back from seizure onset. (default: 600)\n",
    "        sample_timestep: (int) Time in seconds between samples. (default: 5)\n",
    "        inter_overlap: (int) Time in seconds to overlap between interictal samples. (default: 0)\n",
    "        preictal_overlap: (int) Time in seconds to overlap between preictal samples. (default: 0)\n",
    "        ictal_overlap: (int) Time in seconds to overlap between ictal samples. (default: 0)\n",
    "        self_loops: (bool) Whether to add self loops to the graph. (default: True)\n",
    "        balance: (bool) Whether to balance the classes. (default: True)\n",
    "        train_test_split: (float) Percentage of data to be used for testing. (default: None)\n",
    "        fft: (bool) Whether to use fft features. (default: False)\n",
    "        hjorth: (bool) Whether to use hjorth features. (default: False)\n",
    "        downsample: (int) Factor by which to downsample the data. (default: None)\n",
    "        buffer_time: (int) Time in seconds to skip before and after every sample from seizure period. \n",
    "    (default: 15)\n",
    "        batch_size: (int) Batch size for dataloaders. (default: 32)\n",
    "        smote: (bool) Whether to use smote to balance the classes. (default: False)\n",
    "        used_classes_ditct: (dict) Dictionary with classes to be used. \n",
    "    (default: {'interictal': True, 'preictal': True, 'ictal': True})\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    # if used_classes_dict is None:\n",
    "    #     used_classes_dict = {\"interictal\": True, \"preictal\": True, \"ictal\": True}\n",
    "    assert (fft and hjorth) == False, \"When fft is True, hjorth should be False\"\n",
    "    assert (downsample is None) or (\n",
    "        downsample > 0\n",
    "    ), \"Downsample should be None or positive integer\"\n",
    "    assert (train_test_split is None) or (\n",
    "        train_test_split > 0 and train_test_split < 1\n",
    "    ), \"Train test split should be None or float between 0 and 1\"\n",
    "    \n",
    "\n",
    "    def _get_event_tables(self, patient_name: str) -> tuple[dict, dict]:\n",
    "        \"\"\"Read events for given patient into start and stop times lists from .csv extracted files.\n",
    "        Args:\n",
    "            patient_name: (str) Name of the patient to get events for.\n",
    "        Returns:\n",
    "            start_events_dict: (dict) Dictionary with start events for given patient.\n",
    "            stop_events_dict: (dict) Dictionary with stop events for given patient.\n",
    "        \"\"\"\n",
    "\n",
    "        event_table_list = os.listdir(self.event_tables_path)\n",
    "        patient_event_tables = [\n",
    "            os.path.join(self.event_tables_path, ev_table)\n",
    "            for ev_table in event_table_list\n",
    "            if patient_name in ev_table\n",
    "        ]\n",
    "        patient_event_tables = sorted(patient_event_tables)\n",
    "        patient_start_table = patient_event_tables[\n",
    "            0\n",
    "        ]  ## done terribly, but it has to be so for win/linux compat\n",
    "        patient_stop_table = patient_event_tables[1]\n",
    "        start_events_dict = pd.read_csv(patient_start_table).to_dict(\"index\")\n",
    "        stop_events_dict = pd.read_csv(patient_stop_table).to_dict(\"index\")\n",
    "        return start_events_dict, stop_events_dict\n",
    "\n",
    "    def _get_recording_events(self, events_dict, recording) -> list[int]:\n",
    "        \"\"\"Read seizure times into list from event_dict.\n",
    "        Args:\n",
    "            events_dict: (dict) Dictionary with events for given patient.\n",
    "            recording: (str) Name of the recording to get events for.\n",
    "        Returns:\n",
    "            recording_events: (list) List of seizure event start and stop time for given recording.\n",
    "        \"\"\"\n",
    "        recording_list = list(events_dict[recording + \".edf\"].values())\n",
    "        recording_events = [int(x) for x in recording_list if not np.isnan(x)]\n",
    "        return recording_events\n",
    "\n",
    "    def _get_graph(self, n_nodes: int) -> nx.Graph:\n",
    "        \"\"\"Creates Networx complete graph with self loops\n",
    "        for given number of nodes.\n",
    "        Args:\n",
    "            n_nodes: (int) Number of nodes in the graph.\n",
    "        Returns:\n",
    "            graph: (nx.Graph) Fully connected graph with self loops.\n",
    "        \"\"\"\n",
    "        graph = nx.complete_graph(n_nodes)\n",
    "        self_loops = [[node, node] for node in graph.nodes()]\n",
    "        graph.add_edges_from(self_loops)\n",
    "        return graph\n",
    "\n",
    "    def _get_edge_weights_recording(self, plv_values: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Method for extracting PLV values associated with given edges for a recording.\n",
    "        The PLV was computed for the entire recroding for all channels when the recording was\n",
    "        processed.\n",
    "        Args:\n",
    "            plv_values: (np.ndarray) Array with PLV values for given recording.\n",
    "        Returns:\n",
    "            edge_weights: (np.ndarray) Array with PLV values for given edges.\n",
    "        \"\"\"\n",
    "        graph = self._get_graph(plv_values.shape[0])\n",
    "        garph_dict = {}\n",
    "        for edge in graph.edges():\n",
    "            e_start, e_end = edge\n",
    "            garph_dict[edge] = {\"plv\": plv_values[e_start, e_end]}\n",
    "        nx.set_edge_attributes(graph, garph_dict)\n",
    "        edge_weights = from_networkx(graph).plv.numpy()\n",
    "        return edge_weights\n",
    "\n",
    "    def _get_edges(self):\n",
    "        \"\"\"Method to assign edge attributes. Has to be called AFTER get_dataset() method.\"\"\"\n",
    "        graph = self._get_graph(self._features.shape[1])\n",
    "        edges = np.expand_dims(from_networkx(graph).edge_index.numpy(), axis=0)\n",
    "        edges_per_sample_train = np.repeat(\n",
    "            edges, repeats=self._features.shape[0], axis=0\n",
    "        )\n",
    "        self._edges = torch.tensor(edges_per_sample_train)\n",
    "        if self.loso_patient is not None:\n",
    "            edges_per_sample_val = np.repeat(\n",
    "                edges, repeats=self._val_features.shape[0], axis=0\n",
    "            )\n",
    "            self._val_edges = torch.tensor(edges_per_sample_val)\n",
    "\n",
    "    def _array_to_tensor(self):\n",
    "        \"\"\"Method converting features, edges and weights to torch.tensors\"\"\"\n",
    "\n",
    "        self._features = torch.from_numpy(self._features)\n",
    "        self._labels = torch.from_numpy(self._labels)\n",
    "        # self._time_labels = torch.from_numpy(self._time_labels)\n",
    "        # self._edge_weights = torch.from_numpy(self._edge_weights)\n",
    "        if self.loso_patient is not None:\n",
    "            self._val_features = torch.from_numpy(self._val_features)\n",
    "            self._val_labels = torch.from_numpy(self._val_labels)\n",
    "            # self._val_time_labels = torch.from_numpy(self._val_time_labels)\n",
    "            # self._val_edge_weights = torch.from_numpy(self._val_edge_weights)\n",
    "\n",
    "    def _get_labels_count(self):\n",
    "        \"\"\"Convenience method to get counts of labels in the dataset.\"\"\"\n",
    "        labels, counts = np.unique(self._labels, return_counts=True)\n",
    "        self._label_counts = {}\n",
    "        for n, label in enumerate(labels):\n",
    "            self._label_counts[int(label)] = counts[n]\n",
    "        if self.loso_patient is not None:\n",
    "            labels, counts = np.unique(self._val_labels, return_counts=True)\n",
    "            self._val_label_counts = {}\n",
    "            for n, label in enumerate(labels):\n",
    "                self._val_label_counts[int(label)] = counts[n]\n",
    "\n",
    "    def _calculate_hjorth_features(self, features):\n",
    "        \"\"\"Converting features to Hjorth features.\n",
    "        Args:\n",
    "            features: (np.ndarray) Array with features to be converted.\n",
    "        Returns:\n",
    "            new_features: (np.ndarray) Array with Hjorth features.\n",
    "        \"\"\"\n",
    "        new_features = np.array(\n",
    "            [\n",
    "                np.concatenate(\n",
    "                    [\n",
    "                        np.expand_dims(compute_variance(feature), 1),\n",
    "                        np.expand_dims(compute_hjorth_mobility(feature), 1),\n",
    "                        np.expand_dims(compute_hjorth_complexity(feature), 1),\n",
    "                        np.expand_dims(compute_line_length(feature), 1),\n",
    "                        # np.expand_dims(compute_katz_fd(feature), 1),\n",
    "                    ],\n",
    "                    axis=1,\n",
    "                )\n",
    "                for feature in features\n",
    "            ]\n",
    "        )\n",
    "        return new_features\n",
    "\n",
    "    def _features_to_data_list(self, features, edges, labels):\n",
    "        \"\"\"Converts features, edges and labels to list of torch_geometric.data.Data objects.\n",
    "        Args:\n",
    "            features: (np.ndarray) Array with features.\n",
    "            edges: (np.ndarray) Array with edges.\n",
    "            labels: (np.ndarray) Array with labels.\n",
    "        Returns:\n",
    "            data_list: (list) List of torch_geometric.data.Data objects.\n",
    "        \"\"\"\n",
    "        data_list = [\n",
    "            Data(\n",
    "                x=features[i],\n",
    "                edge_index=edges[i],\n",
    "                # edge_attr=edge_weights[i],\n",
    "                y=labels[i],\n",
    "                # time=time_label[i],\n",
    "            )\n",
    "            for i in range(len(features))\n",
    "        ]\n",
    "        return data_list\n",
    "\n",
    "    def _split_data_list(self, data_list):\n",
    "        \"\"\"Methods for splitting list of torch_geometric.data.Data objects into train and validation sets.\n",
    "        Uses StratifiedShuffleSplit to ensure that the classes are balanced in both sets.\n",
    "        Args:\n",
    "            data_list: (list) List of torch_geometric.data.Data objects.\n",
    "        Returns:\n",
    "            data_list_train: (list) List of torch_geometric.data.Data objects for training.\n",
    "            dataset_list_val: (list) List of torch_geometric.data.Data objects for validation.\n",
    "        \"\"\"\n",
    "        class_labels = torch.tensor(\n",
    "            [data.y.item() for data in data_list], dtype=torch.float32\n",
    "        ).unsqueeze(1)\n",
    "        patient_labels = torch.tensor(\n",
    "            np.expand_dims(self._patient_number, 1), dtype=torch.float32\n",
    "        )\n",
    "        class_labels_patient_labels = torch.cat([class_labels, patient_labels], dim=1)\n",
    "        splitter = StratifiedShuffleSplit(\n",
    "            n_splits=1, test_size=self.train_test_split, random_state=42\n",
    "        )\n",
    "        train_indices, val_indices = next(\n",
    "            splitter.split(data_list, class_labels_patient_labels)\n",
    "        )\n",
    "        self._indexes_to_later_delete = {\"train\": train_indices, \"val\": val_indices}\n",
    "        data_list_train = [data_list[i] for i in train_indices]\n",
    "        dataset_list_val = [data_list[i] for i in val_indices]\n",
    "        return data_list_train, dataset_list_val\n",
    "\n",
    "    def _initialize_dicts(self):\n",
    "        \"\"\"Temporary method to initialize dictionaries for storing features, labels, etc.\n",
    "        Looks terrible, but convenient so far.\n",
    "        \"\"\"\n",
    "        self._features_dict = {}\n",
    "        self._labels_dict = {}\n",
    "        self._time_labels_dict = {}\n",
    "        self._edge_weights_dict = {}\n",
    "        self._patient_number_dict = {}\n",
    "        if self.loso_patient:\n",
    "            self._val_features_dict = {}\n",
    "            self._val_labels_dict = {}\n",
    "            self._val_time_labels_dict = {}\n",
    "            self._val_edge_weights_dict = {}\n",
    "            self._val_patient_number_dict = {}\n",
    "\n",
    "    def _convert_dict_to_array(self):\n",
    "        \"\"\"A method to convert dictionaries to numpy arrays. This approach with dicts is redundant,\n",
    "        but allows for joblib parallelization for data loading by not using concatenation in the loading loop.\n",
    "        \"\"\"\n",
    "        self._features = np.concatenate(\n",
    "            [self._features_dict[key] for key in self._features_dict.keys()]\n",
    "        )\n",
    "        del self._features_dict\n",
    "        self._labels = np.concatenate(\n",
    "            [self._labels_dict[key] for key in self._labels_dict.keys()]\n",
    "        )\n",
    "        del self._labels_dict\n",
    "        # self._time_labels = np.concatenate(\n",
    "        #     [self._time_labels_dict[key] for key in self._time_labels_dict.keys()]\n",
    "        # )\n",
    "        # del self._time_labels_dict\n",
    "        # self._edge_weights = np.concatenate(\n",
    "        #     [self._edge_weights_dict[key] for key in self._edge_weights_dict.keys()]\n",
    "        # )\n",
    "        # del self._edge_weights_dict\n",
    "        self._patient_number = np.concatenate(\n",
    "            [self._patient_number_dict[key] for key in self._patient_number_dict.keys()]\n",
    "        )\n",
    "        del self._patient_number_dict\n",
    "        if self.loso_patient:\n",
    "            self._val_features = np.concatenate(\n",
    "                [self._val_features_dict[key] for key in self._val_features_dict.keys()]\n",
    "            )\n",
    "            del self._val_features_dict\n",
    "            self._val_labels = np.concatenate(\n",
    "                [self._val_labels_dict[key] for key in self._val_labels_dict.keys()]\n",
    "            )\n",
    "            del self._val_labels_dict\n",
    "            # self._val_time_labels = np.concatenate(\n",
    "            #     [\n",
    "            #         self._val_time_labels_dict[key]\n",
    "            #         for key in self._val_time_labels_dict.keys()\n",
    "            #     ]\n",
    "            # )\n",
    "            # del self._val_time_labels_dict\n",
    "            # self._val_edge_weights = np.concatenate(\n",
    "            #     [\n",
    "            #         self._val_edge_weights_dict[key]\n",
    "            #         for key in self._val_edge_weights_dict.keys()\n",
    "            #     ]\n",
    "            # )\n",
    "            # del self._val_edge_weights_dict\n",
    "            self._val_patient_number = np.concatenate(\n",
    "                [\n",
    "                    self._val_patient_number_dict[key]\n",
    "                    for key in self._val_patient_number_dict.keys()\n",
    "                ]\n",
    "            )\n",
    "            del self._val_patient_number_dict\n",
    "\n",
    "    def _balance_classes(self):\n",
    "        \"\"\"Method to balance classes in the dataset by removing samples from the majority class.\n",
    "        Currently works only for interictal and ictal classes.\"\"\"\n",
    "        negative_label = self._label_counts[0]\n",
    "        positive_label = self._label_counts[1]\n",
    "\n",
    "        print(f\"Number of negative samples pre removal {negative_label}\")\n",
    "        print(f\"Number of positive samples pre removal {positive_label}\")\n",
    "        imbalance = negative_label - positive_label\n",
    "        print(f\"imbalance {imbalance}\")\n",
    "        negative_indices = np.where(self._labels == 0)[0]\n",
    "        indices_to_discard = np.random.choice(\n",
    "            negative_indices, size=imbalance, replace=False\n",
    "        )\n",
    "\n",
    "        self._features = np.delete(self._features, obj=indices_to_discard, axis=0)\n",
    "        self._labels = np.delete(self._labels, obj=indices_to_discard, axis=0)\n",
    "        self._time_labels = np.delete(self._time_labels, obj=indices_to_discard, axis=0)\n",
    "        self._edge_weights = np.delete(\n",
    "            self._edge_weights, obj=indices_to_discard, axis=0\n",
    "        )\n",
    "        self._patient_number = np.delete(\n",
    "            self._patient_number, obj=indices_to_discard, axis=0\n",
    "        )\n",
    "\n",
    "    def _standardize_data(self, features, labels, loso_features=None):\n",
    "        \"\"\"Standardize features by subtracting mean and dividing by standard deviation.\n",
    "        The mean and std are computed from the interictal class. The same values are used for loso_features.\n",
    "        Args:\n",
    "            features: (np.ndarray) Array with features.\n",
    "            labels: (np.ndarray) Array with labels.\n",
    "            loso_features (optional): (np.ndarray) Array with features for LOSO patient.\n",
    "        \"\"\"\n",
    "        indexes = np.where(labels == 0)[0]\n",
    "        features_negative = features[indexes]\n",
    "        channel_mean = features_negative.mean()\n",
    "        channel_std = features_negative.std()\n",
    "\n",
    "        for i in range(features.shape[0]):\n",
    "            for n in range(features.shape[1]):\n",
    "                features[i, n, :] = (features[i, n, :] - channel_mean) / channel_std\n",
    "        if (\n",
    "            loso_features is not None\n",
    "        ):  ## standardize loso features with the same values as for training data\n",
    "            for i in range(loso_features.shape[0]):\n",
    "                for n in range(loso_features.shape[1]):\n",
    "                    loso_features[i, n, :] = (\n",
    "                        loso_features[i, n, :] - channel_mean\n",
    "                    ) / channel_std\n",
    "\n",
    "    def _min_max_scale(self, features, labels, loso_features=None):\n",
    "        \"\"\"Min max scale features to range [0,1]. The min and max values are computed from the interictal class.\n",
    "        Args:\n",
    "            features: (np.ndarray) Array with features.\n",
    "            labels: (np.ndarray) Array with labels.\n",
    "        \"\"\"\n",
    "        indexes = np.where(labels == 0)[0]\n",
    "        features_negative = features[indexes]\n",
    "\n",
    "        channel_min = features_negative.min()\n",
    "        channel_max = features_negative.max()\n",
    "        for i in range(features.shape[0]):\n",
    "            for n in range(features.shape[1]):\n",
    "                features[i, n, :] = (features[i, n, :] - channel_min) / (\n",
    "                    channel_max - channel_min\n",
    "                )\n",
    "        if loso_features is not None:\n",
    "            for i in range(loso_features.shape[0]):\n",
    "                for n in range(loso_features.shape[1]):\n",
    "                    loso_features[i, n, :] = (loso_features[i, n, :] - channel_min) / (\n",
    "                        channel_max - channel_min\n",
    "                    )\n",
    "\n",
    "    def _apply_smote(self, features, labels):\n",
    "        \"\"\"Performs SMOTE oversampling on the dataset. Implemented for preictal vs ictal scenarion only.\n",
    "        Args:\n",
    "            features: (np.ndarray) Array with features.\n",
    "            labels: (np.ndarray) Array with labels.\n",
    "        Returns:\n",
    "            x_train_smote: (np.ndarray) Array with SMOTE oversampled features.\n",
    "            y_train_smote: (np.ndarray) Array with SMOTE oversampled labels.\n",
    "        \"\"\"\n",
    "        dim_1, dim_2, dim_3 = features.shape\n",
    "\n",
    "        new_dim = dim_1 * dim_2\n",
    "        new_x_train = features.reshape(new_dim, dim_3)\n",
    "        new_y_train = []\n",
    "        for i in range(len(labels)):\n",
    "            new_y_train.extend([labels[i]] * dim_2)\n",
    "\n",
    "        new_y_train = np.array(new_y_train)\n",
    "\n",
    "        # transform the dataset\n",
    "        oversample = SMOTE(random_state=42)\n",
    "        x_train, y_train = oversample.fit_resample(new_x_train, new_y_train)\n",
    "        x_train_smote = x_train.reshape(int(x_train.shape[0] / dim_2), dim_2, dim_3)\n",
    "        y_train_smote = []\n",
    "        for i in range(int(x_train.shape[0] / dim_2)):\n",
    "            # print(i)\n",
    "            value_list = list(y_train.reshape(int(x_train.shape[0] / dim_2), dim_2)[i])\n",
    "            # print(list(set(value_list)))\n",
    "            y_train_smote.extend(list(set(value_list)))\n",
    "            ## Check: if there is any different value in a list\n",
    "            if len(set(value_list)) != 1:\n",
    "                print(\n",
    "                    \"\\n\\n********* STOP: THERE IS SOMETHING WRONG IN TRAIN ******\\n\\n\"\n",
    "                )\n",
    "        y_train_smote = np.array(y_train_smote)\n",
    "        # print(np.unique(y_train_smote,return_counts=True))\n",
    "        return x_train_smote, y_train_smote\n",
    "\n",
    "    def _extend_data(\n",
    "        self,\n",
    "        patient,\n",
    "        patient_number,\n",
    "        features,\n",
    "        labels,\n",
    "        time_labels=None,\n",
    "        plv_edge_weights=None,\n",
    "    ):\n",
    "        \"\"\"Convenience method to extend the dictionaries with features, labels, time labels and edge weights.\n",
    "        Args:\n",
    "            patient: (str) Name of the patient to extend the dictionaries for.\n",
    "            patient_number: (int) Patient number to extend the dictionaries for.\n",
    "            features: (np.ndarray) Array with features.\n",
    "            labels: (np.ndarray) Array with labels.\n",
    "            time_labels (optional): (np.ndarray) Array with time labels.\n",
    "            plv_edge_weights (optional): (np.ndarray) Array with edge weights.\n",
    "        \"\"\"\n",
    "        if patient == self.loso_patient:\n",
    "            # logging.info(f\"Adding recording {record} of patient {patient}\")\n",
    "            try:\n",
    "                self._val_features_dict[patient] = np.concatenate(\n",
    "                    (self._val_features_dict[patient], features), axis=0\n",
    "                )\n",
    "                self._val_labels_dict[patient] = np.concatenate(\n",
    "                    (self._val_labels_dict[patient], labels), axis=0\n",
    "                )\n",
    "                # self._val_time_labels_dict[patient] = np.concatenate(\n",
    "                #     (self._val_time_labels_dict[patient], time_labels), axis=0\n",
    "                # )\n",
    "                # self._val_edge_weights_dict[patient] = np.concatenate(\n",
    "                #     (\n",
    "                #         self._val_edge_weights_dict[patient],\n",
    "                #         np.repeat(plv_edge_weights, features.shape[0], axis=0),\n",
    "                #     )\n",
    "                # )\n",
    "\n",
    "                self._val_patient_number_dict[patient] = np.concatenate(\n",
    "                    (self._val_patient_number_dict[patient], patient_number)\n",
    "                )\n",
    "            except:\n",
    "                self._val_features_dict[patient] = features\n",
    "                self._val_labels_dict[patient] = labels\n",
    "                # self._val_time_labels_dict[patient] = time_labels\n",
    "                # self._val_edge_weights_dict[patient] = np.repeat(\n",
    "                #     plv_edge_weights, features.shape[0], axis=0\n",
    "                # )\n",
    "                self._val_patient_number_dict[patient] = patient_number\n",
    "\n",
    "        else:\n",
    "            try:\n",
    "                self._features_dict[patient] = np.concatenate(\n",
    "                    (self._features_dict[patient], features), axis=0\n",
    "                )\n",
    "                self._labels_dict[patient] = np.concatenate(\n",
    "                    (self._labels_dict[patient], labels), axis=0\n",
    "                )\n",
    "                # self._time_labels_dict[patient] = np.concatenate(\n",
    "                #     (self._time_labels_dict[patient], time_labels), axis=0\n",
    "                # )\n",
    "                # self._edge_weights_dict[patient] = np.concatenate(\n",
    "                #     (\n",
    "                #         self._edge_weights_dict[patient],\n",
    "                #         np.repeat(plv_edge_weights, features.shape[0], axis=0),\n",
    "                #     )\n",
    "                # )\n",
    "\n",
    "                self._patient_number_dict[patient] = np.concatenate(\n",
    "                    (self._patient_number_dict[patient], patient_number)\n",
    "                )\n",
    "            except:\n",
    "                self._features_dict[patient] = features\n",
    "                self._labels_dict[patient] = labels\n",
    "                # self._time_labels_dict[patient] = time_labels\n",
    "                # self._edge_weights_dict[patient] = np.repeat(\n",
    "                #     plv_edge_weights, features.shape[0], axis=0\n",
    "                # )\n",
    "                self._patient_number_dict[patient] = patient_number\n",
    "\n",
    "    def _get_labels_features_edge_weights_seizure(self, patient):\n",
    "        \"\"\"Method to extract features, labels and edge weights for seizure and interictal samples.\"\"\"\n",
    "\n",
    "        event_tables = self._get_event_tables(\n",
    "            patient\n",
    "        )  # extract start and stop of seizure for patient\n",
    "        patient_path = os.path.join(self.npy_dataset_path, patient)\n",
    "        recording_list = [\n",
    "            recording\n",
    "            for recording in os.listdir(patient_path)\n",
    "            if \"seizures\" in recording\n",
    "        ]\n",
    "        for record in recording_list:  # iterate over recordings for a patient\n",
    "            recording_path = os.path.join(patient_path, record)\n",
    "            record = record.replace(\n",
    "                \"seizures_\", \"\"\n",
    "            )  ## some magic to get it properly working with event tables\n",
    "            record_id = record.split(\".npy\")[0]  #  get record id\n",
    "            start_event_tables = self._get_recording_events(\n",
    "                event_tables[0], record_id\n",
    "            )  # get start events\n",
    "            stop_event_tables = self._get_recording_events(\n",
    "                event_tables[1], record_id\n",
    "            )  # get stop events\n",
    "            data_array = np.load(recording_path)  # load the recording\n",
    "\n",
    "            # plv_edge_weights = np.expand_dims(\n",
    "            #     self._get_edge_weights_recording(\n",
    "            #         np.load(os.path.join(self.plv_values_path, patient, record))\n",
    "            #     ),\n",
    "            #     axis=0,\n",
    "            # )\n",
    "\n",
    "            features, labels, time_labels = utils.extract_training_data_and_labels(\n",
    "                data_array,\n",
    "                start_event_tables,\n",
    "                stop_event_tables,\n",
    "                fs=self.sampling_f,\n",
    "                seizure_lookback=self.seizure_lookback,\n",
    "                sample_timestep=self.sample_timestep,\n",
    "                preictal_overlap=self.preictal_overlap,\n",
    "                ictal_overlap=self.ictal_overlap,\n",
    "                buffer_time=self.buffer_time,\n",
    "            )\n",
    "\n",
    "            if features is None:\n",
    "                print(\n",
    "                    f\"Skipping the recording {record} patients {patient} cuz features are none\"\n",
    "                )\n",
    "                continue\n",
    "            # if len(np.unique(labels)) != 2:\n",
    "            #     print(\n",
    "            #         f\"Skipping the recording {record} patients {patient} cuz no seizure samples\"\n",
    "            #     )\n",
    "            #     continue\n",
    "\n",
    "            features = features.squeeze(2)\n",
    "\n",
    "            if self.downsample:\n",
    "                new_sample_count = int(self.downsample * self.sample_timestep)\n",
    "                features = scipy.signal.resample(features, new_sample_count, axis=2)\n",
    "            if self.fft:\n",
    "                features = np.fft.rfft(features, axis=2)\n",
    "            if self.smote:\n",
    "                features, labels = self._apply_smote(features, labels)\n",
    "            time_labels = np.expand_dims(time_labels.astype(np.int32), 1)\n",
    "            labels = labels.reshape((labels.shape[0], 1)).astype(np.float32)\n",
    "            patient_number = torch.full(\n",
    "                [labels.shape[0]],\n",
    "                int(\"\".join(x for x in patient if x.isdigit())),\n",
    "                dtype=torch.float32,\n",
    "            )\n",
    "\n",
    "            self._extend_data(patient, patient_number, features, labels)\n",
    "\n",
    "    def _get_labels_features_edge_weights_interictal(\n",
    "        self, patient, samples_patient: int = None\n",
    "    ):\n",
    "        \"\"\"Method to extract features, labels and edge weights for interictal samples.\n",
    "        Args:\n",
    "            patient: (str) Name of the patient to extract the data for.\n",
    "            samples_patient (optional): (int) Number of samples to extract for a patient.\n",
    "        Samples are extracted from non-seizure recordings for a patient, starting from random time point.\n",
    "        If not specified, the number of samples is calculated as the number of interictal samples for a patient\n",
    "        divided by the number of recordings for a patient.\n",
    "\n",
    "        \"\"\"\n",
    "        patient_path = os.path.join(self.npy_dataset_path, patient)\n",
    "        ## get all non-seizure recordings for a patient\n",
    "        recording_list = [\n",
    "            recording\n",
    "            for recording in os.listdir(patient_path)\n",
    "            if not \"seizures_\" in recording\n",
    "        ]\n",
    "        if samples_patient is None:\n",
    "            patient_num = int(\"\".join(filter(str.isdigit, patient)))\n",
    "            if patient == self.loso_patient:\n",
    "                patient_negatives = np.unique(\n",
    "                    self._val_labels_dict[patient], return_counts=True\n",
    "                )[1][0]\n",
    "                samples_per_recording = int(patient_negatives / len(recording_list))\n",
    "            else:\n",
    "                patient_negatives = np.unique(\n",
    "                    self._labels_dict[patient], return_counts=True\n",
    "                )[1][0]\n",
    "                samples_per_recording = int(patient_negatives / len(recording_list))\n",
    "        else:\n",
    "            samples_per_recording = int(samples_patient / len(recording_list))\n",
    "        for recording in recording_list:\n",
    "            recording_path = os.path.join(patient_path, recording)\n",
    "            data_array = np.expand_dims(np.load(recording_path), 1)\n",
    "            try:\n",
    "                features, labels = utils.extract_training_data_and_labels_interictal(\n",
    "                    input_array=data_array,\n",
    "                    samples_per_recording=samples_per_recording,\n",
    "                    fs=self.sampling_f,\n",
    "                    timestep=self.sample_timestep,\n",
    "                    overlap=self.preictal_overlap,\n",
    "                )\n",
    "            except:\n",
    "                print(f\"Skipping recording {recording} for patient due to the error\")\n",
    "                continue\n",
    "\n",
    "            patient_number = torch.full(\n",
    "                [labels.shape[0]],\n",
    "                patient_num,\n",
    "                dtype=torch.float32,\n",
    "            )\n",
    "            features = features.squeeze(2)\n",
    "            if self.downsample:\n",
    "                new_sample_count = int(self.downsample * self.sample_timestep)\n",
    "                features = scipy.signal.resample(features, new_sample_count, axis=2)\n",
    "            if self.fft:\n",
    "                features = np.fft.rfft(features, axis=2)\n",
    "            labels = labels.reshape((labels.shape[0], 1)).astype(np.float32)\n",
    "            self._extend_data(patient, patient_number, features, labels)\n",
    "\n",
    "    def _update_classes(self):\n",
    "        \"\"\"Method to remove samples of period that we do not want to load, as specified in used_classes_dict.\n",
    "        If it is possible, the method aims set the interictal period as class 0 to be used for extracting normalization parameters.\n",
    "        If it is not possible, preictal period remains chosen as class 0.\n",
    "        \"\"\"\n",
    "        if (\n",
    "            not self.used_classes_dict[\"ictal\"]\n",
    "            or not self.used_classes_dict[\"preictal\"]\n",
    "        ):\n",
    "            label_to_delete = 0 if self.used_classes_dict[\"ictal\"] else 1\n",
    "            idx_to_delete = np.where(self._labels == label_to_delete)[0]\n",
    "            self._features = np.delete(self._features, obj=idx_to_delete, axis=0)\n",
    "            self._labels = np.delete(self._labels, obj=idx_to_delete, axis=0)\n",
    "            self._patient_number = np.delete(\n",
    "                self._patient_number, obj=idx_to_delete, axis=0\n",
    "            )\n",
    "            ## change labels of remaining classes\n",
    "            if label_to_delete == 0:\n",
    "                self._labels[self._labels == 2] = 0\n",
    "                print(\n",
    "                    \"Deleted preictal samples, changed interictal label to 0,  ictal remains 1 \"\n",
    "                )\n",
    "            else:\n",
    "                self._labels[self._labels == 0] = 1\n",
    "                self._labels[self._labels == 2] = 0\n",
    "                print(\n",
    "                    \"Deleted ictal samples, changed interictal label to 0, preictal to 1\"\n",
    "                )\n",
    "            if self.loso_patient is not None:\n",
    "                idx_to_delete = np.where(self._val_labels == label_to_delete)[0]\n",
    "                self._val_features = np.delete(\n",
    "                    self._val_features, obj=idx_to_delete, axis=0\n",
    "                )\n",
    "                self._val_labels = np.delete(\n",
    "                    self._val_labels, obj=idx_to_delete, axis=0\n",
    "                )\n",
    "                self._val_patient_number = np.delete(\n",
    "                    self._val_patient_number, obj=idx_to_delete, axis=0\n",
    "                )\n",
    "                if label_to_delete == 0:\n",
    "                    self._val_labels[self._val_labels == 2] = 0\n",
    "                    print(\n",
    "                        \"Deleted preictal samples from LOSO patient, changed interictal label to 0, ictal remains 1 \"\n",
    "                    )\n",
    "                else:\n",
    "                    self._val_labels[self._val_labels == 0] = 1\n",
    "                    self._val_labels[self._val_labels == 2] = 0\n",
    "                    print(\n",
    "                        \"Deleted ictal from LOSO patient, changed interictal label to 0, preictal to 1\"\n",
    "                    )\n",
    "        elif (sum(self.used_classes_dict.values())== 3): ## case when all three classes are used - just flipping labels\n",
    "            self._labels[self._labels == 2] = 4 ## change interictal to 4 from 2 temporarily\n",
    "            self._labels[self._labels == 0] = 2 ## change preictal to 2 from 0\n",
    "            self._labels[self._labels == 4] = 0  ## change interictal to 0 from 4\n",
    "            if self.loso_patient is not None:\n",
    "                self._val_labels[self._val_labels == 2] = 4\n",
    "                self._val_labels[self._val_labels == 0] = 2\n",
    "                self._val_labels[self._val_labels == 4] = 0\n",
    "    \n",
    "    # TODO define a method to create edges and calculate plv to get weights\n",
    "    def get_dataset(self):\n",
    "        \"\"\"Creating graph data iterators. The iterator yelds dynamic, weighted and undirected graphs\n",
    "        containing self loops. Every node represents one electrode in EEG. The graph is fully connected,\n",
    "        edge weights are calculated for every EEG recording as PLV between channels (edge weight describes\n",
    "        the \"strength\" of connectivity between two channels in a recording). Node features are values of\n",
    "        channel voltages in time. Features are of shape [nodes,features,timesteps].\n",
    "\n",
    "        Returns:\n",
    "            train_dataset {DynamicGraphTemporalSignal} -- Training data iterator.\n",
    "            valid_dataset {DynamicGraphTemporalSignal} -- Validation data iterator (only if loso_patient is\n",
    "            specified in class constructor).\n",
    "        \"\"\"\n",
    "        ### TODO rozkminić o co chodzi z tym całym time labels - na razie wartość liczbowa która tam wchodzi\n",
    "        ### to shape atrybutu time_labels\n",
    "        assert (\n",
    "            \"interictal\" in self.used_classes_dict.keys()\n",
    "        ), \"Please define the behavior for interictal class in used_classes_dict\"\n",
    "        assert (\n",
    "            \"preictal\" in self.used_classes_dict.keys()\n",
    "        ), \"Please define the behavior for preictal class in used_classes_dict\"\n",
    "        assert (\n",
    "            \"ictal\" in self.used_classes_dict.keys()\n",
    "        ), \"Please define the behavior for ictal class in used_classes_dict\"\n",
    "        \n",
    "        assert (\n",
    "            sum(self.used_classes_dict.values()) > 1\n",
    "        ), \"Please define at least two classes to use in used_classes_dict\"\n",
    "        \n",
    "        self._initialize_dicts()\n",
    "        patient_list = os.listdir(self.npy_dataset_path)\n",
    "        start_time = time.time()\n",
    "        if self.smote:\n",
    "            for patient in patient_list:\n",
    "                self._get_labels_features_edge_weights_seizure(patient)\n",
    "        else:\n",
    "            Parallel(n_jobs=6, require=\"sharedmem\")(\n",
    "                delayed(self._get_labels_features_edge_weights_seizure)(patient)\n",
    "                for patient in patient_list\n",
    "            )\n",
    "        print(\n",
    "            f\"Finished reading in {time.time() - start_time} seconds for seizure data\"\n",
    "        )\n",
    "        if self.used_classes_dict[\"interictal\"]:\n",
    "            Parallel(n_jobs=6, require=\"sharedmem\")(\n",
    "                delayed(self._get_labels_features_edge_weights_interictal)(patient)\n",
    "                for patient in patient_list\n",
    "            )\n",
    "\n",
    "        self._convert_dict_to_array()\n",
    "        self._update_classes()\n",
    "\n",
    "        self._get_labels_count()\n",
    "        if self.balance:\n",
    "            self._balance_classes()\n",
    "\n",
    "        print(\n",
    "            f\"Finished reading in {time.time() - start_time} seconds for non seizure data\"\n",
    "        )\n",
    "        start_time_preprocessing = time.time()\n",
    "        self._standardize_data(self._features, self._labels, self._val_features)\n",
    "\n",
    "        self._get_edges()\n",
    "        # self._get_labels_count()\n",
    "        if self.hjorth:\n",
    "            self._features = self._calculate_hjorth_features(self._features)\n",
    "            if self.loso_patient is not None:\n",
    "                self._val_features = self._calculate_hjorth_features(self._val_features)\n",
    "        self._array_to_tensor()\n",
    "\n",
    "        if self.train_test_split is not None:\n",
    "            if self.fft or self.hjorth:\n",
    "                data_list = self._features_to_data_list(\n",
    "                    self._features,\n",
    "                    self._edges,\n",
    "                    # self._edge_weights,\n",
    "                    self._labels,\n",
    "                    # self._time_labels,\n",
    "                )\n",
    "                train_data_list, val_data_list = self._split_data_list(data_list)\n",
    "                label_count = np.unique(\n",
    "                    [data.y.item() for data in train_data_list], return_counts=True\n",
    "                )[1]\n",
    "                self.alpha = label_count[0] / label_count[1]\n",
    "                loaders = [\n",
    "                    DataLoader(\n",
    "                        train_data_list,\n",
    "                        batch_size=self.batch_size,\n",
    "                        shuffle=True,\n",
    "                        drop_last=False,\n",
    "                    ),\n",
    "                    DataLoader(\n",
    "                        val_data_list,\n",
    "                        batch_size=len(val_data_list),\n",
    "                        shuffle=False,\n",
    "                        drop_last=False,\n",
    "                    ),\n",
    "                ]\n",
    "\n",
    "            else:\n",
    "                train_dataset = torch.utils.data.TensorDataset(\n",
    "                    self._features,\n",
    "                    self._edges,\n",
    "                    # self._edge_weights,\n",
    "                    self._labels,\n",
    "                    # self._time_labels,\n",
    "                )\n",
    "\n",
    "                train_dataset, val_dataset = torch.utils.data.random_split(\n",
    "                    train_dataset,\n",
    "                    [1 - self.train_test_split, self.train_test_split],\n",
    "                    generator=torch.Generator().manual_seed(42),\n",
    "                )\n",
    "\n",
    "                train_dataloader = torch.utils.data.DataLoader(\n",
    "                    train_dataset,\n",
    "                    batch_size=self.batch_size,\n",
    "                    shuffle=True,\n",
    "                    # num_workers=2,\n",
    "                    # pin_memory=True,\n",
    "                    # prefetch_factor=4,\n",
    "                    drop_last=False,\n",
    "                )\n",
    "\n",
    "                val_dataloader = torch.utils.data.DataLoader(\n",
    "                    val_dataset,\n",
    "                    batch_size=self.batch_size,\n",
    "                    shuffle=False,\n",
    "                    # num_workers=2,\n",
    "                    # pin_memory=True,\n",
    "                    # prefetch_factor=4,\n",
    "                    drop_last=False,\n",
    "                )\n",
    "                loaders = [train_dataloader, val_dataloader]\n",
    "        else:\n",
    "            if self.fft or self.hjorth:\n",
    "                train_data_list = self._features_to_data_list(\n",
    "                    self._features,\n",
    "                    self._edges,\n",
    "                    # self._edge_weights,\n",
    "                    self._labels,\n",
    "                    # self._time_labels,\n",
    "                )\n",
    "                loaders = [\n",
    "                    DataLoader(\n",
    "                        train_data_list,\n",
    "                        batch_size=self.batch_size,\n",
    "                        shuffle=True,\n",
    "                        drop_last=False,\n",
    "                    )\n",
    "                ]\n",
    "            else:\n",
    "                train_dataset = torch.utils.data.TensorDataset(\n",
    "                    self._features,\n",
    "                    self._edges,\n",
    "                    # self._edge_weights,\n",
    "                    self._labels,\n",
    "                    # self._time_labels,\n",
    "                )\n",
    "                train_dataloader = torch.utils.data.DataLoader(\n",
    "                    train_dataset,\n",
    "                    batch_size=self.batch_size,\n",
    "                    shuffle=True,\n",
    "                    # num_workers=2,\n",
    "                    # pin_memory=True,\n",
    "                    # prefetch_factor=4,\n",
    "                    drop_last=False,\n",
    "                )\n",
    "                loaders = [train_dataloader]\n",
    "        if self.loso_patient:\n",
    "            # if self.hjorth:\n",
    "            #     self._val_features = self._calculate_hjorth_features(self._val_features)\n",
    "\n",
    "            if self.fft or self.hjorth:\n",
    "                loso_data_list = self._features_to_data_list(\n",
    "                    self._val_features,\n",
    "                    self._val_edges,\n",
    "                    # self._val_edge_weights,\n",
    "                    self._val_labels,\n",
    "                    # self._val_time_labels,\n",
    "                )\n",
    "                print(\"Preprocessing time: \", time.time() - start_time_preprocessing)\n",
    "                return (\n",
    "                    *loaders,\n",
    "                    DataLoader(\n",
    "                        loso_data_list,\n",
    "                        batch_size=len(loso_data_list),\n",
    "                        shuffle=False,\n",
    "                        drop_last=False,\n",
    "                    ),\n",
    "                )\n",
    "            loso_dataset = torch.utils.data.TensorDataset(\n",
    "                self._val_features,\n",
    "                self._val_edges,\n",
    "                # self._val_edge_weights,\n",
    "                self._val_labels,\n",
    "                #  self._val_time_labels,\n",
    "            )\n",
    "            loso_dataloader = torch.utils.data.DataLoader(\n",
    "                loso_dataset,\n",
    "                batch_size=self.batch_size,\n",
    "                shuffle=False,\n",
    "                # pin_memory=True,\n",
    "                # num_workers=2,\n",
    "                # prefetch_factor=4,\n",
    "                drop_last=False,\n",
    "            )\n",
    "\n",
    "            return (*loaders, loso_dataloader)\n",
    "\n",
    "        return (*loaders,)\n",
    "\n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO ekstrachować do osobnego loadera, oddzielić już ten jeden track całkowicie\n",
    "## czy nie zapisać tego po prostu jako jeden duży HDF5, a potem wczytywać?\n",
    "## pomyśleć o strukturze hdfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TIMESTEP = 6\n",
    "PREICTAL_OVERLAP = 0\n",
    "ICTAL_OVERLAP = 0\n",
    "INTER_OVERLAP = 0\n",
    "SFREQ = 256\n",
    "torch_geometric.seed_everything(42)\n",
    "dataloader = SeizureDataLoader(\n",
    "    npy_dataset_path=Path('data/npy_data_full'),\n",
    "    event_tables_path=Path('data/event_tables'),\n",
    "    plv_values_path=Path('data/plv_arrays'),\n",
    "    loso_patient='chb20',\n",
    "    sampling_f=SFREQ,\n",
    "    seizure_lookback=600,\n",
    "    sample_timestep= TIMESTEP,\n",
    "    inter_overlap=INTER_OVERLAP,\n",
    "    preictal_overlap=PREICTAL_OVERLAP,\n",
    "    ictal_overlap=ICTAL_OVERLAP,\n",
    "    self_loops=False,\n",
    "    balance=False,\n",
    "    train_test_split=0.05,\n",
    "    fft=False,\n",
    "    hjorth=False,\n",
    "    downsample=60,\n",
    "    batch_size=64,\n",
    "    buffer_time=60,\n",
    "    smote=False,\n",
    "    used_classes_dict={\"ictal\": True, \"interictal\": True, \"preictal\": True}\n",
    "    )\n",
    "train_loader,valid_loader, loso_loader =dataloader.get_dataset() \n",
    "alpha = list(dataloader._label_counts.values())[0]/list(dataloader._label_counts.values())[1]\n",
    "alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "features_train = dataloader._features.numpy()\n",
    "#single_case = features_train[0]\n",
    "main_dataframe = pd.DataFrame(columns=['id','time','channel','value'])\n",
    "for n,case in enumerate(dataloader._features.numpy()):\n",
    "    new_dataframe = pd.DataFrame(columns=['id','time','channel','value'])\n",
    "    new_dataframe[\"id\"] = np.repeat(n,case.shape[0]*case.shape[1])\n",
    "    new_dataframe[\"time\"] = np.tile(np.arange(case.shape[1]),case.shape[0])\n",
    "    new_dataframe[\"channel\"] = np.stack([torch.full([case.shape[1]],i) for i in range(case.shape[0])]).flatten()\n",
    "    new_dataframe['value'] = case.flatten()\n",
    "main_dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case = features_train[0]\n",
    "new_dataframe = pd.DataFrame(columns=['id','time','value'])\n",
    "new_dataframe[\"id\"] = np.stack([torch.full([case.shape[1]],i) for i in range(case.shape[0])]).flatten()\n",
    "new_dataframe[\"time\"] = np.tile(np.arange(case.shape[1]),case.shape[0])\n",
    "new_dataframe['value'] = case.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_parameters = {\n",
    "    \"abs_energy\" : None,\n",
    "    \"absolute_sum_of_changes\" : None,\n",
    "    \"agg_autocorrelation\" : [{\"f_agg\": \"mean\", \"maxlag\": 10}],\n",
    "    \"autocorrelation\" : [{\"lag\": 10}],\n",
    "    \"number_peaks\" : [{\"n\":5}],\n",
    "    \"c3\" : [{\"lag\": 10}],\n",
    "    \"cid_ce\" : [{\"normalize\": True}],\n",
    "    \"longest_strike_below_mean\" : None,\n",
    "    \"longest_strike_above_mean\" : None,\n",
    "    \"fourier_entropy\" : [{\"bins\": 10}],\n",
    "    \"mean_change\" : None,\n",
    "    \"number_crossing_m\" : [{\"m\": 0}],\n",
    "    \"sample_entropy\" : None,\n",
    "    \"variance\" : None,\n",
    "    \"variation_coefficient\" : None,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_features = extract_features(\n",
    "    new_dataframe,\n",
    "    column_id=\"id\",\n",
    "    column_sort=\"time\",\n",
    "    column_kind=None,\n",
    "    column_value=None,\n",
    "    n_jobs=8,\n",
    "    default_fc_parameters=fc_parameters,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 18/18 [00:00<00:00, 69.10it/s]\n",
      "Feature Extraction: 100%|██████████| 18/18 [00:00<00:00, 78.75it/s]\n",
      "Feature Extraction: 100%|██████████| 18/18 [00:00<00:00, 84.98it/s]\n"
     ]
    }
   ],
   "source": [
    "from tsfresh import extract_features\n",
    "try:\n",
    "    del final_df\n",
    "except:\n",
    "    pass\n",
    "indexes_preictal = np.where(dataloader._labels == 2)[0]\n",
    "indexes_ictal = np.where(dataloader._labels == 1)[0]\n",
    "indexes_interictal = np.where(dataloader._labels == 0)[0]\n",
    "features_preictal = dataloader._features[indexes_preictal]\n",
    "features_ictal = dataloader._features[indexes_ictal]\n",
    "features_interictal = dataloader._features[indexes_interictal]\n",
    "case_interictal = features_interictal[1789]\n",
    "case_preictal = features_preictal[176]\n",
    "case_ictal = features_ictal[162]\n",
    "cases_list = [case_preictal,case_ictal,case_interictal]\n",
    "for case in cases_list:\n",
    "    new_dataframe = pd.DataFrame(columns=['id','time','channel','value'])\n",
    "    new_dataframe[\"id\"] = np.repeat(0,case.shape[0]*case.shape[1])\n",
    "    new_dataframe[\"time\"] = np.tile(np.arange(case.shape[1]),case.shape[0])\n",
    "    new_dataframe[\"channel\"] = np.stack([torch.full([case.shape[1]],i) for i in range(case.shape[0])]).flatten()\n",
    "    new_dataframe['value'] = abs(case.flatten())\n",
    "    extracted_features = extract_features(\n",
    "    new_dataframe,\n",
    "    column_id=\"id\",\n",
    "    column_sort=\"time\",\n",
    "    column_kind=\"channel\",\n",
    "    column_value=\"value\",\n",
    "    default_fc_parameters=fc_parameters,\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        final_df = pd.concat([final_df,extracted_features],axis=0)\n",
    "    except:\n",
    "        final_df = extracted_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0__abs_energy</th>\n",
       "      <th>0__absolute_sum_of_changes</th>\n",
       "      <th>0__agg_autocorrelation__f_agg_\"mean\"__maxlag_10</th>\n",
       "      <th>0__autocorrelation__lag_10</th>\n",
       "      <th>0__number_peaks__n_5</th>\n",
       "      <th>0__c3__lag_10</th>\n",
       "      <th>0__cid_ce__normalize_True</th>\n",
       "      <th>0__longest_strike_below_mean</th>\n",
       "      <th>0__longest_strike_above_mean</th>\n",
       "      <th>0__fourier_entropy__bins_10</th>\n",
       "      <th>...</th>\n",
       "      <th>17__c3__lag_10</th>\n",
       "      <th>17__cid_ce__normalize_True</th>\n",
       "      <th>17__longest_strike_below_mean</th>\n",
       "      <th>17__longest_strike_above_mean</th>\n",
       "      <th>17__fourier_entropy__bins_10</th>\n",
       "      <th>17__mean_change</th>\n",
       "      <th>17__number_crossing_m__m_0</th>\n",
       "      <th>17__sample_entropy</th>\n",
       "      <th>17__variance</th>\n",
       "      <th>17__variation_coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.085349</td>\n",
       "      <td>46.147923</td>\n",
       "      <td>0.089711</td>\n",
       "      <td>-0.005815</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.007280</td>\n",
       "      <td>20.898393</td>\n",
       "      <td>13.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.307760</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005581</td>\n",
       "      <td>18.508867</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.263438</td>\n",
       "      <td>-0.000993</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.708982</td>\n",
       "      <td>0.021811</td>\n",
       "      <td>0.828464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1853.459725</td>\n",
       "      <td>246.644345</td>\n",
       "      <td>0.097074</td>\n",
       "      <td>-0.118039</td>\n",
       "      <td>29.0</td>\n",
       "      <td>4.597540</td>\n",
       "      <td>11.791308</td>\n",
       "      <td>25.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.801953</td>\n",
       "      <td>...</td>\n",
       "      <td>2.377510</td>\n",
       "      <td>16.779325</td>\n",
       "      <td>15.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.881337</td>\n",
       "      <td>-0.002482</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.812281</td>\n",
       "      <td>0.865046</td>\n",
       "      <td>0.674013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>125.627128</td>\n",
       "      <td>68.297468</td>\n",
       "      <td>0.223037</td>\n",
       "      <td>0.068463</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.087021</td>\n",
       "      <td>12.933209</td>\n",
       "      <td>29.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.972467</td>\n",
       "      <td>...</td>\n",
       "      <td>0.161393</td>\n",
       "      <td>12.465626</td>\n",
       "      <td>21.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.837301</td>\n",
       "      <td>0.001280</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.544535</td>\n",
       "      <td>0.146667</td>\n",
       "      <td>0.763628</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 270 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0__abs_energy  0__absolute_sum_of_changes   \n",
       "0      22.085349                   46.147923  \\\n",
       "0    1853.459725                  246.644345   \n",
       "0     125.627128                   68.297468   \n",
       "\n",
       "   0__agg_autocorrelation__f_agg_\"mean\"__maxlag_10   \n",
       "0                                         0.089711  \\\n",
       "0                                         0.097074   \n",
       "0                                         0.223037   \n",
       "\n",
       "   0__autocorrelation__lag_10  0__number_peaks__n_5  0__c3__lag_10   \n",
       "0                   -0.005815                  32.0       0.007280  \\\n",
       "0                   -0.118039                  29.0       4.597540   \n",
       "0                    0.068463                  26.0       0.087021   \n",
       "\n",
       "   0__cid_ce__normalize_True  0__longest_strike_below_mean   \n",
       "0                  20.898393                          13.0  \\\n",
       "0                  11.791308                          25.0   \n",
       "0                  12.933209                          29.0   \n",
       "\n",
       "   0__longest_strike_above_mean  0__fourier_entropy__bins_10  ...   \n",
       "0                          11.0                     1.307760  ...  \\\n",
       "0                          10.0                     0.801953  ...   \n",
       "0                          11.0                     0.972467  ...   \n",
       "\n",
       "   17__c3__lag_10  17__cid_ce__normalize_True  17__longest_strike_below_mean   \n",
       "0        0.005581                   18.508867                           10.0  \\\n",
       "0        2.377510                   16.779325                           15.0   \n",
       "0        0.161393                   12.465626                           21.0   \n",
       "\n",
       "   17__longest_strike_above_mean  17__fourier_entropy__bins_10   \n",
       "0                           12.0                      1.263438  \\\n",
       "0                           11.0                      0.881337   \n",
       "0                           16.0                      0.837301   \n",
       "\n",
       "   17__mean_change  17__number_crossing_m__m_0  17__sample_entropy   \n",
       "0        -0.000993                         0.0            1.708982  \\\n",
       "0        -0.002482                         0.0            1.812281   \n",
       "0         0.001280                         0.0            1.544535   \n",
       "\n",
       "   17__variance  17__variation_coefficient  \n",
       "0      0.021811                   0.828464  \n",
       "0      0.865046                   0.674013  \n",
       "0      0.146667                   0.763628  \n",
       "\n",
       "[3 rows x 270 columns]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.47787711, -0.63775281, -0.27446598, -2.15135084,  0.16903085,\n",
       "        -0.52401646, -0.89039371,  0.60131954, -0.38829014, -0.61966935,\n",
       "         0.81204733,  0.        , -1.23655798, -0.37548689,  1.5248756 ],\n",
       "       [-0.87013642, -0.82428875, -1.13913739, -0.56946402,  0.16903085,\n",
       "        -0.65504061,  0.16025054, -0.69753067, -1.05393037,  0.4644226 ,\n",
       "        -0.2280228 ,  0.        ,  0.55627829, -0.92589786,  0.28320169],\n",
       "       [ 0.0840688 , -0.31184865, -0.37784455, -0.0504753 ,  0.6761234 ,\n",
       "        -0.21081564, -1.09701886,  0.81779457, -0.72111026,  0.14195463,\n",
       "         0.01531812,  0.        , -1.21309985,  0.28732808,  1.04935879],\n",
       "       [ 0.46012498,  1.54974799, -1.0640813 , -0.49090884,  1.18321596,\n",
       "         0.0417013 ,  1.47731911, -0.9140057 , -1.38675049, -0.53276489,\n",
       "        -2.38993227,  0.        ,  0.96779647,  0.65215409,  0.49215139],\n",
       "       [ 0.11029074, -0.41536127,  1.49516812,  0.11602363, -0.3380617 ,\n",
       "         0.04356135, -0.99821213,  0.81779457,  0.94299033, -0.97484905,\n",
       "        -0.51467411,  0.        , -1.35158439, -0.02575382, -1.26203082],\n",
       "       [-0.67612173, -0.66102649, -1.05087313, -1.11261259, -0.3380617 ,\n",
       "        -0.56700992, -0.14067218, -0.58929315, -0.72111026,  0.35876391,\n",
       "        -0.34796645,  0.        , -0.18548878, -0.75425662, -0.63355365],\n",
       "       [-0.66616657,  0.00388776, -0.70677496,  1.40441153,  1.69030851,\n",
       "        -0.52838683,  1.46465366, -0.2645806 , -1.05393037,  0.3136991 ,\n",
       "         1.63558875,  0.        ,  1.13326406, -0.67539092,  0.53584563],\n",
       "       [ 2.78753657,  2.90485838, -1.26717144, -0.50838505, -0.84515425,\n",
       "         3.2460127 ,  1.2904492 , -0.48105563, -1.05393037,  0.38938775,\n",
       "        -0.94061121,  0.        ,  1.53345563,  2.41292179, -1.6105663 ],\n",
       "       [ 0.11000764, -0.25166117,  0.4566063 , -0.33838233, -0.3380617 ,\n",
       "        -0.07341411, -0.73590386, -0.04810556,  1.94145069,  0.3434362 ,\n",
       "         1.46605618,  0.        , -0.33069532, -0.03809636, -1.34014989],\n",
       "       [-0.70476678, -1.0006087 ,  1.32943511,  0.66074686, -0.3380617 ,\n",
       "        -0.57870666, -1.1184799 ,  0.38484451,  0.2773501 , -0.86574166,\n",
       "        -0.08804577,  0.        , -1.24514483, -0.73274059,  0.31806743],\n",
       "       [-0.88052494, -0.93339608,  0.46993913, -0.61278903,  0.6761234 ,\n",
       "        -0.64847933,  0.21689171, -0.2645806 ,  1.94145069, -0.06756982,\n",
       "         0.53342671,  0.        ,  0.71029872, -0.96336177, -0.47748312],\n",
       "       [-0.60927293,  0.0409022 ,  0.19010381,  1.27204599,  1.69030851,\n",
       "        -0.5458241 ,  0.80817038, -1.02224322, -1.05393037,  0.22543985,\n",
       "        -0.0780932 ,  0.        ,  0.60083599, -0.52937742,  1.79671335],\n",
       "       [ 2.04075902,  1.35724452, -0.26207238,  0.19233775, -2.36643191,\n",
       "         1.88758638, -0.15763385, -0.69753067,  0.94299033, -0.19068366,\n",
       "         0.94114849,  0.        ,  0.30184904,  2.12346262, -0.56030027],\n",
       "       [-0.45435452, -0.44198245,  0.34553721, -0.40821569, -0.3380617 ,\n",
       "        -0.4787107 , -0.54260048,  0.06013195,  0.2773501 , -1.20693757,\n",
       "        -0.4279146 ,  0.        , -0.40976285, -0.36979627,  1.21055312],\n",
       "       [-0.25006382, -0.37822916,  0.48320326,  2.0371303 ,  0.6761234 ,\n",
       "        -0.23196031, -0.59962691,  0.16836947,  0.2773501 ,  0.34666023,\n",
       "         1.21080573,  0.        , -0.24944172, -0.32757948, -0.81825292],\n",
       "       [-0.33758592,  0.81466646, -1.15623751, -0.60042448,  0.16903085,\n",
       "        -0.38575221,  1.95862563, -0.80576818, -0.05547002,  3.35420649,\n",
       "         0.24395193,  0.        ,  1.26221156, -0.34892118, -0.12102727],\n",
       "       [ 1.12971954, -0.05172187,  2.43019942,  1.41375064, -1.35224681,\n",
       "         0.82419914, -1.37275415,  3.41549499,  0.94299033, -1.40532606,\n",
       "        -1.58865336,  0.        , -1.73744691,  1.48910233,  0.66771584],\n",
       "       [-0.79563654, -0.76342992,  0.09846627, -0.25343853, -0.84515425,\n",
       "        -0.61494398,  0.27693582, -0.48105563, -0.05547002, -0.0744287 ,\n",
       "        -0.2544295 ,  0.        ,  0.89323286, -0.89830972, -1.05511858]])"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit_transform(features_extracted_ictal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_extracted_preictal = final_df.values[0].reshape(18,15)\n",
    "features_extracted_ictal = final_df.values[1].reshape(18,15)\n",
    "features_extracted_interictal = final_df.values[2].reshape(18,15)\n",
    "features_extracted_preictal = scaler.fit_transform(features_extracted_preictal)\n",
    "features_extracted_ictal = scaler.fit_transform(features_extracted_ictal)\n",
    "features_extracted_interictal = scaler.fit_transform(features_extracted_interictal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must be the same size",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[190], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m fig,ax \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39msubplots(\u001b[39m18\u001b[39m,\u001b[39m1\u001b[39m,figsize\u001b[39m=\u001b[39m(\u001b[39m10\u001b[39m,\u001b[39m10\u001b[39m))\n\u001b[1;32m      4\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m18\u001b[39m):\n\u001b[0;32m----> 5\u001b[0m     ax[i]\u001b[39m.\u001b[39;49mscatter(i,features_extracted_preictal[i])\n\u001b[1;32m      6\u001b[0m     ax[i]\u001b[39m.\u001b[39mscatter(i,features_extracted_ictal[i])\n\u001b[1;32m      7\u001b[0m     ax[i]\u001b[39m.\u001b[39mscatter(i,features_extracted_interictal[i])\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/matplotlib/__init__.py:1442\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1439\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m   1440\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minner\u001b[39m(ax, \u001b[39m*\u001b[39margs, data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m   1441\u001b[0m     \u001b[39mif\u001b[39;00m data \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1442\u001b[0m         \u001b[39mreturn\u001b[39;00m func(ax, \u001b[39m*\u001b[39;49m\u001b[39mmap\u001b[39;49m(sanitize_sequence, args), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1444\u001b[0m     bound \u001b[39m=\u001b[39m new_sig\u001b[39m.\u001b[39mbind(ax, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1445\u001b[0m     auto_label \u001b[39m=\u001b[39m (bound\u001b[39m.\u001b[39marguments\u001b[39m.\u001b[39mget(label_namer)\n\u001b[1;32m   1446\u001b[0m                   \u001b[39mor\u001b[39;00m bound\u001b[39m.\u001b[39mkwargs\u001b[39m.\u001b[39mget(label_namer))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/matplotlib/axes/_axes.py:4584\u001b[0m, in \u001b[0;36mAxes.scatter\u001b[0;34m(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, edgecolors, plotnonfinite, **kwargs)\u001b[0m\n\u001b[1;32m   4582\u001b[0m y \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mma\u001b[39m.\u001b[39mravel(y)\n\u001b[1;32m   4583\u001b[0m \u001b[39mif\u001b[39;00m x\u001b[39m.\u001b[39msize \u001b[39m!=\u001b[39m y\u001b[39m.\u001b[39msize:\n\u001b[0;32m-> 4584\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mx and y must be the same size\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   4586\u001b[0m \u001b[39mif\u001b[39;00m s \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   4587\u001b[0m     s \u001b[39m=\u001b[39m (\u001b[39m20\u001b[39m \u001b[39mif\u001b[39;00m mpl\u001b[39m.\u001b[39mrcParams[\u001b[39m'\u001b[39m\u001b[39m_internal.classic_mode\u001b[39m\u001b[39m'\u001b[39m] \u001b[39melse\u001b[39;00m\n\u001b[1;32m   4588\u001b[0m          mpl\u001b[39m.\u001b[39mrcParams[\u001b[39m'\u001b[39m\u001b[39mlines.markersize\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m \u001b[39m2.0\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must be the same size"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 18 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "fig,ax = plt.subplots(18,1,figsize=(10,10))\n",
    "\n",
    "for i in range(18):\n",
    "    ax[i].scatter(i,features_extracted_preictal[i])\n",
    "    ax[i].scatter(i,features_extracted_ictal[i])\n",
    "    ax[i].scatter(i,features_extracted_interictal[i])\n",
    "    ax[i].set_title(f'Channel {i+1}')\n",
    "plt.legend(['preictal', 'ictal', 'interictal'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_features = extract_features(\n",
    "    new_dataframe,\n",
    "    column_id=\"id\",\n",
    "    column_sort=\"time\",\n",
    "    column_kind=\"channel\",\n",
    "    column_value=\"value\",\n",
    "    default_fc_parameters=fc_parameters,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nl = np.stack(\n",
    "    [\n",
    "        new_dataframe[new_dataframe[\"channel\"] == ch][\"value\"].to_list()\n",
    "        for ch in new_dataframe[\"channel\"].unique()\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecurrentGCN(torch.nn.Module):\n",
    "    def __init__(self, timestep,sfreq, n_nodes=18,batch_size=32):\n",
    "        super(RecurrentGCN, self).__init__()\n",
    "        self.n_nodes = n_nodes\n",
    "        self.out_features = 128\n",
    "        self.recurrent_1 = A3TGCN2(sfreq*timestep,32, add_self_loops=True,improved=False)\n",
    "        self.recurrent_2 = GCNConv(32,64,add_self_loops=True,improved=False)\n",
    "        self.recurrent_3 = GCNConv(64,128,add_self_loops=True,improved=False)\n",
    "        self.fc1 = torch.nn.Linear(n_nodes*128, 64)\n",
    "        self.fc2 = torch.nn.Linear(64, 32)\n",
    "        self.fc3 = torch.nn.Linear(32, 16)\n",
    "        self.fc4 = torch.nn.Linear(16, 1)\n",
    "        self.flatten = torch.nn.Flatten(start_dim=0)\n",
    "        self.dropout = torch.nn.Dropout()\n",
    "    def forward(self, x, edge_index,edge_weight,batch):\n",
    "        x = torch.squeeze(x)\n",
    "        h = self.recurrent_1(x, edge_index=edge_index, edge_weight = edge_weight)\n",
    "        h = torch.nn.BatchNorm1d(32)(h)\n",
    "        h = F.leaky_relu(h)\n",
    "        h = self.recurrent_2(h, edge_index,edge_weight)\n",
    "        h = torch.nn.BatchNorm1d(64)(h)\n",
    "        h = F.leaky_relu(h)\n",
    "        h = self.recurrent_3(h, edge_index,edge_weight)\n",
    "        h = torch.nn.BatchNorm1d(128)(h)\n",
    "        h = F.leaky_relu(h)\n",
    "        h = global_mean_pool(h,batch)\n",
    "        h = self.dropout(h)\n",
    "        h = self.fc1(h)\n",
    "        h = F.leaky_relu(h)\n",
    "        h = self.dropout(h)\n",
    "        h = self.fc2(h)\n",
    "        h = F.leaky_relu(h)\n",
    "        h = self.dropout(h)\n",
    "        h = self.fc3(h)\n",
    "        h = F.leaky_relu(h)\n",
    "        h = self.dropout(h)\n",
    "        h = self.fc4(h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = dataloader._features\n",
    "labels = dataloader._labels\n",
    "indexes_interictal = np.where(dataloader._labels == 0)[0]\n",
    "features_interictal = features[indexes_interictal]\n",
    "indexes_ictal = np.where(dataloader._labels == 1)[0]\n",
    "features_ictal = features[indexes_ictal]\n",
    "indexes_preictal = np.where(dataloader._labels == 2)[0]\n",
    "features_preictal = features[indexes_preictal]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## compare samples 14323 negative and 2543 positive - for the standarization they were the same amplitudes\n",
    "## how do I choose criteria for rejecting a sample when it is flat most of the time?\n",
    "## wavelet coef energy is useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "hjorth_features_negative = mne_features.univariate.compute_variance(features_negative[865].numpy())\n",
    "hjorth_features_positive = mne_features.univariate.compute_variance(features_positive[865].numpy())\n",
    "hjoth_features_healthy = mne_features.univariate.compute_variance(features_healthy[234].numpy())\n",
    "plt.plot(hjorth_features_negative)\n",
    "plt.plot(hjorth_features_positive)\n",
    "plt.plot(hjoth_features_healthy)\n",
    "plt.legend(['negative','positive','healthy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "fig,ax = plt.subplots(18,1,figsize=(10,10))\n",
    "\n",
    "for i in range(18):\n",
    "    \n",
    "    ax[i].plot(features_interictal[12,i,:])\n",
    "    ax[i].plot(features_ictal[15,i,:])\n",
    "    #ax[i].plot(features_preictal[5,i,:])\n",
    "    ax[i].set_title(f'Channel {i+1}')\n",
    "plt.legend(['interictal', 'preictal'])\n",
    "plt.show()\n",
    "\n",
    "# fig,ax = plt.subplots(18,1,figsize=(10,10))\n",
    "# for i in range(18):\n",
    "#     ax [i].plot(features_positive[865,i,:])\n",
    "#     ax[i].set_title(f'Channel {i+1}')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_loso = dataloader._val_features\n",
    "labels_loso = dataloader._val_labels\n",
    "indexes_interictal_loso = np.where(dataloader._val_labels == 0)[0]\n",
    "features_interictal_loso = features_loso[indexes_interictal_loso]\n",
    "indexes_ictal_loso = np.where(dataloader._val_labels == 1)[0]\n",
    "features_ictal_loso = features_loso[indexes_ictal_loso]\n",
    "indexes_preictal_loso = np.where(dataloader._val_labels == 2)[0]\n",
    "features_preictal_loso = features_loso[indexes_preictal_loso]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "fig,ax = plt.subplots(18,1,figsize=(10,10))\n",
    "for i in range(18):\n",
    "    \n",
    "    ax[i].plot(features_interictal_loso[20,i,:])\n",
    "    #ax[i].plot(features_ictal_loso[2,i,:])\n",
    "    ax[i].plot(features_preictal_loso[15,i,:])\n",
    "    ax[i].set_title(f'Channel {i+1}')\n",
    "plt.legend(['interictal', 'preictal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_loso = dataloader._val_features.numpy()\n",
    "indexes_loso = np.where(dataloader._val_labels == 0)[0]\n",
    "features_negative_loso = features_loso[indexes_loso]\n",
    "indexes_positive_loso = np.where(dataloader._val_labels == 1)[0]\n",
    "features_positive_loso = features_loso[indexes_positive_loso]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.explain import Explainer, AttentionExplainer, ExplainerConfig\n",
    "explainer = Explainer(\n",
    "    model=model,\n",
    "    algorithm=AttentionExplainer(),\n",
    "    explanation_type='model',\n",
    "   # node_mask_type='attributes',\n",
    "    edge_mask_type='object',\n",
    "    model_config=dict(\n",
    "        mode='binary_classification',\n",
    "        task_level='graph',\n",
    "        return_type='raw',  # Model returns log probabilities.\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecurrentGCN(torch.nn.Module):\n",
    "    def __init__(self, timestep,sfreq, n_nodes=18,batch_size=32):\n",
    "        super(RecurrentGCN, self).__init__()\n",
    "        self.n_nodes = n_nodes\n",
    "        self.out_features = 128\n",
    "        self.recurrent_1 = GCNConv(3,32, add_self_loops=True,improved=False)\n",
    "        self.recurrent_2 = GCNConv(32,64,add_self_loops=True,improved=False)\n",
    "        self.recurrent_3 = GCNConv(64,128,add_self_loops=True,improved=False)\n",
    "        self.fc1 = torch.nn.Linear(128, 64)\n",
    "        self.fc2 = torch.nn.Linear(64, 32)\n",
    "        self.fc3 = torch.nn.Linear(32, 16)\n",
    "        self.fc4 = torch.nn.Linear(16, 3)\n",
    "        self.batch_norm_1 = torch.nn.BatchNorm1d(32)\n",
    "        self.batch_norm_2 = torch.nn.BatchNorm1d(64)\n",
    "        self.batch_norm_3 = torch.nn.BatchNorm1d(128)\n",
    "        self.flatten = torch.nn.Flatten(start_dim=0)\n",
    "        self.dropout = torch.nn.Dropout()\n",
    "    def forward(self, x, edge_index,edge_weight,batch):\n",
    "        x = torch.squeeze(x)\n",
    "        h = self.recurrent_1(x, edge_index=edge_index, edge_weight = edge_weight)\n",
    "        h = self.batch_norm_1(h)\n",
    "        h = F.leaky_relu(h)\n",
    "        h = self.recurrent_2(h, edge_index,edge_weight)\n",
    "        h = self.batch_norm_2(h)\n",
    "        h = F.leaky_relu(h)\n",
    "        h = self.recurrent_3(h, edge_index,edge_weight)\n",
    "        h = self.batch_norm_3(h)\n",
    "        h = F.leaky_relu(h)\n",
    "        h = global_mean_pool(h,batch)\n",
    "        h = self.dropout(h)\n",
    "        h = self.fc1(h)\n",
    "        h = F.leaky_relu(h)\n",
    "        h = self.dropout(h)\n",
    "        h = self.fc2(h)\n",
    "        h = F.leaky_relu(h)\n",
    "        h = self.dropout(h)\n",
    "        h = self.fc3(h)\n",
    "        h = F.leaky_relu(h)\n",
    "        h = self.dropout(h)\n",
    "        h = self.fc4(h)\n",
    "        return h.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GATv2Lightning(pl.LightningModule):\n",
    "    def __init__(self, timestep,sfreq,alpha,threshold=0.5, hidden_channels=32,heads=8,negative_slope = 0.01, dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.hidden_channels = hidden_channels\n",
    "        self.recurrent_1 = GATv2Conv(\n",
    "            sfreq*timestep,hidden_channels,heads=heads,negative_slope=negative_slope,dropout=dropout, add_self_loops=True,improved=True,edge_dim=1)\n",
    "        self.fc1 = torch.nn.Linear(hidden_channels*heads, 64)\n",
    "        nn.init.kaiming_uniform_(self.fc1.weight,a=negative_slope)\n",
    "        self.fc2 = torch.nn.Linear(64, 32)\n",
    "        nn.init.kaiming_uniform_(self.fc2.weight,a=negative_slope)\n",
    "        self.fc3 = torch.nn.Linear(32, 1)\n",
    "        nn.init.kaiming_uniform_(self.fc3.weight,a=negative_slope)\n",
    "        self.batch_norm = torch.nn.BatchNorm1d(hidden_channels*heads)\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "        self.activation_recurrent = nn.Sequential(\n",
    "            self.batch_norm,\n",
    "            nn.LeakyReLU()\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            self.dropout,\n",
    "            self.fc1,\n",
    "            nn.LeakyReLU(),\n",
    "            self.dropout,\n",
    "            self.fc2,\n",
    "            nn.LeakyReLU(),\n",
    "            self.dropout,\n",
    "            self.fc3 \n",
    "        )\n",
    "        self.loss = nn.BCEWithLogitsLoss(pos_weight=torch.full([1], alpha))\n",
    "        self.sensitivity = BinaryRecall(threshold=threshold)\n",
    "        self.specificity = BinarySpecificity(threshold=threshold)\n",
    "        self.auroc = AUROC(task=\"binary\")\n",
    "    def forward(self, x, edge_index, edge_attr,batch):\n",
    "        h = self.recurrent_1(x, edge_index, edge_attr)\n",
    "        h = self.activation_recurrent(h)\n",
    "        h = global_mean_pool(h,batch)\n",
    "        h = self.classifier(h)\n",
    "        return h.squeeze()\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x = batch.x\n",
    "        x = x.squeeze()\n",
    "        signal_samples = x.shape[1]\n",
    "        x = 2 / signal_samples * torch.abs(x)\n",
    "        x = (x-x.mean(dim=0))/x.std(dim=0)\n",
    "        edge_index = batch.edge_index\n",
    "        edge_attr = batch.edge_attr.float()\n",
    "        y = batch.y\n",
    "        batches = batch.batch\n",
    "        y_hat = self(x, edge_index, edge_attr,batches)\n",
    "        loss = self.loss(y_hat, y)\n",
    "        self.log('train_loss', loss, on_step=False, on_epoch=True,prog_bar=True)\n",
    "        self.log('train_sensitivity', self.sensitivity(y_hat, y), on_step=False, on_epoch=True,prog_bar=True)\n",
    "        self.log('train_specificity', self.specificity(y_hat, y), on_step=False, on_epoch=True,prog_bar=True)\n",
    "        return loss\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x = batch.x\n",
    "        x = x.squeeze()\n",
    "        signal_samples = x.shape[1]\n",
    "        x = 2 / signal_samples * torch.abs(x)\n",
    "        x = (x-x.mean(dim=0))/x.std(dim=0)\n",
    "        edge_index = batch.edge_index\n",
    "        edge_attr = batch.edge_attr.float()\n",
    "        y = batch.y\n",
    "        batches = batch.batch\n",
    "        y_hat = self(x, edge_index, edge_attr,batches)\n",
    "        loss = self.loss(y_hat, y)\n",
    "        self.log('valid_loss', loss, on_step=False, on_epoch=True,prog_bar=True)\n",
    "        self.log('valid_sensitivity', self.sensitivity(y_hat, y), on_step=False, on_epoch=True,prog_bar=True)\n",
    "        self.log('valid_specificity', self.specificity(y_hat, y), on_step=False, on_epoch=True,prog_bar=True)\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "        return optimizer\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GATv2(torch.nn.Module):\n",
    "    def __init__(self, timestep, sfreq, n_nodes=18, batch_size=32):\n",
    "        super(GATv2, self).__init__()\n",
    "        self.n_nodes = n_nodes\n",
    "        hidden_dim = 32\n",
    "        out_dim = 64\n",
    "        n_heads = 4\n",
    "        self.recurrent_1 = GATv2Conv(\n",
    "            int((sfreq * timestep / 2) + 1),\n",
    "            hidden_dim,\n",
    "            heads=n_heads,\n",
    "            negative_slope=0.01,\n",
    "            dropout=0.4,\n",
    "            add_self_loops=True,\n",
    "            improved=True,\n",
    "            edge_dim=1,\n",
    "        )\n",
    "        self.recurrent_2 = GATv2Conv(\n",
    "            hidden_dim * n_heads,\n",
    "            out_dim,\n",
    "            heads=n_heads,\n",
    "            negative_slope=0.01,\n",
    "            dropout=0.4,\n",
    "            add_self_loops=True,\n",
    "            improved=True,\n",
    "            edge_dim=1,\n",
    "        )\n",
    "    \n",
    "        self.fc1 = torch.nn.Linear(out_dim*n_heads, 512)\n",
    "        nn.init.kaiming_uniform_(self.fc1.weight, a=0.01)\n",
    "        self.fc2 = torch.nn.Linear(512, 128)\n",
    "        nn.init.kaiming_uniform_(self.fc2.weight, a=0.01)\n",
    "        self.fc3 = torch.nn.Linear(128, 3)\n",
    "        nn.init.kaiming_uniform_(self.fc3.weight, a=0.01)\n",
    "        self.fc4 = torch.nn.Linear(128, 3)\n",
    "        self.connectivity = torch.nn.Linear(sfreq * timestep * n_nodes, 324)\n",
    "        self.connectivity_2 = torch.nn.Linear(sfreq * timestep, 324)\n",
    "        self.batch_norm_1 = torch.nn.BatchNorm1d(hidden_dim * n_heads)\n",
    "        self.batch_norm_2 = torch.nn.BatchNorm1d(out_dim* n_heads)\n",
    "        self.dropout = torch.nn.Dropout()\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, batch):\n",
    "        h = self.recurrent_1(x, edge_index=edge_index, edge_attr=edge_attr)\n",
    "        h = self.batch_norm_1(h)\n",
    "        h = F.leaky_relu(h)\n",
    "        # h = global_mean_pool(h,batch)\n",
    "\n",
    "        h = self.recurrent_2(h, edge_index=edge_index, edge_attr=edge_attr)\n",
    "        h = self.batch_norm_2(h)\n",
    "        h = F.leaky_relu(h)\n",
    "        h = global_mean_pool(h, batch)\n",
    "\n",
    "        h = self.dropout(h)\n",
    "        h = self.fc1(h)\n",
    "        h = F.leaky_relu(h)\n",
    "        h = self.dropout(h)\n",
    "        h = self.fc2(h)\n",
    "        h = F.leaky_relu(h)\n",
    "        h = self.dropout(h)\n",
    "        h = self.fc3(h)\n",
    "        # h = F.leaky_relu(h)\n",
    "        # h = self.dropout(h)\n",
    "        # h = self.fc4(h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Linear, Sequential, BatchNorm1d, ReLU, Dropout\n",
    "from torch_geometric.nn import GCNConv, GINConv, GINEConv\n",
    "from torch_geometric.nn import global_mean_pool, global_add_pool\n",
    "\n",
    "\n",
    "class GIN(torch.nn.Module):\n",
    "    \"\"\"GIN\"\"\"\n",
    "\n",
    "    def __init__(self, sfreq, timestep, dim_h=128):\n",
    "        super(GIN, self).__init__()\n",
    "        self.conv1 = GINConv(\n",
    "            Sequential(\n",
    "                Linear(int((sfreq * timestep / 2) + 1), dim_h),\n",
    "                BatchNorm1d(dim_h),\n",
    "                ReLU(),\n",
    "                Linear(dim_h, dim_h),\n",
    "                ReLU(),\n",
    "            ),\n",
    "           # edge_dim=1,\n",
    "        )\n",
    "        self.conv2 = GINConv(\n",
    "            Sequential(\n",
    "                Linear(dim_h, dim_h),\n",
    "                BatchNorm1d(dim_h),\n",
    "                ReLU(),\n",
    "                Linear(dim_h, dim_h),\n",
    "                ReLU(),\n",
    "            ),\n",
    "           # edge_dim=1,\n",
    "        )\n",
    "        self.conv3 = GINConv(\n",
    "            Sequential(\n",
    "                Linear(dim_h, dim_h),\n",
    "                BatchNorm1d(dim_h),\n",
    "                ReLU(),\n",
    "                Linear(dim_h, dim_h),\n",
    "                ReLU(),\n",
    "            ),\n",
    "           # edge_dim=1,\n",
    "        )\n",
    "\n",
    "        self.att_1 = GATv2Conv(\n",
    "            int((sfreq * timestep / 2) + 1),\n",
    "            dim_h,\n",
    "            heads=1,\n",
    "            negative_slope=0.01,\n",
    "            dropout=0.4,\n",
    "            add_self_loops=True,\n",
    "            improved=True,\n",
    "            edge_dim=1,\n",
    "        )\n",
    "        self.att_2 = GATv2Conv(\n",
    "            dim_h,\n",
    "            dim_h,\n",
    "            heads=1,\n",
    "            negative_slope=0.01,\n",
    "            dropout=0.4,\n",
    "            add_self_loops=True,\n",
    "            improved=True,\n",
    "            edge_dim=1,\n",
    "        )\n",
    "        self.att_3 = GATv2Conv(\n",
    "            dim_h,\n",
    "            dim_h,\n",
    "            heads=1,\n",
    "            negative_slope=0.01,\n",
    "            dropout=0.4,\n",
    "            add_self_loops=True,\n",
    "            improved=True,\n",
    "            edge_dim=1,\n",
    "        )\n",
    "        self.lin1 = Linear(dim_h * 3, dim_h * 3)\n",
    "        self.lin2 = Linear(dim_h * 3, 3)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        # Node embeddings\n",
    "       # _, edge_scores_1 = self.att_1(x, edge_index, return_attention_weights=True)\n",
    "        h1 = self.conv1(x, edge_index)\n",
    "      #  _, edge_scores_2 = self.att_2(h1, edge_index, return_attention_weights=True)\n",
    "        h2 = self.conv2(h1, edge_index)\n",
    "      #  _, edge_scores_3 = self.att_3(h1, edge_index, return_attention_weights=True)\n",
    "        h3 = self.conv3(h2, edge_index)\n",
    "\n",
    "        # Graph-level readout\n",
    "        h1 = global_mean_pool(h1, batch)\n",
    "        h2 = global_mean_pool(h2, batch)\n",
    "        h3 = global_mean_pool(h3, batch)\n",
    "        # Concatenate graph embeddings\n",
    "        h = torch.cat((h1, h2, h3), dim=1)\n",
    "        # Classifier\n",
    "        h = self.lin1(h)\n",
    "        h = h.relu()\n",
    "        h = F.dropout(h, p=0.5, training=self.training)\n",
    "        h = self.lin2(h)\n",
    "\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = sklearn.utils.class_weight.compute_class_weight(\n",
    "    \"balanced\",\n",
    "    classes=np.unique(dataloader._labels.int().squeeze()),\n",
    "    y=dataloader._labels.int().squeeze().numpy(),\n",
    ")\n",
    "class_weights = torch.from_numpy(class_weights).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## normal loop\n",
    "from torchmetrics import Specificity, Recall, F1Score\n",
    "torch_geometric.seed_everything(42)\n",
    "early_stopping = utils.EarlyStopping(patience=4, verbose=True)\n",
    "device = torch.device(\"cpu\")\n",
    "#model = GATv2(TIMESTEP,60,batch_size=32).to(device) #Gatv2\n",
    "model = GIN(60, 6).to(device)\n",
    "loss_fn =  nn.CrossEntropyLoss()\n",
    "f1_score = F1Score(\"multiclass\",num_classes=3,average='macro')\n",
    "optimizer = torch.optim.AdamW(model.parameters(),lr=0.001,weight_decay=0.0001)\n",
    "recall = Recall(task=\"multiclass\", average='macro', num_classes=3)\n",
    "specificity = Specificity(task=\"multiclass\", average='macro', num_classes=3)\n",
    "auroc = AUROC(task=\"multiclass\", num_classes=3)\n",
    "roc = ROC('multiclass', num_classes=3)\n",
    "model.train()\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min',patience=2)\n",
    "\n",
    "for epoch in tqdm(range(15)):\n",
    "        try:\n",
    "                del preds, ground_truth\n",
    "        except:\n",
    "                pass\n",
    "        epoch_loss = 0.0\n",
    "        epoch_loss_valid = 0.0\n",
    "        model.train()\n",
    "        sample_counter = 0\n",
    "        batch_counter = 0\n",
    "        print(get_lr(optimizer))\n",
    "        for time_train, batch in enumerate(train_loader): ## TODO - this thing is still operating with no edge weights!!!\n",
    "                ## find a way to compute plv per batch fast (is it even possible?)\n",
    "            \n",
    "                x = batch.x\n",
    "        \n",
    "                edge_index = batch.edge_index\n",
    "\n",
    "                y = batch.y.long()\n",
    "                batch_idx = batch.batch\n",
    "           \n",
    "                x = torch.square(torch.abs(x)).float()\n",
    "                y_hat = model(x, edge_index,batch_idx)\n",
    "               # y_hat = model(x, edge_index,None, batch_idx).squeeze()\n",
    "               # y_hat = model(x, edge_index, batch_idx).squeeze()\n",
    "                # print(y_hat.shape)\n",
    "                # print(y.shape)\n",
    "                loss = loss_fn(y_hat,y)\n",
    "                epoch_loss += loss\n",
    "                try:\n",
    "                 preds = torch.cat([preds,y_hat.detach()],dim=0)\n",
    "                 ground_truth = torch.cat([ground_truth,y],dim=0)\n",
    "            \n",
    "                except:\n",
    "                 preds= y_hat.detach()\n",
    "                 ground_truth = y\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        ## calculate acc\n",
    "        \n",
    "        train_auroc = auroc(preds,ground_truth)\n",
    "        train_sensitivity = recall(preds,ground_truth)\n",
    "        train_specificity = specificity(preds,ground_truth)\n",
    "        train_f1 = f1_score(preds,ground_truth)\n",
    "        del preds, ground_truth\n",
    "        print(f'Epoch: {epoch}', f'Epoch loss: {epoch_loss.detach().numpy()/(time_train+1)}')\n",
    "        print(f'Epoch sensitivity: {train_sensitivity}')\n",
    "        print(f'Epoch specificity: {train_specificity}')\n",
    "        print(f'Epoch AUROC: {train_auroc} ')\n",
    "        print(f'Epoch F1: {train_f1} ')\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "                try:\n",
    "                        del preds_valid, ground_truth_valid\n",
    "                except:\n",
    "                        pass\n",
    "                for time_valid, batch_valid in enumerate(valid_loader):\n",
    "                        x = batch_valid.x\n",
    "                        edge_index = batch_valid.edge_index\n",
    "                        y_val = batch_valid.y.long()\n",
    "                        batch_idx = batch_valid.batch\n",
    "                        x = torch.square(torch.abs(x)).float()\n",
    "                        y_hat_val = model(x, edge_index,batch_idx)\n",
    "                        #y_hat_val = model(x, edge_index,None,batch_idx)\n",
    "                        #y_hat_val = model(x, edge_index,batch_idx)\n",
    "                        loss_valid = loss_fn(y_hat_val,y_val)\n",
    "                        epoch_loss_valid += loss_valid\n",
    "                        try:\n",
    "                         preds_valid = torch.cat([preds_valid,y_hat_val],dim=0)\n",
    "                         ground_truth_valid = torch.cat([ground_truth_valid,y_val],dim=0)\n",
    "                        except:\n",
    "                         preds_valid= y_hat_val\n",
    "                         ground_truth_valid = y_val\n",
    "        early_stopping(epoch_loss_valid.numpy()/(time_valid+1), model)\n",
    "        val_auroc = auroc(preds_valid,ground_truth_valid)\n",
    "        val_sensitivity = recall(preds_valid,ground_truth_valid)\n",
    "        val_specificity = specificity(preds_valid,ground_truth_valid)\n",
    "        val_f1 = f1_score(preds_valid,ground_truth_valid)\n",
    "        del preds_valid, ground_truth_valid\n",
    "        print(f'Epoch val_loss: {epoch_loss_valid.detach().numpy()/(time_valid+1)}')\n",
    "        print(f'Epoch val_sensitivity: {val_sensitivity}')\n",
    "        print(f'Epoch val specificity: {val_specificity}')\n",
    "        print(f'Epoch val AUROC: {val_auroc} ')\n",
    "        print(f'Epoch val F1: {val_f1} ')\n",
    "        scheduler.step(epoch_loss_valid.detach().numpy()/(time_valid+1))\n",
    "        if early_stopping.early_stop:\n",
    "                print(\"Early stopping\")\n",
    "                model.load_state_dict(torch.load('checkpoint.pt'))\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('checkpoint.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    try:\n",
    "        del preds_valid, ground_truth_valid\n",
    "    except:\n",
    "        pass\n",
    "    epoch_loss_loso = 0.0\n",
    "    for time_loso, batch_loso in enumerate(loso_loader):\n",
    "            x = batch_loso.x.to(device)\n",
    "            edge_index = batch_loso.edge_index.to(device)\n",
    "            y_loso = batch_loso.y.to(device).long()\n",
    "            batch_idx = batch_loso.batch.to(device)\n",
    "   \n",
    "            x = torch.square(torch.abs(x)).float()\n",
    "            \n",
    "            \n",
    "            #y_hat_loso = model(x, edge_index,None,batch_idx)\n",
    "            y_hat_loso = model(x, edge_index,batch_idx)\n",
    "            loss_loso = loss_fn(y_hat_loso,y_loso)\n",
    "            #loss_loso = torchvision.ops.sigmoid_focal_loss(y_hat,y,alpha=0.65,gamma=4,reduction='mean')\n",
    "            epoch_loss_loso += loss_loso\n",
    "            try:\n",
    "                preds_loso = torch.cat([preds_loso,y_hat_loso],dim=0)\n",
    "                ground_truth_loso= torch.cat([ground_truth_loso,y_loso],dim=0)\n",
    "            except:\n",
    "                preds_loso= y_hat_loso\n",
    "                ground_truth_loso = y_loso\n",
    "    loso_auroc = auroc(preds_loso,ground_truth_loso)\n",
    "    loso_sensitivity = recall(preds_loso,ground_truth_loso)\n",
    "    loso_specificity = specificity(preds_loso,ground_truth_loso)\n",
    "    loso_f1 = f1_score(preds_loso,ground_truth_loso)\n",
    "    del preds_loso, ground_truth_loso\n",
    "\n",
    "    print(f'Loso_loss: {epoch_loss_loso.cpu().numpy()/(time_loso+1)}')\n",
    "    print(f'Loso_sensitivity: {loso_sensitivity}')\n",
    "    print(f'Loso_specificity: {loso_specificity}')\n",
    "    print(f'Loso_F1: {loso_f1} ')\n",
    "    print(f'Loso_AUROC: {loso_auroc} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loso_preds_cm = np.argmax(torch.nn.functional.softmax(preds_loso,dim=1).cpu().numpy(),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loso_preds_cm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "classes = ('Preictal', 'Ictal', 'Healthy')\n",
    "\n",
    "# Build confusion matrix\n",
    "cf_matrix = confusion_matrix(ground_truth_loso, loso_preds_cm)\n",
    "df_cm = pd.DataFrame(cf_matrix , index = [i for i in classes],\n",
    "                     columns = [i for i in classes])\n",
    "plt.figure(figsize = (12,7))\n",
    "sn.heatmap(df_cm, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics import ConfusionMatrix\n",
    "cm_loso = ConfusionMatrix('multiclass',num_classes=3)\n",
    "cm_loso(torch.tensor(loso_preds_cm),ground_truth_loso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics import ConfusionMatrix\n",
    "cm_loso = ConfusionMatrix('multiclass',num_classes=3)\n",
    "cm_loso(preds_loso,ground_truth_loso)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "88cc438b9c90976695678f0d6c20e4c06983b5710e6855b5b4390f60ecf93fe8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
