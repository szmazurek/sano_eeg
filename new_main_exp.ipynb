{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/code/sano/sano_eeg/sano_env/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-03-27 17:32:03.361234: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-27 17:32:03.667807: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-03-27 17:32:03.701808: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-03-27 17:32:03.701831: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-03-27 17:32:04.757740: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-27 17:32:04.757853: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-27 17:32:04.757860: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import os\n",
    "from dataclasses import dataclass\n",
    "import utils\n",
    "from torch_geometric_temporal import  DynamicGraphTemporalSignal,StaticGraphTemporalSignal, temporal_signal_split, DynamicGraphTemporalSignalBatch\n",
    "import networkx as nx\n",
    "from torch_geometric.utils import from_networkx\n",
    "import scipy\n",
    "import sklearn\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DynamicBatchSampler,DataLoader\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torchvision.ops import sigmoid_focal_loss\n",
    "from torch_geometric_temporal.nn.recurrent import DCRNN,  GConvGRU, A3TGCN, TGCN2, TGCN, A3TGCN2\n",
    "from torch_geometric_temporal.nn.attention import STConv\n",
    "from torchmetrics.classification import BinaryRecall,BinarySpecificity, AUROC, ROC\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "import pytorch_lightning as pl\n",
    "from torch_geometric.nn import GCNConv,BatchNorm,GATv2Conv\n",
    "from sklearn.model_selection import KFold,StratifiedKFold, StratifiedShuffleSplit\n",
    "from mne_features.univariate import compute_variance, compute_hjorth_complexity, compute_hjorth_mobility\n",
    "import torchaudio\n",
    "import mne_features\n",
    "import torch_geometric\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "from librosa import zero_crossings\n",
    "from scipy.signal import find_peaks, peak_prominences\n",
    "from statistics import mean\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_geometric.seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO think about using kwargs argument here to specify args for dataloader\n",
    "@dataclass\n",
    "class SeizureDataLoader:\n",
    "    npy_dataset_path: Path\n",
    "    event_tables_path: Path\n",
    "    plv_values_path: Path\n",
    "    loso_patient: str = None\n",
    "    sampling_f: int = 256\n",
    "    seizure_lookback: int = 600\n",
    "    sample_timestep: int = 5\n",
    "    inter_overlap: int = 0\n",
    "    ictal_overlap: int = 0\n",
    "    self_loops: bool = True\n",
    "    balance: bool = True\n",
    "    train_test_split: float = None\n",
    "    fft: bool = False\n",
    "    hjorth: bool = False\n",
    "    teager_keiser: bool = False\n",
    "    downsample: int = None\n",
    "    buffer_time: int = 15\n",
    "    batch_size: int = 32\n",
    "    smote: bool = False\n",
    "    \"\"\"Class to prepare dataloaders for eeg seizure perdiction from stored files.\n",
    "\n",
    "    Attributes:\n",
    "        npy_dataset_path {Path} -- Path to folder with dataset preprocessed into .npy files.\n",
    "        event_tables_path {Path} -- Path to folder with .csv files containing seizure events information for every patient.\n",
    "        loso_patient {str} -- Name of patient to be selected for LOSO valdiation, specified in format \"chb{patient_number}\"\",\n",
    "        eg. \"chb16\". (default: {None}).\n",
    "        samplin_f {int} -- Sampling frequency of the loaded eeg data. (default: {256}).\n",
    "        seizure_lookback {int} -- Time horizon to sample pre-seizure data (length of period before seizure) in seconds. \n",
    "        (default: {600}).\n",
    "        sample_timestep {int} -- Amounts of seconds analyzed in a single sample. (default: {5}).\n",
    "        overlap {int} -- Amount of seconds overlap between samples. (default: {0}).\n",
    "        self_loops {bool} -- Wheather to add self loops to nodes of the graph. (default: {True}).\n",
    "        shuffle {bool} --  Wheather to shuffle training samples.\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    assert (fft and hjorth) == False, \"When fft is True, hjorth should be False\"\n",
    "\n",
    "    def _get_event_tables(self, patient_name: str) -> tuple[dict, dict]:\n",
    "        \"\"\"Read events for given patient into start and stop times lists from .csv extracted files.\"\"\"\n",
    "\n",
    "        event_table_list = os.listdir(self.event_tables_path)\n",
    "        patient_event_tables = [\n",
    "            os.path.join(self.event_tables_path, ev_table)\n",
    "            for ev_table in event_table_list\n",
    "            if patient_name in ev_table\n",
    "        ]\n",
    "        patient_event_tables = sorted(patient_event_tables)\n",
    "        patient_start_table = patient_event_tables[\n",
    "            0\n",
    "        ]  ## done terribly, but it has to be so for win/linux compat\n",
    "        patient_stop_table = patient_event_tables[1]\n",
    "        start_events_dict = pd.read_csv(patient_start_table).to_dict(\"index\")\n",
    "        stop_events_dict = pd.read_csv(patient_stop_table).to_dict(\"index\")\n",
    "        return start_events_dict, stop_events_dict\n",
    "\n",
    "    def _get_recording_events(self, events_dict, recording) -> list[int]:\n",
    "        \"\"\"Read seizure times into list from event_dict\"\"\"\n",
    "        recording_list = list(events_dict[recording + \".edf\"].values())\n",
    "        recording_events = [int(x) for x in recording_list if not np.isnan(x)]\n",
    "        return recording_events\n",
    "\n",
    "    def _get_graph(self, n_nodes: int) -> nx.Graph:\n",
    "        \"\"\"Creates Networx fully connected graph with self loops\"\"\"\n",
    "        graph = nx.complete_graph(n_nodes)\n",
    "        self_loops = [[node, node] for node in graph.nodes()]\n",
    "        graph.add_edges_from(self_loops)\n",
    "        return graph\n",
    "\n",
    "    def _get_edge_weights_recording(self, plv_values: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Method that takes plv values for given recording and assigns them\n",
    "        as edge attributes to a fc graph.\"\"\"\n",
    "        graph = self._get_graph(plv_values.shape[0])\n",
    "        garph_dict = {}\n",
    "        for edge in graph.edges():\n",
    "            e_start, e_end = edge\n",
    "            garph_dict[edge] = {\"plv\": plv_values[e_start, e_end]}\n",
    "        nx.set_edge_attributes(graph, garph_dict)\n",
    "        edge_weights = from_networkx(graph).plv.numpy()\n",
    "        return edge_weights\n",
    "\n",
    "    def _get_edges(self):\n",
    "        \"\"\"Method to assign edge attributes. Has to be called AFTER get_dataset() method.\"\"\"\n",
    "        graph = self._get_graph(self._features.shape[1])\n",
    "        edges = np.expand_dims(from_networkx(graph).edge_index.numpy(), axis=0)\n",
    "        edges_per_sample_train = np.repeat(\n",
    "            edges, repeats=self._features.shape[0], axis=0\n",
    "        )\n",
    "        self._edges = torch.tensor(edges_per_sample_train)\n",
    "        if self.loso_patient is not None:\n",
    "            edges_per_sample_val = np.repeat(\n",
    "                edges, repeats=self._val_features.shape[0], axis=0\n",
    "            )\n",
    "            self._val_edges = torch.tensor(edges_per_sample_val)\n",
    "\n",
    "    def _array_to_tensor(self):\n",
    "        \"\"\"Method converting features, edges and weights to torch.tensors\"\"\"\n",
    "\n",
    "        self._features = torch.tensor(self._features, dtype=torch.float32)\n",
    "        self._labels = torch.tensor(self._labels)\n",
    "        self._time_labels = torch.tensor(self._time_labels)\n",
    "        self._edge_weights = torch.tensor(self._edge_weights)\n",
    "        if self.loso_patient is not None:\n",
    "            self._val_features = torch.tensor(self._val_features, dtype=torch.float32)\n",
    "            self._val_labels = torch.tensor(self._val_labels)\n",
    "            self._val_time_labels = torch.tensor(self._val_time_labels)\n",
    "            self._val_edge_weights = torch.tensor(self._val_edge_weights)\n",
    "\n",
    "    def _get_labels_count(self):\n",
    "        labels, counts = np.unique(self._labels, return_counts=True)\n",
    "        print(labels, counts)\n",
    "        self._label_counts = {}\n",
    "        for n, label in enumerate(labels):\n",
    "            self._label_counts[int(label)] = counts[n]\n",
    "        if self.loso_patient is not None:\n",
    "            labels, counts = np.unique(self._val_labels, return_counts=True)\n",
    "            self._val_label_counts = {}\n",
    "            for n, label in enumerate(labels):\n",
    "                self._val_label_counts[int(label)] = counts[n]\n",
    "\n",
    "    def _perform_features_fft(self):\n",
    "        self._features = torch.fft.rfft(self._features)\n",
    "        if self.loso_patient is not None:\n",
    "            self._val_features = torch.fft.rfft(self._val_features)\n",
    "\n",
    "    def _downsample_features(self):\n",
    "        resampler = torchaudio.transforms.Resample(self.sampling_f, self.downsample)\n",
    "        self._features = resampler(self._features)\n",
    "        if self.loso_patient is not None:\n",
    "            self._val_features = resampler(self._val_features)\n",
    "\n",
    "    def _calculate_hjorth_features(self, features):\n",
    "        new_features = np.array(\n",
    "            [\n",
    "                np.concatenate(\n",
    "                    [\n",
    "                        np.expand_dims(compute_variance(feature), 1),\n",
    "                        np.expand_dims(compute_hjorth_mobility(feature), 1),\n",
    "                        np.expand_dims(compute_hjorth_complexity(feature), 1),\n",
    "                        np.expand_dims([len(find_peaks(sig)[0]) for sig in feature], 1),\n",
    "                        np.expand_dims(np.sum(zero_crossings(feature), axis=1), 1),\n",
    "                        np.expand_dims(\n",
    "                            [\n",
    "                                peak_prominences(sig, find_peaks(sig)[0])[0].mean()\n",
    "                                for sig in feature\n",
    "                            ],\n",
    "                            1,\n",
    "                        ),\n",
    "                    ],\n",
    "                    axis=1,\n",
    "                )\n",
    "                for feature in features\n",
    "            ]\n",
    "        )\n",
    "        return new_features\n",
    "\n",
    "    def _features_to_data_list(self, features, edges, edge_weights, labels, time_label):\n",
    "        data_list = [\n",
    "            Data(\n",
    "                x=features[i],\n",
    "                edge_index=edges[i],\n",
    "                edge_attr=edge_weights[i],\n",
    "                y=labels[i],\n",
    "                # time=time_label[i],\n",
    "            )\n",
    "            for i in range(len(features))\n",
    "        ]\n",
    "        return data_list\n",
    "\n",
    "    def _split_data_list(self, data_list):\n",
    "        class_labels = torch.tensor(\n",
    "            [data.y.item() for data in data_list], dtype=torch.float32\n",
    "        ).unsqueeze(1)\n",
    "        patient_labels = torch.tensor(\n",
    "            np.expand_dims(self._patient_number, 1), dtype=torch.float32\n",
    "        )\n",
    "        class_labels_patient_labels = torch.cat([class_labels, patient_labels], dim=1)\n",
    "        splitter = StratifiedShuffleSplit(\n",
    "            n_splits=1, test_size=self.train_test_split, random_state=42\n",
    "        )\n",
    "        train_indices, val_indices = next(\n",
    "            splitter.split(data_list, class_labels_patient_labels)\n",
    "        )\n",
    "        self._indexes_to_later_delete = {\"train\": train_indices, \"val\": val_indices}\n",
    "        data_list_train = [data_list[i] for i in train_indices]\n",
    "        dataset_list_val = [data_list[i] for i in val_indices]\n",
    "        return data_list_train, dataset_list_val\n",
    "\n",
    "    def _initialize_dicts(self):\n",
    "        self._features_dict = {}\n",
    "        self._labels_dict = {}\n",
    "        self._time_labels_dict = {}\n",
    "        self._edge_weights_dict = {}\n",
    "        self._patient_number_dict = {}\n",
    "        if self.loso_patient:\n",
    "            self._val_features_dict = {}\n",
    "            self._val_labels_dict = {}\n",
    "            self._val_time_labels_dict = {}\n",
    "            self._val_edge_weights_dict = {}\n",
    "            self._val_patient_number_dict = {}\n",
    "\n",
    "    def _convert_dict_to_array(self):\n",
    "        self._features = np.concatenate(\n",
    "            [self._features_dict[key] for key in self._features_dict.keys()]\n",
    "        )\n",
    "        del self._features_dict\n",
    "        self._labels = np.concatenate(\n",
    "            [self._labels_dict[key] for key in self._labels_dict.keys()]\n",
    "        )\n",
    "        del self._labels_dict\n",
    "        self._time_labels = np.concatenate(\n",
    "            [self._time_labels_dict[key] for key in self._time_labels_dict.keys()]\n",
    "        )\n",
    "        del self._time_labels_dict\n",
    "        self._edge_weights = np.concatenate(\n",
    "            [self._edge_weights_dict[key] for key in self._edge_weights_dict.keys()]\n",
    "        )\n",
    "        del self._edge_weights_dict\n",
    "        self._patient_number = np.concatenate(\n",
    "            [self._patient_number_dict[key] for key in self._patient_number_dict.keys()]\n",
    "        )\n",
    "        del self._patient_number_dict\n",
    "        if self.loso_patient:\n",
    "            self._val_features = np.concatenate(\n",
    "                [self._val_features_dict[key] for key in self._val_features_dict.keys()]\n",
    "            )\n",
    "            del self._val_features_dict\n",
    "            self._val_labels = np.concatenate(\n",
    "                [self._val_labels_dict[key] for key in self._val_labels_dict.keys()]\n",
    "            )\n",
    "            del self._val_labels_dict\n",
    "            self._val_time_labels = np.concatenate(\n",
    "                [\n",
    "                    self._val_time_labels_dict[key]\n",
    "                    for key in self._val_time_labels_dict.keys()\n",
    "                ]\n",
    "            )\n",
    "            del self._val_time_labels_dict\n",
    "            self._val_edge_weights = np.concatenate(\n",
    "                [\n",
    "                    self._val_edge_weights_dict[key]\n",
    "                    for key in self._val_edge_weights_dict.keys()\n",
    "                ]\n",
    "            )\n",
    "            del self._val_edge_weights_dict\n",
    "            self._val_patient_number = np.concatenate(\n",
    "                [\n",
    "                    self._val_patient_number_dict[key]\n",
    "                    for key in self._val_patient_number_dict.keys()\n",
    "                ]\n",
    "            )\n",
    "            del self._val_patient_number_dict\n",
    "\n",
    "    def _balance_classes(self):\n",
    "        negative_label = self._label_counts[0]\n",
    "        positive_label = self._label_counts[1]\n",
    "        \n",
    "        print(f\"Number of negative samples pre removal {negative_label}\")\n",
    "        print(f\"Number of positive samples pre removal {positive_label}\")\n",
    "        imbalance = negative_label - positive_label\n",
    "        print(f\"imbalance {imbalance}\")\n",
    "        negative_indices = np.where(self._labels == 0)[0]\n",
    "        indices_to_discard = np.random.choice(\n",
    "            negative_indices, size=imbalance, replace=False\n",
    "        )\n",
    "\n",
    "        self._features = np.delete(self._features, obj=indices_to_discard, axis=0)\n",
    "        self._labels = np.delete(self._labels, obj=indices_to_discard, axis=0)\n",
    "        self._time_labels = np.delete(self._time_labels, obj=indices_to_discard, axis=0)\n",
    "        self._edge_weights = np.delete(\n",
    "            self._edge_weights, obj=indices_to_discard, axis=0\n",
    "        )\n",
    "        self._patient_number = np.delete(self._patient_number, obj=indices_to_discard,axis=0)\n",
    "\n",
    "    def _standardize_data(self, features, labels, loso_features=None):\n",
    "        indexes = np.where(labels == 0)[0]  \n",
    "        features_negative = features[indexes]\n",
    "        channel_mean = features_negative.mean()\n",
    "        channel_std = features_negative.std()\n",
    "        # if features_negative.shape[0] == 1:\n",
    "        #     channel_mean = features_negative.mean(2).squeeze()\n",
    "        #     channel_std = features_negative.std(2).squeeze()\n",
    "        # else:\n",
    "        #    # print(features_negative[0].shape)\n",
    "        #     channel_mean = features_negative.mean(axis=0).mean(1)\n",
    "        #     channel_std = features_negative.std(axis=0).std(1)\n",
    "        for i in range(features.shape[0]):\n",
    "            for n in range(features.shape[1]):\n",
    "                #        features[i,n,:] = (features[i,n,:] - channel_mean[n])/channel_std[n]\n",
    "                features[i, n, :] = (features[i, n, :] - channel_mean) / channel_std\n",
    "        if (\n",
    "            loso_features is not None\n",
    "        ):  ## standardize loso features with the same values as for training data\n",
    "            for i in range(loso_features.shape[0]):\n",
    "                for n in range(loso_features.shape[1]):\n",
    "                    loso_features[i, n, :] = (\n",
    "                        loso_features[i, n, :] - channel_mean\n",
    "                    ) / channel_std\n",
    "\n",
    "    def _min_max_scale(self, features, labels):\n",
    "        indexes = np.where(labels == 0)[0]  ## changed from 0!\n",
    "        features_negative = features[indexes]\n",
    "\n",
    "        channel_min = features_negative.min(axis=0).min(1)\n",
    "        channel_max = features_negative.max(axis=0).max(1)\n",
    "        for i in range(features.shape[0]):\n",
    "            for n in range(features.shape[1]):\n",
    "                features[i, n, :] = (features[i, n, :] - channel_min[n]) / (\n",
    "                    channel_max[n] - channel_min[n]\n",
    "                )\n",
    "                # features[i,n,:] = (features[i,n,:] - channel_min)/(channel_max - channel_min)\n",
    "\n",
    "    def _apply_smote(self, features, labels):\n",
    "        dim_1 = np.array(features).shape[0]\n",
    "        dim_2 = np.array(features).shape[1]\n",
    "        dim_3 = np.array(features).shape[2]\n",
    "\n",
    "        new_dim = dim_1 * dim_2\n",
    "        new_x_train = features.reshape(new_dim, dim_3)\n",
    "        new_y_train = []\n",
    "        for i in range(len(labels)):\n",
    "            new_y_train.extend([labels[i]] * dim_2)\n",
    "\n",
    "        new_y_train = np.array(new_y_train)\n",
    "\n",
    "        # transform the dataset\n",
    "        oversample = SMOTE(random_state=42)\n",
    "        x_train, y_train = oversample.fit_resample(new_x_train, new_y_train)\n",
    "        x_train_smote = x_train.reshape(int(x_train.shape[0] / dim_2), dim_2, dim_3)\n",
    "        y_train_smote = []\n",
    "        for i in range(int(x_train.shape[0] / dim_2)):\n",
    "            # print(i)\n",
    "            value_list = list(y_train.reshape(int(x_train.shape[0] / dim_2), dim_2)[i])\n",
    "            # print(list(set(value_list)))\n",
    "            y_train_smote.extend(list(set(value_list)))\n",
    "            ## Check: if there is any different value in a list\n",
    "            if len(set(value_list)) != 1:\n",
    "                print(\n",
    "                    \"\\n\\n********* STOP: THERE IS SOMETHING WRONG IN TRAIN ******\\n\\n\"\n",
    "                )\n",
    "        y_train_smote = np.array(y_train_smote)\n",
    "        # print(np.unique(y_train_smote,return_counts=True))\n",
    "        return x_train_smote, y_train_smote\n",
    "\n",
    "    def _get_labels_features_edge_weights_seizure(self, patient):\n",
    "        \"\"\"Prepare features, labels, time labels and edge wieghts for training and\n",
    "        optionally validation data.\"\"\"\n",
    "\n",
    "        event_tables = self._get_event_tables(\n",
    "            patient\n",
    "        )  # extract start and stop of seizure for patient\n",
    "        patient_path = os.path.join(self.npy_dataset_path, patient)\n",
    "        recording_list = os.listdir(patient_path)\n",
    "        for record in recording_list:  # iterate over recordings for a patient\n",
    "            # if \"seizures_\" not in record:\n",
    "            #     ## skip non-seizure files\n",
    "            #     continue\n",
    "\n",
    "            recording_path = os.path.join(patient_path, record)\n",
    "            record = record.replace(\n",
    "                \"seizures_\", \"\"\n",
    "            )  ## some magic to get it properly working with event tables\n",
    "            record_id = record.split(\".npy\")[0]  #  get record id\n",
    "            start_event_tables = self._get_recording_events(\n",
    "                event_tables[0], record_id\n",
    "            )  # get start events\n",
    "            stop_event_tables = self._get_recording_events(\n",
    "                event_tables[1], record_id\n",
    "            )  # get stop events\n",
    "            data_array = np.load(recording_path)  # load the recording\n",
    "\n",
    "            plv_edge_weights = np.expand_dims(\n",
    "                self._get_edge_weights_recording(\n",
    "                    np.load(os.path.join(self.plv_values_path, patient, record))\n",
    "                ),\n",
    "                axis=0,\n",
    "            )\n",
    "\n",
    "            features, labels, time_labels = utils.extract_training_data_and_labels(\n",
    "                data_array,\n",
    "                start_event_tables,\n",
    "                stop_event_tables,\n",
    "                fs=self.sampling_f,\n",
    "                seizure_lookback=self.seizure_lookback,\n",
    "                sample_timestep=self.sample_timestep,\n",
    "                inter_overlap=self.inter_overlap,\n",
    "                ictal_overlap=self.ictal_overlap,\n",
    "                buffer_time=self.buffer_time,\n",
    "            )\n",
    "\n",
    "            if features is None:\n",
    "                # print(\n",
    "                #     f\"Skipping the recording {record} patients {patient} cuz features are none\"\n",
    "                # )\n",
    "                continue\n",
    "            if len(np.unique(labels)) != 2:\n",
    "                # print(\n",
    "                #     f\"Skipping the recording {record} patients {patient} cuz no seizure samples\"\n",
    "                # )\n",
    "                continue\n",
    "\n",
    "            features = features.squeeze()\n",
    "\n",
    "            if (self.smote):  \n",
    "               # print(f\"Applying smote on loso patient {patient} features\")\n",
    "                smote_start = time.time()\n",
    "                features, labels = self._apply_smote(features, labels)\n",
    "                logging.info(f\"Applied one smote in {time.time() - smote_start} for patient {patient}\")\n",
    "\n",
    "            time_labels = np.expand_dims(time_labels.astype(np.int32), 1)\n",
    "            labels = labels.reshape((labels.shape[0], 1)).astype(np.float32)\n",
    "            patient_number = torch.full(\n",
    "                [labels.shape[0]],\n",
    "                int(\"\".join(x for x in patient if x.isdigit())),\n",
    "                dtype=torch.float32,\n",
    "            )\n",
    "            if patient == self.loso_patient:\n",
    "                #logging.info(f\"Adding recording {record} of patient {patient}\")\n",
    "                try:\n",
    "                    self._val_features_dict[patient] = np.concatenate(\n",
    "                        (self._val_features_dict[patient], features), axis=0\n",
    "                    )\n",
    "                    self._val_labels_dict[patient] = np.concatenate(\n",
    "                        (self._val_labels_dict[patient], labels), axis=0\n",
    "                    )\n",
    "                    self._val_time_labels_dict[patient] = np.concatenate(\n",
    "                        (self._val_time_labels_dict[patient], time_labels), axis=0\n",
    "                    )\n",
    "                    self._val_edge_weights_dict[patient] = np.concatenate(\n",
    "                        (\n",
    "                            self._val_edge_weights_dict[patient],\n",
    "                            np.repeat(plv_edge_weights, features.shape[0], axis=0),\n",
    "                        )\n",
    "                    )\n",
    "\n",
    "                    self._val_patient_number_dict[patient] = np.concatenate(\n",
    "                        (self._val_patient_number_dict[patient], patient_number)\n",
    "                    )\n",
    "                except:\n",
    "                    self._val_features_dict[patient] = features\n",
    "                    self._val_labels_dict[patient] = labels\n",
    "                    self._val_time_labels_dict[patient] = time_labels\n",
    "                    self._val_edge_weights_dict[patient] = np.repeat(\n",
    "                        plv_edge_weights, features.shape[0], axis=0\n",
    "                    )\n",
    "                    self._val_patient_number_dict[patient] = patient_number\n",
    "\n",
    "            else:\n",
    "                try:\n",
    "                    self._features_dict[patient] = np.concatenate(\n",
    "                        (self._features_dict[patient], features), axis=0\n",
    "                    )\n",
    "                    self._labels_dict[patient] = np.concatenate(\n",
    "                        (self._labels_dict[patient], labels), axis=0\n",
    "                    )\n",
    "                    self._time_labels_dict[patient] = np.concatenate(\n",
    "                        (self._time_labels_dict[patient], time_labels), axis=0\n",
    "                    )\n",
    "                    self._edge_weights_dict[patient] = np.concatenate(\n",
    "                        (\n",
    "                            self._edge_weights_dict[patient],\n",
    "                            np.repeat(plv_edge_weights, features.shape[0], axis=0),\n",
    "                        )\n",
    "                    )\n",
    "\n",
    "                    self._patient_number_dict[patient] = np.concatenate(\n",
    "                        (self._patient_number_dict[patient], patient_number)\n",
    "                    )\n",
    "                except:\n",
    "                    #print(\"Creating initial attributes\")\n",
    "                    self._features_dict[patient] = features\n",
    "                    self._labels_dict[patient] = labels\n",
    "                    self._time_labels_dict[patient] = time_labels\n",
    "                    self._edge_weights_dict[patient] = np.repeat(\n",
    "                        plv_edge_weights, features.shape[0], axis=0\n",
    "                    )\n",
    "                    self._patient_number_dict[patient] = patient_number\n",
    "\n",
    "    def _get_labels_features_edge_weights_interictal(\n",
    "        self, samples_recording: int = None\n",
    "    ):\n",
    "        patient_list = os.listdir(self.npy_dataset_path)\n",
    "        interictal_samples = len(np.where(self._labels == 0))\n",
    "        loso_interictal_samples = len(np.where(self._val_labels == 0))\n",
    "        for patient in patient_list:\n",
    "            patient_path = os.path.join(self.npy_dataset_path, patient)\n",
    "            ## get all non-seizure recordings\n",
    "            recording_list = [\n",
    "                recording\n",
    "                for recording in os.listdir(patient_path)\n",
    "                if not \"seizures_\" in recording\n",
    "            ]\n",
    "            if not samples_recording:\n",
    "                if patient == self.loso_patient:\n",
    "                    samples_per_recording = int(\n",
    "                        loso_interictal_samples / len(recording_list)\n",
    "                    )\n",
    "                else:\n",
    "                    samples_per_recording = int(\n",
    "                        interictal_samples / len(recording_list)\n",
    "                    )\n",
    "            else:\n",
    "                samples_per_recording = samples_recording\n",
    "            for recording in recording_list:\n",
    "                recording_path = os.path.join(patient_path, recording)\n",
    "                data_array = np.load(recording_path)\n",
    "\n",
    "    # TODO define a method to create edges and calculate plv to get weights\n",
    "    def get_dataset(self) -> DynamicGraphTemporalSignal:\n",
    "        \"\"\"Creating graph data iterators. The iterator yelds dynamic, weighted and undirected graphs\n",
    "        containing self loops. Every node represents one electrode in EEG. The graph is fully connected,\n",
    "        edge weights are calculated for every EEG recording as PLV between channels (edge weight describes\n",
    "        the \"strength\" of connectivity between two channels in a recording). Node features are values of\n",
    "        channel voltages in time. Features are of shape [nodes,features,timesteps].\n",
    "\n",
    "        Returns:\n",
    "            train_dataset {DynamicGraphTemporalSignal} -- Training data iterator.\n",
    "            valid_dataset {DynamicGraphTemporalSignal} -- Validation data iterator (only if loso_patient is\n",
    "            specified in class constructor).\n",
    "        \"\"\"\n",
    "        ### TODO rozkminić o co chodzi z tym całym time labels - na razie wartość liczbowa która tam wchodzi\n",
    "        ### to shape atrybutu time_labels\n",
    "\n",
    "        self._initialize_dicts()\n",
    "        patient_list = os.listdir(self.npy_dataset_path)\n",
    "        start_time = time.time()\n",
    "        if self.smote:\n",
    "            for patient in patient_list:\n",
    "                self._get_labels_features_edge_weights_seizure(patient)\n",
    "        else:\n",
    "            Parallel(n_jobs=6, require=\"sharedmem\")(\n",
    "                delayed(self._get_labels_features_edge_weights_seizure)(patient)\n",
    "                for patient in patient_list\n",
    "            )\n",
    "        \n",
    "        self._convert_dict_to_array()\n",
    "        self._get_labels_count()\n",
    "        if self.balance:\n",
    "            self._balance_classes()\n",
    "        \n",
    "        print(f\"Finished processing in {time.time() - start_time} seconds\")\n",
    "        print(f\"Features shape {self._features.shape}\")\n",
    "\n",
    "        start_time_preprocessing = time.time()\n",
    "        self._standardize_data(self._features, self._labels, self._val_features)\n",
    "        \n",
    "        self._get_edges()\n",
    "        #self._get_labels_count()\n",
    "        if self.hjorth:\n",
    "            self._features = self._calculate_hjorth_features(self._features)\n",
    "        self._array_to_tensor()\n",
    "        if self.downsample and not self.hjorth:\n",
    "            self._downsample_features()\n",
    "        if self.fft:\n",
    "            self._perform_features_fft()\n",
    "\n",
    "        train_dataset = torch.utils.data.TensorDataset(\n",
    "            self._features,\n",
    "            self._edges,\n",
    "            self._edge_weights,\n",
    "            self._labels,\n",
    "            # self._time_labels,\n",
    "        )\n",
    "        if self.train_test_split is not None:\n",
    "            if self.fft or self.hjorth:\n",
    "                data_list = self._features_to_data_list(\n",
    "                    self._features,\n",
    "                    self._edges,\n",
    "                    self._edge_weights,\n",
    "                    self._labels,\n",
    "                    self._time_labels,\n",
    "                )\n",
    "                train_data_list, val_data_list = self._split_data_list(data_list)\n",
    "                label_count = np.unique(\n",
    "                    [data.y.item() for data in train_data_list], return_counts=True\n",
    "                )[1]\n",
    "                self.alpha = label_count[0] / label_count[1]\n",
    "                loaders = [\n",
    "                    DataLoader(\n",
    "                        train_data_list,\n",
    "                        batch_size=self.batch_size,\n",
    "                        shuffle=True,\n",
    "                        drop_last=False,\n",
    "                    ),\n",
    "                    DataLoader(\n",
    "                        val_data_list,\n",
    "                        batch_size=len(val_data_list),\n",
    "                        shuffle=False,\n",
    "                        drop_last=False,\n",
    "                    ),\n",
    "                ]\n",
    "\n",
    "            else:\n",
    "                train_dataset, val_dataset = torch.utils.data.random_split(\n",
    "                    train_dataset,\n",
    "                    [1 - self.train_test_split, self.train_test_split],\n",
    "                    generator=torch.Generator().manual_seed(42),\n",
    "                )\n",
    "\n",
    "                train_dataloader = torch.utils.data.DataLoader(\n",
    "                    train_dataset,\n",
    "                    batch_size=self.batch_size,\n",
    "                    shuffle=True,\n",
    "                    # num_workers=2,\n",
    "                    # pin_memory=True,\n",
    "                    # prefetch_factor=4,\n",
    "                    drop_last=False,\n",
    "                )\n",
    "\n",
    "                val_dataloader = torch.utils.data.DataLoader(\n",
    "                    val_dataset,\n",
    "                    batch_size=self.batch_size,\n",
    "                    shuffle=False,\n",
    "                    # num_workers=2,\n",
    "                    # pin_memory=True,\n",
    "                    # prefetch_factor=4,\n",
    "                    drop_last=False,\n",
    "                )\n",
    "                loaders = [train_dataloader, val_dataloader]\n",
    "        else:\n",
    "            if self.fft or self.hjorth:\n",
    "                train_data_list = self._features_to_data_list(\n",
    "                    self._features,\n",
    "                    self._edges,\n",
    "                    self._edge_weights,\n",
    "                    self._labels,\n",
    "                    self._time_labels,\n",
    "                )\n",
    "                loaders = [\n",
    "                    DataLoader(\n",
    "                        train_data_list,\n",
    "                        batch_size=self.batch_size,\n",
    "                        shuffle=True,\n",
    "                        drop_last=False,\n",
    "                    )\n",
    "                ]\n",
    "            else:\n",
    "                train_dataloader = torch.utils.data.DataLoader(\n",
    "                    train_dataset,\n",
    "                    batch_size=self.batch_size,\n",
    "                    shuffle=True,\n",
    "                    # num_workers=2,\n",
    "                    # pin_memory=True,\n",
    "                    # prefetch_factor=4,\n",
    "                    drop_last=False,\n",
    "                )\n",
    "                loaders = [train_dataloader]\n",
    "        if self.loso_patient:\n",
    "            if self.hjorth:\n",
    "                self._val_features = self._calculate_hjorth_features(self._val_features)\n",
    "\n",
    "            if self.fft or self.hjorth:\n",
    "                loso_data_list = self._features_to_data_list(\n",
    "                    self._val_features,\n",
    "                    self._val_edges,\n",
    "                    self._val_edge_weights,\n",
    "                    self._val_labels,\n",
    "                    self._val_time_labels,\n",
    "                )\n",
    "                print(\"Preprocessing time: \", time.time() - start_time_preprocessing)\n",
    "                return (\n",
    "                    *loaders,\n",
    "                    DataLoader(\n",
    "                        loso_data_list,\n",
    "                        batch_size=len(loso_data_list),\n",
    "                        shuffle=False,\n",
    "                        drop_last=False,\n",
    "                    ),\n",
    "                )\n",
    "            loso_dataset = torch.utils.data.TensorDataset(\n",
    "                self._val_features,\n",
    "                self._val_edges,\n",
    "                self._val_edge_weights,\n",
    "                self._val_labels,\n",
    "                #  self._val_time_labels,\n",
    "            )\n",
    "            loso_dataloader = torch.utils.data.DataLoader(\n",
    "                loso_dataset,\n",
    "                batch_size=self.batch_size,\n",
    "                shuffle=False,\n",
    "                # pin_memory=True,\n",
    "                # num_workers=2,\n",
    "                # prefetch_factor=4,\n",
    "                drop_last=False,\n",
    "            )\n",
    "\n",
    "            return (*loaders, loso_dataloader)\n",
    "\n",
    "        return (*loaders,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecurrentGCN(torch.nn.Module):\n",
    "    def __init__(self, timestep,sfreq, n_nodes=18,batch_size=32):\n",
    "        super(RecurrentGCN, self).__init__()\n",
    "        self.n_nodes = n_nodes\n",
    "        self.out_features = 128\n",
    "        self.recurrent_1 = A3TGCN2(sfreq*timestep,32, add_self_loops=True,improved=False)\n",
    "        self.recurrent_2 = GCNConv(32,64,add_self_loops=True,improved=False)\n",
    "        self.recurrent_3 = GCNConv(64,128,add_self_loops=True,improved=False)\n",
    "        self.fc1 = torch.nn.Linear(n_nodes*128, 64)\n",
    "        self.fc2 = torch.nn.Linear(64, 32)\n",
    "        self.fc3 = torch.nn.Linear(32, 16)\n",
    "        self.fc4 = torch.nn.Linear(16, 1)\n",
    "        self.flatten = torch.nn.Flatten(start_dim=0)\n",
    "        self.dropout = torch.nn.Dropout()\n",
    "    def forward(self, x, edge_index,edge_weight,batch):\n",
    "        x = torch.squeeze(x)\n",
    "        h = self.recurrent_1(x, edge_index=edge_index, edge_weight = edge_weight)\n",
    "        h = torch.nn.BatchNorm1d(32)(h)\n",
    "        h = F.leaky_relu(h)\n",
    "        h = self.recurrent_2(h, edge_index,edge_weight)\n",
    "        h = torch.nn.BatchNorm1d(64)(h)\n",
    "        h = F.leaky_relu(h)\n",
    "        h = self.recurrent_3(h, edge_index,edge_weight)\n",
    "        h = torch.nn.BatchNorm1d(128)(h)\n",
    "        h = F.leaky_relu(h)\n",
    "        h = global_mean_pool(h,batch)\n",
    "        h = self.dropout(h)\n",
    "        h = self.fc1(h)\n",
    "        h = F.leaky_relu(h)\n",
    "        h = self.dropout(h)\n",
    "        h = self.fc2(h)\n",
    "        h = F.leaky_relu(h)\n",
    "        h = self.dropout(h)\n",
    "        h = self.fc3(h)\n",
    "        h = F.leaky_relu(h)\n",
    "        h = self.dropout(h)\n",
    "        h = self.fc4(h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GATv2(torch.nn.Module):\n",
    "    def __init__(self, timestep,sfreq, n_nodes=18,batch_size=32):\n",
    "        super(GATv2, self).__init__()\n",
    "        self.n_nodes = n_nodes\n",
    "        self.out_features = 128\n",
    "        n_heads = 4\n",
    "        self.recurrent_1 = GATv2Conv(int((sfreq*timestep/2)+1),32,heads=n_heads,negative_slope=0.01,dropout=0.4, add_self_loops=True,improved=True,edge_dim=1)\n",
    "        self.recurrent_2 = GATv2Conv(128,64,heads=n_heads,negative_slope=0.01,dropout=0.4, add_self_loops=True,improved=True,edge_dim=1)\n",
    "\n",
    "        # int((sfreq*timestep/2)+1)\n",
    "        # for children in list(self.recurrent_1.children()):\n",
    "        #     for param in list(children.named_parameters()):\n",
    "        #         if param[0] == 'weight':\n",
    "        #             nn.init.kaiming_uniform_(param[1], a=0.01)\n",
    "        #nn.init.kaiming_uniform_(self.recurrent_1.att,a=0.01)\n",
    "        self.fc1 = torch.nn.Linear(64*n_heads, 128)\n",
    "        nn.init.kaiming_uniform_(self.fc1.weight,a=0.01)\n",
    "        self.fc2 = torch.nn.Linear(128, 64)\n",
    "        nn.init.kaiming_uniform_(self.fc2.weight,a=0.01)\n",
    "        self.fc3 = torch.nn.Linear(64, 1)\n",
    "        nn.init.kaiming_uniform_(self.fc3.weight,a=0.01)\n",
    "        self.fc4 = torch.nn.Linear(128, 1)\n",
    "        self.connectivity = torch.nn.Linear(sfreq*timestep*n_nodes,324)\n",
    "        self.connectivity_2 = torch.nn.Linear(sfreq*timestep,324)\n",
    "        self.batch_norm_1 = torch.nn.BatchNorm1d(32*n_heads)\n",
    "        self.batch_norm_2 = torch.nn.BatchNorm1d(64*n_heads)\n",
    "        self.dropout = torch.nn.Dropout()\n",
    "    def forward(self, x, edge_index, edge_attr,batch):\n",
    "        h = self.recurrent_1(x, edge_index=edge_index, edge_attr = edge_attr)\n",
    "        h = self.batch_norm_1(h)\n",
    "        h = F.leaky_relu(h)\n",
    "        #h = global_mean_pool(h,batch)\n",
    "   \n",
    "        h = self.recurrent_2(h, edge_index=edge_index, edge_attr = edge_attr)\n",
    "        h = self.batch_norm_2(h)\n",
    "        h = F.leaky_relu(h)\n",
    "        h = global_mean_pool(h,batch)\n",
    "    \n",
    "        h = self.dropout(h)\n",
    "        h = self.fc1(h)\n",
    "        h = F.leaky_relu(h)\n",
    "        h = self.dropout(h)\n",
    "        h = self.fc2(h)\n",
    "        h = F.leaky_relu(h)\n",
    "        h = self.dropout(h)\n",
    "        h = self.fc3(h)\n",
    "        # h = F.leaky_relu(h)\n",
    "        # h = self.dropout(h)\n",
    "        # h = self.fc4(h)\n",
    "        return h.squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1.] [15131  1711]\n",
      "Finished processing in 19.281068325042725 seconds\n",
      "Features shape (16842, 18, 1536)\n",
      "Preprocessing time:  12.738569736480713\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8.843366452367038"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TIMESTEP = 6\n",
    "INTER_OVERLAP = 0\n",
    "ICTAL_OVERLAP = 0\n",
    "SFREQ = 256\n",
    "torch_geometric.seed_everything(42)\n",
    "dataloader = SeizureDataLoader(\n",
    "    npy_dataset_path=Path('data/npy_data'),\n",
    "    event_tables_path=Path('data/event_tables'),\n",
    "    plv_values_path=Path('data/plv_arrays'),\n",
    "    loso_patient='chb20',\n",
    "    sampling_f=SFREQ,\n",
    "    seizure_lookback=600,\n",
    "    sample_timestep= TIMESTEP,\n",
    "    inter_overlap=INTER_OVERLAP,\n",
    "    ictal_overlap=ICTAL_OVERLAP,\n",
    "    self_loops=False,\n",
    "    balance=False,\n",
    "    train_test_split=0.05,\n",
    "    fft=True,\n",
    "    hjorth=False,\n",
    "    teager_keiser=False,\n",
    "    downsample=60,\n",
    "    batch_size=64,\n",
    "    buffer_time=60,\n",
    "    smote=False,\n",
    "    )\n",
    "train_loader,valid_loader, loso_loader =dataloader.get_dataset() #,loso_loader\n",
    "alpha = list(dataloader._label_counts.values())[0]/list(dataloader._label_counts.values())[1]\n",
    "alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.843366452367038"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = dataloader._features\n",
    "labels = dataloader._labels\n",
    "indexes = np.where(dataloader._val_labels == 0)[0]\n",
    "features_negative = features[indexes]\n",
    "indexes_positive = np.where(dataloader._val_labels == 1)[0]\n",
    "features_positive = features[indexes_positive]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## compare samples 14323 negative and 2543 positive - for the standarization they were the same amplitudes\n",
    "## how do I choose criteria for rejecting a sample when it is flat most of the time?\n",
    "## wavelet coef energy is useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "hjorth_features_negative = mne_features.univariate.compute_variance(features_negative[0].numpy())\n",
    "hjorth_features_positive = mne_features.univariate.compute_variance(features_positive[1].numpy())\n",
    "plt.plot(hjorth_features_negative)\n",
    "plt.plot(hjorth_features_positive)\n",
    "plt.legend(['negative','positive'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "hjorth_features_negative = mne_features.univariate.compute_hjorth_complexity(features_negative[0].numpy())\n",
    "hjorth_features_positive = mne_features.univariate.compute_hjorth_complexity(features_positive[2].numpy())\n",
    "plt.plot(hjorth_features_negative)\n",
    "plt.plot(hjorth_features_positive)\n",
    "plt.legend(['negative','positive'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "hjorth_features_negative = mne_features.univariate.compute_hjorth_mobility(features_negative[1].numpy())\n",
    "hjorth_features_positive = mne_features.univariate.compute_hjorth_mobility(features_positive[2].numpy())\n",
    "plt.plot(hjorth_features_negative)\n",
    "plt.plot(hjorth_features_positive)\n",
    "plt.legend(['negative','positive'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "fig,ax = plt.subplots(18,1,figsize=(20,20))\n",
    "for i in range(18):\n",
    "    \n",
    "    ax[i].scatter(y=features_negative[17,i,1],x =[1])\n",
    "    ax[i].scatter(y=features_positive[0,i,1],x =[1])\n",
    "    ax[i].set_title(f'Channel {i+1}')\n",
    "plt.legend(['negative','positive'])\n",
    "plt.show()\n",
    "\n",
    "# fig,ax = plt.subplots(18,1,figsize=(10,10))\n",
    "# for i in range(18):\n",
    "#     ax [i].plot(features_positive[865,i,:])\n",
    "#     ax[i].set_title(f'Channel {i+1}')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "fig,ax = plt.subplots(18,1,figsize=(10,10))\n",
    "for i in range(18):\n",
    "    \n",
    "    ax[i].plot(features_negative[6532,i,:])\n",
    "    ax[i].plot(features_positive[7000,i,:])\n",
    "    ax[i].set_title(f'Channel {i+1}')\n",
    "plt.legend(['negative','positive'])\n",
    "plt.show()\n",
    "\n",
    "# fig,ax = plt.subplots(18,1,figsize=(10,10))\n",
    "# for i in range(18):\n",
    "#     ax [i].plot(features_positive[865,i,:])\n",
    "#     ax[i].set_title(f'Channel {i+1}')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_loso = dataloader._val_features.numpy()\n",
    "indexes_loso = np.where(dataloader._val_labels == 0)[0]\n",
    "features_negative_loso = features_loso[indexes_loso]\n",
    "indexes_positive_loso = np.where(dataloader._val_labels == 1)[0]\n",
    "features_positive_loso = features_loso[indexes_positive_loso]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "channel_mean_loso = np.mean(features_negative_loso,axis=0).mean(1)\n",
    "channel_std_loso = np.std(features_negative_loso,axis=0).std(1)\n",
    "for i in range(features_negative_loso.shape[0]):\n",
    "    for n in range(features_negative_loso.shape[1]):\n",
    "        features_negative_loso[i,n,:] = (features_negative_loso[i,n,:] - channel_mean_loso[n])/channel_std_loso[n]\n",
    "for i in range(features_positive_loso.shape[0]):\n",
    "    for n in range(features_positive_loso.shape[1]):\n",
    "        features_positive_loso[i,n,:] = (features_positive_loso[i,n,:] - channel_mean_loso[n])/channel_std_loso[n]\n",
    "fig,ax = plt.subplots(5,1,figsize=(10,10))\n",
    "for i in range(5):\n",
    "    ax[i].plot(features_negative_loso[3,i,:])\n",
    "    ax[i].set_title(f'Channel {i+1}')\n",
    "plt.show()\n",
    "\n",
    "fig,ax = plt.subplots(5,1,figsize=(10,10))\n",
    "for i in range(5):\n",
    "    ax[i].plot(features_positive_loso[12,i,:])\n",
    "    ax[i].set_title(f'Channel {i+1}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_std = np.std(features_negative,axis=0).mean(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "channel_mean = np.mean(features_negative,axis=0).mean(1)\n",
    "channel_std = np.std(features_negative,axis=0).std(1)\n",
    "for i in range(features_negative.shape[0]):\n",
    "    for n in range(features_negative.shape[1]):\n",
    "        features_negative[i,n,:] = (features_negative[i,n,:] - channel_mean[n])/channel_std[n]\n",
    "for i in range(features_positive.shape[0]):\n",
    "    for n in range(features_positive.shape[1]):\n",
    "        features_positive[i,n,:] = (features_positive[i,n,:] - channel_mean[n])/channel_std[n]\n",
    "fig,ax = plt.subplots(5,1,figsize=(10,10))\n",
    "for i in range(5):\n",
    "    ax[i].plot(features_positive[1,i,:])\n",
    "    ax[i].set_title(f'Channel {i+1}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.explain import Explainer, AttentionExplainer, ExplainerConfig\n",
    "explainer = Explainer(\n",
    "    model=model,\n",
    "    algorithm=AttentionExplainer(),\n",
    "    explanation_type='model',\n",
    "   # node_mask_type='attributes',\n",
    "    edge_mask_type='object',\n",
    "    model_config=dict(\n",
    "        mode='binary_classification',\n",
    "        task_level='graph',\n",
    "        return_type='raw',  # Model returns log probabilities.\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecurrentGCN(torch.nn.Module):\n",
    "    def __init__(self, timestep,sfreq, n_nodes=18,batch_size=32):\n",
    "        super(RecurrentGCN, self).__init__()\n",
    "        self.n_nodes = n_nodes\n",
    "        self.out_features = 128\n",
    "        self.recurrent_1 = GCNConv(3,32, add_self_loops=True,improved=False)\n",
    "        self.recurrent_2 = GCNConv(32,64,add_self_loops=True,improved=False)\n",
    "        self.recurrent_3 = GCNConv(64,128,add_self_loops=True,improved=False)\n",
    "        self.fc1 = torch.nn.Linear(128, 64)\n",
    "        self.fc2 = torch.nn.Linear(64, 32)\n",
    "        self.fc3 = torch.nn.Linear(32, 16)\n",
    "        self.fc4 = torch.nn.Linear(16, 1)\n",
    "        self.batch_norm_1 = torch.nn.BatchNorm1d(32)\n",
    "        self.batch_norm_2 = torch.nn.BatchNorm1d(64)\n",
    "        self.batch_norm_3 = torch.nn.BatchNorm1d(128)\n",
    "        self.flatten = torch.nn.Flatten(start_dim=0)\n",
    "        self.dropout = torch.nn.Dropout()\n",
    "    def forward(self, x, edge_index,edge_weight,batch):\n",
    "        x = torch.squeeze(x)\n",
    "        h = self.recurrent_1(x, edge_index=edge_index, edge_weight = edge_weight)\n",
    "        h = self.batch_norm_1(h)\n",
    "        h = F.leaky_relu(h)\n",
    "        h = self.recurrent_2(h, edge_index,edge_weight)\n",
    "        h = self.batch_norm_2(h)\n",
    "        h = F.leaky_relu(h)\n",
    "        h = self.recurrent_3(h, edge_index,edge_weight)\n",
    "        h = self.batch_norm_3(h)\n",
    "        h = F.leaky_relu(h)\n",
    "        h = global_mean_pool(h,batch)\n",
    "        h = self.dropout(h)\n",
    "        h = self.fc1(h)\n",
    "        h = F.leaky_relu(h)\n",
    "        h = self.dropout(h)\n",
    "        h = self.fc2(h)\n",
    "        h = F.leaky_relu(h)\n",
    "        h = self.dropout(h)\n",
    "        h = self.fc3(h)\n",
    "        h = F.leaky_relu(h)\n",
    "        h = self.dropout(h)\n",
    "        h = self.fc4(h)\n",
    "        return h.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GATv2Lightning(pl.LightningModule):\n",
    "    def __init__(self, timestep,sfreq,alpha,threshold=0.5, hidden_channels=32,heads=8,negative_slope = 0.01, dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.hidden_channels = hidden_channels\n",
    "        self.recurrent_1 = GATv2Conv(\n",
    "            sfreq*timestep,hidden_channels,heads=heads,negative_slope=negative_slope,dropout=dropout, add_self_loops=True,improved=True,edge_dim=1)\n",
    "        self.fc1 = torch.nn.Linear(hidden_channels*heads, 64)\n",
    "        nn.init.kaiming_uniform_(self.fc1.weight,a=negative_slope)\n",
    "        self.fc2 = torch.nn.Linear(64, 32)\n",
    "        nn.init.kaiming_uniform_(self.fc2.weight,a=negative_slope)\n",
    "        self.fc3 = torch.nn.Linear(32, 1)\n",
    "        nn.init.kaiming_uniform_(self.fc3.weight,a=negative_slope)\n",
    "        self.batch_norm = torch.nn.BatchNorm1d(hidden_channels*heads)\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "        self.activation_recurrent = nn.Sequential(\n",
    "            self.batch_norm,\n",
    "            nn.LeakyReLU()\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            self.dropout,\n",
    "            self.fc1,\n",
    "            nn.LeakyReLU(),\n",
    "            self.dropout,\n",
    "            self.fc2,\n",
    "            nn.LeakyReLU(),\n",
    "            self.dropout,\n",
    "            self.fc3 \n",
    "        )\n",
    "        self.loss = nn.BCEWithLogitsLoss(pos_weight=torch.full([1], alpha))\n",
    "        self.sensitivity = BinaryRecall(threshold=threshold)\n",
    "        self.specificity = BinarySpecificity(threshold=threshold)\n",
    "        self.auroc = AUROC(task=\"binary\")\n",
    "    def forward(self, x, edge_index, edge_attr,batch):\n",
    "        h = self.recurrent_1(x, edge_index, edge_attr)\n",
    "        h = self.activation_recurrent(h)\n",
    "        h = global_mean_pool(h,batch)\n",
    "        h = self.classifier(h)\n",
    "        return h.squeeze()\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x = batch.x\n",
    "        x = x.squeeze()\n",
    "        signal_samples = x.shape[1]\n",
    "        x = 2 / signal_samples * torch.abs(x)\n",
    "        x = (x-x.mean(dim=0))/x.std(dim=0)\n",
    "        edge_index = batch.edge_index\n",
    "        edge_attr = batch.edge_attr.float()\n",
    "        y = batch.y\n",
    "        batches = batch.batch\n",
    "        y_hat = self(x, edge_index, edge_attr,batches)\n",
    "        loss = self.loss(y_hat, y)\n",
    "        self.log('train_loss', loss, on_step=False, on_epoch=True,prog_bar=True)\n",
    "        self.log('train_sensitivity', self.sensitivity(y_hat, y), on_step=False, on_epoch=True,prog_bar=True)\n",
    "        self.log('train_specificity', self.specificity(y_hat, y), on_step=False, on_epoch=True,prog_bar=True)\n",
    "        return loss\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x = batch.x\n",
    "        x = x.squeeze()\n",
    "        signal_samples = x.shape[1]\n",
    "        x = 2 / signal_samples * torch.abs(x)\n",
    "        x = (x-x.mean(dim=0))/x.std(dim=0)\n",
    "        edge_index = batch.edge_index\n",
    "        edge_attr = batch.edge_attr.float()\n",
    "        y = batch.y\n",
    "        batches = batch.batch\n",
    "        y_hat = self(x, edge_index, edge_attr,batches)\n",
    "        loss = self.loss(y_hat, y)\n",
    "        self.log('valid_loss', loss, on_step=False, on_epoch=True,prog_bar=True)\n",
    "        self.log('valid_sensitivity', self.sensitivity(y_hat, y), on_step=False, on_epoch=True,prog_bar=True)\n",
    "        self.log('valid_specificity', self.specificity(y_hat, y), on_step=False, on_epoch=True,prog_bar=True)\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "        return optimizer\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lightning_model = GATv2Lightning(TIMESTEP,60,alpha,threshold=0.5, hidden_channels=32,heads=8,negative_slope = 0.01, dropout=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(max_epochs=10, callbacks=[pl.callbacks.EarlyStopping(monitor='valid_loss', patience=5, mode='min')],precision=16,gradient_clip_val=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(lightning_model, train_loader, loso_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation = explainer(transform_x(sample.x), sample.edge_index ,edge_attr=sample.edge_attr.float(),batch=sample.batch)\n",
    "explanation.visualize_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = np.load(\"/home/szymon/code/sano/sano_eeg/data/npy_data_full/chb01/chb01_01.npy\")\n",
    "total_samples = array.shape[1]\n",
    "fs = 256\n",
    "timestep = 6\n",
    "overlap = 5\n",
    "samples_per_recording = 71*fs\n",
    "random_start_time = np.random.randint(0,total_samples-samples_per_recording)\n",
    "interictal_period = array[\n",
    "                :, random_start_time  : random_start_time+samples_per_recording\n",
    "            ]\n",
    "interictal_period = (\n",
    "            np.expand_dims(interictal_period.transpose(), axis=2)\n",
    "            .swapaxes(0, 2)\n",
    "            .swapaxes(0, 1)\n",
    "        )  ##reshape for preprocessing\n",
    "final_array = utils.prepare_timestep_array(interictal_period, timestep*fs, overlap*fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001\n",
      "Epoch: 0 Epoch loss: 1.3020436564289717\n",
      "Epoch sensitivity: 0.5598683953285217\n",
      "Epoch specificity: 0.7376834750175476\n",
      "Epoch AUROC: 0.6794337630271912 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1/25 [00:28<11:23, 28.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (inf --> 1.109545).  Saving model ...\n",
      "Epoch val_loss: 1.109545111656189\n",
      "Epoch val_sensitivity: 0.29629629850387573\n",
      "Epoch val specificity: 0.9724770784378052\n",
      "Epoch val AUROC: 0.8393120169639587 \n",
      "0.001\n",
      "Epoch: 1 Epoch loss: 1.06699447327876\n",
      "Epoch sensitivity: 0.5960526466369629\n",
      "Epoch specificity: 0.8096878528594971\n",
      "Epoch AUROC: 0.7644992470741272 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 2/25 [00:55<10:29, 27.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (1.109545 --> 1.057326).  Saving model ...\n",
      "Epoch val_loss: 1.057326316833496\n",
      "Epoch val_sensitivity: 0.40740740299224854\n",
      "Epoch val specificity: 0.956749677658081\n",
      "Epoch val AUROC: 0.8571752309799194 \n",
      "0.001\n",
      "Epoch: 2 Epoch loss: 0.9829776353570094\n",
      "Epoch sensitivity: 0.6861842274665833\n",
      "Epoch specificity: 0.7976986169815063\n",
      "Epoch AUROC: 0.8110201358795166 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 3/25 [01:19<09:28, 25.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (1.057326 --> 1.000369).  Saving model ...\n",
      "Epoch val_loss: 1.0003694295883179\n",
      "Epoch val_sensitivity: 0.43209877610206604\n",
      "Epoch val specificity: 0.942332923412323\n",
      "Epoch val AUROC: 0.8670939207077026 \n",
      "0.001\n",
      "Epoch: 3 Epoch loss: 0.9308767736670506\n",
      "Epoch sensitivity: 0.7348684072494507\n",
      "Epoch specificity: 0.7796458601951599\n",
      "Epoch AUROC: 0.8327381014823914 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 4/25 [01:43<08:50, 25.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 1 out of 3\n",
      "Epoch val_loss: 1.03385329246521\n",
      "Epoch val_sensitivity: 0.43209877610206604\n",
      "Epoch val specificity: 0.9541284441947937\n",
      "Epoch val AUROC: 0.8741484880447388 \n",
      "0.001\n",
      "Epoch: 4 Epoch loss: 0.8795564203148344\n",
      "Epoch sensitivity: 0.7703947424888611\n",
      "Epoch specificity: 0.78460693359375\n",
      "Epoch AUROC: 0.8547898530960083 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 5/25 [02:08<08:22, 25.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 2 out of 3\n",
      "Epoch val_loss: 1.043623447418213\n",
      "Epoch val_sensitivity: 0.48148149251937866\n",
      "Epoch val specificity: 0.9436435103416443\n",
      "Epoch val AUROC: 0.871414065361023 \n",
      "0.001\n",
      "Epoch: 5 Epoch loss: 0.8371732795380976\n",
      "Epoch sensitivity: 0.7881578803062439\n",
      "Epoch specificity: 0.7791634798049927\n",
      "Epoch AUROC: 0.86629718542099 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 6/25 [02:33<07:55, 25.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (1.000369 --> 0.915884).  Saving model ...\n",
      "Epoch val_loss: 0.9158839583396912\n",
      "Epoch val_sensitivity: 0.604938268661499\n",
      "Epoch val specificity: 0.9213630557060242\n",
      "Epoch val AUROC: 0.8827565312385559 \n",
      "0.001\n",
      "Epoch: 6 Epoch loss: 0.8236094926932893\n",
      "Epoch sensitivity: 0.7980263233184814\n",
      "Epoch specificity: 0.780059278011322\n",
      "Epoch AUROC: 0.8715394735336304 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 7/25 [02:59<07:37, 25.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 1 out of 3\n",
      "Epoch val_loss: 1.0733695030212402\n",
      "Epoch val_sensitivity: 0.5061728358268738\n",
      "Epoch val specificity: 0.9344692230224609\n",
      "Epoch val AUROC: 0.8773442506790161 \n",
      "0.001\n",
      "Epoch: 7 Epoch loss: 0.8187342183998382\n",
      "Epoch sensitivity: 0.8092105388641357\n",
      "Epoch specificity: 0.7745469808578491\n",
      "Epoch AUROC: 0.8741692304611206 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 8/25 [03:25<07:13, 25.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 2 out of 3\n",
      "Epoch val_loss: 0.9698489308357239\n",
      "Epoch val_sensitivity: 0.5432098507881165\n",
      "Epoch val specificity: 0.9187418222427368\n",
      "Epoch val AUROC: 0.8741647005081177 \n",
      "0.001\n",
      "Epoch: 8 Epoch loss: 0.8099378608612425\n",
      "Epoch sensitivity: 0.82039475440979\n",
      "Epoch specificity: 0.790532648563385\n",
      "Epoch AUROC: 0.8799048662185669 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 8/25 [03:49<08:07, 28.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 3 out of 3\n",
      "Epoch val_loss: 1.0783798694610596\n",
      "Epoch val_sensitivity: 0.43209877610206604\n",
      "Epoch val specificity: 0.956749677658081\n",
      "Epoch val AUROC: 0.8696988821029663 \n",
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## normal loop\n",
    "torch_geometric.seed_everything(42)\n",
    "import torchvision\n",
    "early_stopping = utils.EarlyStopping(patience=3, verbose=True)\n",
    "device = torch.device(\"cpu\")\n",
    "model = GATv2(TIMESTEP,60,batch_size=32).to(device) #Gatv2\n",
    "loss_fn =  nn.BCEWithLogitsLoss(pos_weight=torch.full([1], alpha))\n",
    "#loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(),lr=0.001,weight_decay=0.0001)\n",
    "recall = BinaryRecall(threshold=0.5)\n",
    "specificity = BinarySpecificity(threshold=0.5)\n",
    "auroc = AUROC(task=\"binary\")\n",
    "roc = ROC('binary')\n",
    "model.train()\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min',patience=2)\n",
    "\n",
    "for epoch in tqdm(range(25)):\n",
    "        try:\n",
    "                del preds, ground_truth\n",
    "        except:\n",
    "                pass\n",
    "        epoch_loss = 0.0\n",
    "        epoch_loss_valid = 0.0\n",
    "        model.train()\n",
    "        sample_counter = 0\n",
    "        batch_counter = 0\n",
    "        print(get_lr(optimizer))\n",
    "        for time, batch in enumerate(train_loader): ## TODO - this thing is still operating with no edge weights!!!\n",
    "                ## find a way to compute plv per batch fast (is it even possible?)\n",
    "        \n",
    "                x = batch.x\n",
    "        \n",
    "                edge_index = batch.edge_index\n",
    "                edge_attr = batch.edge_attr.float()\n",
    "\n",
    "                y = batch.y\n",
    "                batch_idx = batch.batch\n",
    "                #time_to_seizure = batch.time.float()\n",
    "               \n",
    "               # y = torch.tensor(np.array([1 if y_train == 0 else 0 for y_train in y]),dtype=torch.float32)\n",
    "            \n",
    "               # x = x.squeeze()\n",
    "              \n",
    "                #signal_samples = x.shape[1]\n",
    "                x = torch.square(torch.abs(x))\n",
    "                #x = (x-x.mean(dim=0))/x.std(dim=0)\n",
    "                y_hat = model(x, edge_index,None,batch_idx)\n",
    "              \n",
    "           \n",
    "                # y_hat =torch.stack(\n",
    "                #         [model(x=x[n], edge_index=edge_index[n], edge_weight=edge_attr[n].float()) \n",
    "                #          for n in range(x.shape[0])])\n",
    "                ##loss\n",
    "        \n",
    "                loss = loss_fn(y_hat,y)\n",
    "                #loss = torchvision.ops.sigmoid_focal_loss(y_hat,y,alpha=alpha,gamma=3,reduction='mean')\n",
    "                epoch_loss += loss\n",
    "                ## get preds & gorund truth\n",
    "                try:\n",
    "                 preds = torch.cat([preds,y_hat.detach()],dim=0)\n",
    "                 ground_truth = torch.cat([ground_truth,y],dim=0)\n",
    "            \n",
    "                except:\n",
    "                 preds= y_hat.detach()\n",
    "                 ground_truth = y\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        ## calculate acc\n",
    "        \n",
    "        train_auroc = auroc(preds,ground_truth)\n",
    "        train_sensitivity = recall(preds,ground_truth)\n",
    "        train_specificity = specificity(preds,ground_truth)\n",
    "        del preds, ground_truth\n",
    "        print(f'Epoch: {epoch}', f'Epoch loss: {epoch_loss.detach().numpy()/(time+1)}')\n",
    "        print(f'Epoch sensitivity: {train_sensitivity}')\n",
    "        print(f'Epoch specificity: {train_specificity}')\n",
    "        print(f'Epoch AUROC: {train_auroc} ')\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "                try:\n",
    "                        del preds_valid, ground_truth_valid\n",
    "                except:\n",
    "                        pass\n",
    "                for time_valid, batch_valid in enumerate(valid_loader):\n",
    "                        x = batch_valid.x\n",
    "                        edge_index = batch_valid.edge_index\n",
    "                        edge_attr = batch_valid.edge_attr.float()\n",
    "                        y_val = batch_valid.y\n",
    "                        batch_idx = batch_valid.batch\n",
    "                        #inverse_y_val = torch.tensor(np.array([1 if y == 0 else 0 for y in y_val]),dtype=torch.float32)\n",
    "                        #time_to_seizure_val = batch_valid.time.float()\n",
    "                        x = x.squeeze()\n",
    "                        #signal_samples = x.shape[1]\n",
    "                        x = torch.square(torch.abs(x))\n",
    "                        # x = (x-x.mean(dim=0))/x.std(dim=0)\n",
    "                        \n",
    "                        y_hat_val = model(x, edge_index,None,batch_idx)\n",
    "                        loss_valid = loss_fn(y_hat_val,y_val)\n",
    "                       # loss_valid = torchvision.ops.sigmoid_focal_loss(y_hat_val,inverse_y_val,alpha=alpha,gamma=3,reduction='mean')\n",
    "                        epoch_loss_valid += loss_valid\n",
    "                        try:\n",
    "                         preds_valid = torch.cat([preds_valid,y_hat_val],dim=0)\n",
    "                         ground_truth_valid = torch.cat([ground_truth_valid,y_val],dim=0)\n",
    "                        except:\n",
    "                         preds_valid= y_hat_val\n",
    "                         ground_truth_valid = y_val\n",
    "        #scheduler.step(epoch_loss_valid)\n",
    "        early_stopping(epoch_loss_valid.numpy()/(time_valid+1), model)\n",
    "        val_auroc = auroc(preds_valid,ground_truth_valid)\n",
    "        val_sensitivity = recall(preds_valid,ground_truth_valid)\n",
    "        val_specificity = specificity(preds_valid,ground_truth_valid)\n",
    "        del preds_valid, ground_truth_valid\n",
    "        print(f'Epoch val_loss: {epoch_loss_valid.detach().numpy()/(time_valid+1)}')\n",
    "        print(f'Epoch val_sensitivity: {val_sensitivity}')\n",
    "        print(f'Epoch val specificity: {val_specificity}')\n",
    "        print(f'Epoch val AUROC: {val_auroc} ')\n",
    "        if early_stopping.early_stop:\n",
    "                print(\"Early stopping\")\n",
    "                model.load_state_dict(torch.load('checkpoint.pt'))\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loso_loss: 1.655221700668335\n",
      "Loso_sensitivity: 0.5496688485145569\n",
      "Loso_specificity: 0.9800000190734863\n",
      "Loso_AUROC: 0.9359867572784424 \n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "recall = BinaryRecall(threshold=0.5)\n",
    "specificity = BinarySpecificity(threshold=0.5)\n",
    "with torch.no_grad():\n",
    "    try:\n",
    "        del preds_valid, ground_truth_valid\n",
    "    except:\n",
    "        pass\n",
    "    epoch_loss_loso = 0.0\n",
    "    for time_loso, batch_loso in enumerate(loso_loader):\n",
    "            x = batch_loso.x.to(device)\n",
    "            edge_index = batch_loso.edge_index.to(device)\n",
    "            edge_attr = batch_loso.edge_attr.float().to(device)\n",
    "            y_loso = batch_loso.y.to(device)\n",
    "            batch_idx = batch_loso.batch.to(device)\n",
    "            #y_loso = torch.tensor(np.array([1 if y == 0 else 0 for y in y_loso]))\n",
    "            #time_to_seizure_val = batch_valid.time.float()\n",
    "            x = x.squeeze()\n",
    "            # x = batch_valid[0].to(device)\n",
    "            # edge_index = batch_valid[1].to(device)\n",
    "            # y_val = batch_valid[3].squeeze().to(device)\n",
    "           # x = (x-x.mean(dim=0))/x.std(dim=0)\n",
    "            x = torch.square(torch.abs(x))\n",
    "            \n",
    "            \n",
    "            y_hat_loso = model(x, edge_index,None,batch_idx)\n",
    "            loss_loso = loss_fn(y_hat_loso,y_loso)\n",
    "            #loss_loso = torchvision.ops.sigmoid_focal_loss(y_hat,y,alpha=0.65,gamma=4,reduction='mean')\n",
    "            epoch_loss_loso += loss_loso\n",
    "            try:\n",
    "                preds_loso = torch.cat([preds_loso,y_hat_loso],dim=0)\n",
    "                ground_truth_loso= torch.cat([ground_truth_loso,y_loso],dim=0)\n",
    "            except:\n",
    "                preds_loso= y_hat_loso\n",
    "                ground_truth_loso = y_loso\n",
    "    loso_auroc = auroc(preds_loso,ground_truth_loso)\n",
    "    loso_sensitivity = recall(preds_loso,ground_truth_loso)\n",
    "    loso_specificity = specificity(preds_loso,ground_truth_loso)\n",
    "    del preds_loso, ground_truth_loso\n",
    "\n",
    "    print(f'Loso_loss: {epoch_loss_loso.cpu().numpy()/(time_loso+1)}')\n",
    "    print(f'Loso_sensitivity: {loso_sensitivity}')\n",
    "    print(f'Loso_specificity: {loso_specificity}')\n",
    "    print(f'Loso_AUROC: {loso_auroc} ')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "88cc438b9c90976695678f0d6c20e4c06983b5710e6855b5b4390f60ecf93fe8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
